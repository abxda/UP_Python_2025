{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUUFgyMIICv5f1CG08Avti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/UP_Python_2025/blob/main/Semana_04_01_Lunes_UP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **De Números a Mapas: La Magia de los Datos Geoespaciales**\n",
        "\n",
        "**Objetivo Principal:**\n",
        "\n",
        "En este taller, aprenderás a combinar **datos censales** (información sobre la población y viviendas) con **datos geoespaciales** (mapas con ubicaciones geográficas). Usaremos Python y la eficiente base de datos DuckDB para lograrlo.\n",
        "\n",
        "*   **¿Qué son los Datos Censales?**\n",
        "    Imagina una radiografía detallada de la población de un país. Los censos recolectan información vital como edad, género, educación, empleo y características de las viviendas. Son esenciales para entender cómo es una sociedad en un momento específico.\n",
        "\n",
        "*   **¿Qué son los Datos Geoespaciales?**\n",
        "    Son datos que tienen una ubicación en la Tierra. Pueden ser las fronteras de una manzana, un municipio o un estado, o cualquier fenómeno que ocurra en un lugar concreto. La clave es la referencia geográfica.\n",
        "\n",
        "**Automatización del Flujo de Trabajo:**\n",
        "\n",
        "Dominarás cómo automatizar todo el proceso: desde **descargar** datos de fuentes oficiales como el INEGI, **extraer** la información importante, **convertirla** a formatos eficientes y, finalmente, **unir** estos datos para realizar análisis más profundos. La automatización es clave para trabajar de forma eficiente y poder repetir nuestros análisis fácilmente.\n",
        "\n",
        "**¿Por qué es fundamental entender esto?**\n",
        "\n",
        "*   **Análisis con Contexto:**\n",
        "    Saber **dónde** ocurren los fenómenos (como la densidad de población o el acceso a servicios) y **quiénes** son los afectados, añade una dimensión crucial a los datos. La ubicación enriquece enormemente el análisis.\n",
        "\n",
        "*   **Planeación Inteligente:**\n",
        "    Combinar datos del censo con mapas es vital para planificar ciudades, distribuir recursos de manera efectiva, diseñar políticas públicas basadas en evidencia y promover un desarrollo más justo y sostenible.\n",
        "\n",
        "*   **Decisiones Informadas:**\n",
        "    Al poner variables clave en un mapa (por ejemplo, dónde vive la población vulnerable o cómo es el acceso a escuelas), podemos ver patrones, desigualdades y tendencias que serían invisibles en simples tablas de números. Los mapas son herramientas poderosas para comunicar y analizar.\n",
        "\n",
        "**En resumen, en esta clase aprenderás a:**\n",
        "\n",
        "1.  **Descargar Datos con Python:** Usar Python para obtener datos del INEGI directamente desde internet, de forma automática.\n",
        "2.  **Extraer Información de Mapas (Shapefiles):** Descomprimir y obtener los archivos esenciales de los Shapefiles, un formato común para mapas digitales.\n",
        "3.  **Usar DuckDB para tus Datos:** Conocer DuckDB, una base de datos rápida y fácil de usar que no necesita un servidor complicado, perfecta para manejar datos censales y mapas.\n",
        "4.  **Unir Datos del Censo con Mapas:** Combinar las estadísticas del censo con las formas geográficas de los mapas para crear un conjunto de datos enriquecido, listo para el análisis espacial.\n",
        "5.  **Organizar tu Trabajo:** Establecer buenas prácticas para organizar tus archivos y limpiar datos, asegurando un proceso eficiente y sin errores.\n",
        "\n",
        "## **Preparando el Escenario: Configuración del Entorno y Librerías Esenciales**\n",
        "\n",
        "**Librerías Python: Tus Herramientas Clave**\n",
        "\n",
        "Piensa en las librerías como cajas de herramientas especializadas para Python. Nos ayudan a realizar tareas específicas sin tener que programar todo desde cero. ¡Usamos herramientas probadas y optimizadas!\n",
        "\n",
        "*   **`requests`:** Tu mensajero web. Permite a Python pedir y recibir información de servidores web, como cuando tu navegador descarga un archivo. Lo usaremos para **descargar los datos del INEGI**.\n",
        "*   **`tqdm`:** La barra de progreso amigable. Muestra cuánto falta para que terminen tareas largas (como las descargas), haciendo la espera más llevadera.\n",
        "*   **`os` y `shutil`:** Tus organizadores de archivos. `os` te deja interactuar con el sistema operativo (crear carpetas, ver archivos). `shutil` te da herramientas más potentes para copiar o borrar carpetas enteras. Fundamentales para **mantener tus datos ordenados**.\n",
        "*   **`zipfile`:** El descompresor. Permite a Python trabajar con archivos `.zip` (un formato común para comprimir datos). Lo usaremos para **extraer los datos del INEGI** que vienen en este formato.\n",
        "*   **`duckdb`:** Tu base de datos personal y potente. Es una base de datos SQL que funciona desde un simple archivo, ¡sin necesidad de instalar un servidor! Es muy rápida para analizar datos y tiene **soporte para datos geoespaciales**, lo que la hace ideal para nuestro proyecto.\n",
        "*   **`geopandas`:** El experto en mapas de Python. Extiende `pandas` (la librería estrella para datos tabulares) para que pueda manejar datos geoespaciales. Permite leer, escribir y manipular formatos de mapas como Shapefiles y GeoParquet, y realizar **operaciones con geometrías**.\n",
        "*   **`pyarrow`:** Un acelerador para tus datos. Ayuda a `geopandas` y `duckdb` a leer y escribir formatos de datos eficientes como GeoParquet de manera muy rápida.\n",
        "\n",
        "*(Otras librerías como `folium` para mapas interactivos o `chardet` para detectar codificación de texto pueden ser útiles en proyectos más avanzados, pero nos centraremos en las anteriores para este flujo elemental).*\n",
        "\n",
        "**Instalación de Librerías: ¡Equipando tu Entorno!**\n",
        "\n",
        "Para usar estas herramientas, primero debemos instalarlas. Usaremos `pip`, el instalador de paquetes de Python, en la primera celda de código.\n",
        "\n",
        "**Organización de Carpetas: ¡Tu Espacio de Trabajo Ordenado!**\n",
        "\n",
        "Una buena estructura de carpetas es esencial. Crearemos la siguiente organización para nuestros datos del INEGI:\n",
        "\n",
        "```\n",
        "inegi/                  # Carpeta principal para este proyecto\n",
        "├── censo_csv/          # Aquí guardaremos los archivos CSV del censo (datos tabulares)\n",
        "└── marco_geoestadistico/ # Aquí guardaremos los archivos ZIP de los mapas (Shapefiles)\n",
        "    └── shp_extraidos/  # Subcarpeta para los componentes de los Shapefiles\n",
        "        └── m/          # Específicamente para los Shapefiles de Manzanas\n",
        "```\n",
        "\n",
        "Crearemos estas carpetas usando Python para asegurar que nuestro espacio de trabajo esté listo.\n",
        "\n",
        "**¿Por qué la organización es tan importante?**\n",
        "\n",
        "*   **Claridad:** Un proyecto ordenado es más fácil de entender, tanto para ti como para otros.\n",
        "*   **Reproducibilidad:** Facilita que tú u otros puedan repetir tu análisis en el futuro.\n",
        "*   **Eficiencia:** Encuentras lo que necesitas rápidamente, ahorrando tiempo y frustración."
      ],
      "metadata": {
        "id": "ePSMYUXfJlF0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnAWTxJCJQkN"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Instalación de Librerías Esenciales\n",
        "# -------------------------------------------\n",
        "# Usamos 'pip install' para añadir a nuestro entorno Python las herramientas (librerías)\n",
        "# que necesitaremos para este proyecto. El comando '--quiet' reduce la cantidad de mensajes\n",
        "# durante la instalación.\n",
        "\n",
        "# Librerías a instalar:\n",
        "# - duckdb: Para nuestra base de datos analítica rápida y basada en archivos.\n",
        "# - geopandas: Para leer, escribir y manipular datos geoespaciales (mapas).\n",
        "# - fsspec: Una dependencia de geopandas para trabajar con diferentes sistemas de archivos.\n",
        "# - matplotlib: Aunque no graficaremos explícitamente, es una dependencia común de geopandas.\n",
        "# - tqdm: Para mostrar barras de progreso visuales durante tareas largas.\n",
        "# - requests: Para descargar archivos de internet (datos del INEGI).\n",
        "# - pyarrow: Para que geopandas y duckdb puedan trabajar eficientemente con el formato GeoParquet.\n",
        "\n",
        "!pip install duckdb geopandas fsspec matplotlib tqdm requests pyarrow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 2: Importación de Librerías\n",
        "# ----------------------------------\n",
        "# Aquí cargamos las librerías que instalamos o que vienen con Python\n",
        "# para poder usar sus funciones en nuestro código.\n",
        "\n",
        "# --- Para interactuar con el sistema de archivos y utilidades generales ---\n",
        "import os  # Funciones para interactuar con el sistema operativo (rutas, carpetas)\n",
        "import shutil  # Operaciones de alto nivel con archivos y carpetas (ej. borrar carpetas)\n",
        "import time  # Funciones relacionadas con el tiempo (ej. pausas, aunque no la usaremos activamente)\n",
        "from zipfile import ZipFile  # Para trabajar con archivos comprimidos .zip\n",
        "\n",
        "# --- Para descargas web y barras de progreso ---\n",
        "import requests  # Para hacer solicitudes HTTP (descargar archivos de internet)\n",
        "from tqdm import tqdm  # Para mostrar barras de progreso visuales\n",
        "\n",
        "# --- Para análisis de datos y geoespacial ---\n",
        "import duckdb  # Para la base de datos analítica DuckDB\n",
        "import geopandas as gpd  # Para trabajar con datos geoespaciales (Shapefiles, GeoParquet)\n",
        "\n",
        "# (Nota: pyarrow se usa internamente por geopandas y duckdb para Parquet,\n",
        "# no necesitamos importarlo directamente aquí para las operaciones que haremos.)\n",
        "\n",
        "print(\"Librerías importadas exitosamente.\")"
      ],
      "metadata": {
        "id": "jsSihpykdzBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descarga Programática de Datos: ¡Python al Rescate de la Información en la Web!**\n",
        "\n",
        "**Descarga Programática: ¿Qué significa?**\n",
        "\n",
        "Normalmente, para bajar un archivo de internet, abres tu navegador, buscas el enlace y haces clic. Eso es **descarga manual**. La **descarga programática** significa usar código (en nuestro caso, Python) para hacer este proceso **automáticamente**.\n",
        "\n",
        "*   **URLs: Las Direcciones de la Información Web**\n",
        "    Para descargar algo, Python necesita la **URL** (la dirección web exacta) del archivo. Muchos sitios, como el INEGI, ofrecen enlaces directos a sus archivos de datos.\n",
        "\n",
        "*   **`requests.get()`: Hablando con la Web**\n",
        "    La librería `requests` permite a Python \"hablar\" con los servidores web. Cuando usamos `requests.get(url)`, nuestro script le pide al servidor que le envíe el recurso (el archivo) que se encuentra en esa `url`. Si todo va bien, el servidor responde enviando los datos del archivo.\n",
        "\n",
        "**La Función `download(url, directory)`: Tu Asistente de Descargas Inteligente**\n",
        "\n",
        "Hemos creado una función llamada `download` que se encarga de todo el proceso de descarga de forma ordenada. Veamos sus partes más importantes:\n",
        "\n",
        "```python\n",
        "# def download(url, directory):\n",
        "#     # ... (código que veremos en la siguiente celda) ...\n",
        "```\n",
        "\n",
        "*   **`url` y `directory` (Entradas):**\n",
        "    *   `url`: La dirección web completa del archivo a descargar.\n",
        "    *   `directory`: La carpeta en tu computadora donde quieres guardar el archivo.\n",
        "\n",
        "*   **Extracción del Nombre del Archivo:**\n",
        "    `filename = url.split('/')[-1]`\n",
        "    Esta línea inteligentemente toma la URL y extrae solo el nombre del archivo (lo que está después de la última `/`).\n",
        "\n",
        "*   **Ruta Completa de Guardado:**\n",
        "    `filepath = os.path.join(directory, filename)`\n",
        "    Combina la carpeta de destino y el nombre del archivo para crear la ruta completa donde se guardará. `os.path.join` lo hace de forma que funcione en cualquier sistema operativo (Windows, Mac, Linux).\n",
        "\n",
        "*   **Verificación de Existencia (¡No Descargar Dos Veces!):**\n",
        "    `if os.path.exists(filepath): ... return`\n",
        "    Antes de descargar, la función revisa si el archivo ya existe. Si es así, nos avisa y no lo descarga de nuevo, ¡ahorrando tiempo y datos!\n",
        "\n",
        "*   **La Descarga Real con `requests`:**\n",
        "    `response = requests.get(url, stream=True)`\n",
        "    Aquí ocurre la magia. `requests.get()` contacta la URL. El argumento `stream=True` es muy importante para archivos grandes: le dice a `requests` que descargue el archivo por partes (en \"streaming\") en lugar de intentar cargarlo todo en la memoria de golpe. Esto es más eficiente.\n",
        "\n",
        "*   **Manejo de Errores HTTP (Importante):**\n",
        "    `response.raise_for_status()`\n",
        "    Justo después de la solicitud, esta línea verifica si la descarga fue exitosa (por ejemplo, si el servidor respondió con un código \"200 OK\"). Si hubo un error (como \"404 Archivo No Encontrado\"), el script se detendrá y mostrará un error claro. Es una forma elemental y directa de manejar problemas de red.\n",
        "\n",
        "*   **Guardando el Archivo con Barra de Progreso `tqdm`:**\n",
        "    Se abre el archivo en modo escritura binaria (`'wb'`) y se usa `tqdm` para crear una barra de progreso.\n",
        "    *   `tqdm(total=total_size, ...)`: Configura la barra usando el tamaño total del archivo (si el servidor lo proporciona) y unidades como Bytes, KB, MB.\n",
        "    *   `for data in response.iter_content(chunk_size=1024): ...`: El archivo se descarga en pedazos (chunks) de 1KB. Cada pedazo se escribe en el disco y la barra de progreso se actualiza.\n",
        "\n",
        "*   **Mensaje de Éxito:**\n",
        "    Al final, un mensaje nos confirma que la descarga se completó.\n",
        "\n",
        "**Beneficios de la Descarga Programática:**\n",
        "\n",
        "*   **Automatización:** Descarga múltiples archivos o actualiza datos con solo ejecutar el script.\n",
        "*   **Eficiencia:** Ahorra tiempo y esfuerzo comparado con hacerlo manualmente.\n",
        "*   **Reproducibilidad:** Asegura que siempre obtienes los datos de la misma fuente y de la misma manera, lo que es clave para que tus análisis se puedan repetir.\n",
        "*   **Integración:** Puedes incluir la descarga de datos como el primer paso de un flujo de trabajo de análisis más grande."
      ],
      "metadata": {
        "id": "4AhnR3xKehBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 3: Función de Descarga Programática\n",
        "# -----------------------------------------\n",
        "# Esta función se encarga de descargar un archivo desde una URL\n",
        "# y guardarlo en un directorio específico. Incluye una barra de\n",
        "# progreso y evita descargar archivos que ya existen.\n",
        "\n",
        "def download(url, directory):\n",
        "    \"\"\"\n",
        "    Descarga un archivo desde la URL especificada y lo guarda en 'directory'.\n",
        "\n",
        "    Si el archivo ya existe en 'directory', no realiza la descarga de nuevo.\n",
        "    Muestra una barra de progreso durante la descarga.\n",
        "    Detiene el script si ocurre un error HTTP (ej. archivo no encontrado).\n",
        "\n",
        "    Args:\n",
        "        url (str): La URL completa del archivo a descargar.\n",
        "        directory (str): La ruta de la carpeta donde se guardará el archivo.\n",
        "    \"\"\"\n",
        "    # Extraer el nombre del archivo de la URL\n",
        "    # Por ejemplo, de \"https://example.com/datos.zip\", obtenemos \"datos.zip\"\n",
        "    filename = url.split('/')[-1]\n",
        "\n",
        "    # Construir la ruta completa donde se guardará el archivo\n",
        "    # os.path.join se asegura de que la ruta sea correcta para cualquier sistema operativo\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    # 1. Verificar si el archivo ya existe para evitar descargas redundantes\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"El archivo '{filename}' ya existe en '{directory}'. No se descarga de nuevo.\")\n",
        "        return  # Salir de la función si el archivo ya existe\n",
        "\n",
        "    # Si el archivo no existe, proceder con la descarga\n",
        "    print(f\"Descargando '{filename}' de '{url}'...\")\n",
        "\n",
        "    try:\n",
        "        # 2. Realizar la solicitud de descarga\n",
        "        # stream=True es importante para archivos grandes: descarga el contenido en bloques\n",
        "        response = requests.get(url, stream=True, timeout=30) # timeout de 30 segundos\n",
        "\n",
        "        # 3. Verificar si la solicitud fue exitosa (códigos HTTP 2xx)\n",
        "        # Si hay un error (ej. 404 No Encontrado, 500 Error del Servidor),\n",
        "        # esto levantará una excepción HTTPError y detendrá el script aquí.\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # 4. Obtener el tamaño total del archivo (si el servidor lo proporciona)\n",
        "        # Necesario para que la barra de progreso tqdm muestre el total.\n",
        "        # Content-Length viene en bytes.\n",
        "        total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # 5. Guardar el archivo en disco, mostrando una barra de progreso\n",
        "        # 'wb' significa \"write binary\" (escritura binaria), adecuado para cualquier tipo de archivo.\n",
        "        with open(filepath, 'wb') as f:\n",
        "            # Configuración de la barra de progreso tqdm\n",
        "            # desc: Descripción que aparece junto a la barra.\n",
        "            # total: Tamaño total del archivo en bytes.\n",
        "            # unit: Unidad base ('B' para bytes).\n",
        "            # unit_scale: Permite escalar automáticamente a KB, MB, GB.\n",
        "            # unit_divisor: Define cuántas unidades base forman la siguiente escala (1024 bytes = 1 KB).\n",
        "            progress_bar_params = {\n",
        "                'desc': filename,\n",
        "                'total': total_size_in_bytes,\n",
        "                'unit': 'B',\n",
        "                'unit_scale': True,\n",
        "                'unit_divisor': 1024,\n",
        "                'ncols': 80 # Ancho de la barra de progreso\n",
        "            }\n",
        "\n",
        "            # Si total_size_in_bytes es 0 (servidor no envió Content-Length),\n",
        "            # tqdm no puede mostrar un progreso porcentual, pero sí los bytes descargados.\n",
        "            # En ese caso, quitamos 'total' para que tqdm funcione en modo \"flujo desconocido\".\n",
        "            if total_size_in_bytes == 0:\n",
        "                progress_bar_params.pop('total', None) # Quitar 'total' si es 0\n",
        "\n",
        "            with tqdm(**progress_bar_params) as pbar:\n",
        "                # Iterar sobre el contenido de la respuesta en bloques (chunks)\n",
        "                # chunk_size=8192 bytes (8KB) es un buen tamaño de bloque.\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:  # Filtrar chunks de keep-alive vacíos\n",
        "                        f.write(chunk)  # Escribir el bloque en el archivo\n",
        "                        pbar.update(len(chunk))  # Actualizar la barra de progreso\n",
        "\n",
        "        print(f\"\\nDescarga de '{filename}' completada y guardada en '{filepath}'.\\n\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        print(f\"Error HTTP durante la descarga de '{filename}': {http_err}\")\n",
        "        # Opcional: si el archivo se creó parcialmente, eliminarlo.\n",
        "        if os.path.exists(filepath):\n",
        "            os.remove(filepath)\n",
        "            print(f\"Archivo parcial '{filepath}' eliminado.\")\n",
        "        # El script se detendrá aquí debido a la excepción no manejada completamente,\n",
        "        # lo cual es aceptable para un enfoque \"elemental\".\n",
        "        raise # Re-lanzar la excepción para detener el script\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error inesperado durante la descarga de '{filename}': {e}\")\n",
        "        if os.path.exists(filepath):\n",
        "            os.remove(filepath)\n",
        "            print(f\"Archivo parcial '{filepath}' eliminado.\")\n",
        "        raise # Re-lanzar la excepción\n",
        "\n",
        "# --- Ejemplo de uso (comentado para no ejecutarlo ahora) ---\n",
        "# if __name__ == '__main__':\n",
        "# # Crear un directorio temporal para la prueba\n",
        "#     test_dir = \"./temp_downloads\"\n",
        "#     os.makedirs(test_dir, exist_ok=True)\n",
        "#\n",
        "# # URL de un archivo pequeño para probar (reemplazar con una URL válida y pequeña)\n",
        "# # Por ejemplo, el logo de Python\n",
        "#     test_url = \"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\"\n",
        "#\n",
        "#     print(\"Iniciando descarga de prueba...\")\n",
        "#     download(test_url, test_dir)\n",
        "#\n",
        "# # Intentar descargar de nuevo para ver el mensaje de \"ya existe\"\n",
        "#     print(\"\\nIntentando descargar el mismo archivo de nuevo...\")\n",
        "#     download(test_url, test_dir)\n",
        "#\n",
        "# # Prueba con una URL que no existe (error 404)\n",
        "#     error_url = \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/archivo_que_no_existe.zip\"\n",
        "#     print(f\"\\nIntentando descargar desde una URL incorrecta: {error_url}\")\n",
        "#     try:\n",
        "#         download(error_url, test_dir)\n",
        "#     except requests.exceptions.HTTPError as e:\n",
        "#         print(f\"Descarga fallida como se esperaba: {e}\")\n",
        "#\n",
        "# # Limpiar el directorio de prueba\n",
        "# # shutil.rmtree(test_dir)\n",
        "# # print(f\"\\nDirectorio de prueba '{test_dir}' eliminado.\")"
      ],
      "metadata": {
        "id": "VMh0btIBd4bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extracción de Shapefiles desde Archivos ZIP**\n",
        "\n",
        "**Archivos Shapefile: El Formato Clásico para Datos Geoespaciales Vectoriales**\n",
        "\n",
        "*   **¿Qué es un Shapefile?**\n",
        "    Un Shapefile es un formato de archivo muy popular para guardar **datos geoespaciales vectoriales**. Piensa en datos vectoriales como aquellos que representan características geográficas usando **puntos** (una ciudad), **líneas** (una carretera) o **polígonos** (el contorno de un municipio o una manzana). Aunque es un formato con algunos años, sigue siendo muy común para distribuir mapas digitales.\n",
        "\n",
        "*   **Componentes de un Shapefile: Un Equipo de Archivos**\n",
        "    Un Shapefile no es un solo archivo, sino un **conjunto de archivos que trabajan juntos**. Cada uno tiene una extensión diferente y cumple un rol específico. Para que un Shapefile funcione, necesitamos principalmente los siguientes componentes (¡todos deben tener el mismo nombre base, ej. `09m`!):\n",
        "    *   **`.shp` (Shape File):** Es el archivo principal que contiene las **geometrías** en sí (las coordenadas que definen los puntos, líneas o polígonos).\n",
        "    *   **`.shx` (Shape Index File):** Es un índice que ayuda a los programas a buscar y acceder a las geometrías en el archivo `.shp` de manera más rápida.\n",
        "    *   **`.dbf` (dBase Table):** Contiene la **tabla de atributos** asociada a cada geometría. Imagina una hoja de cálculo donde cada fila corresponde a una forma en el mapa (ej. una manzana) y cada columna es un dato sobre esa forma (ej. su clave, su población, etc.).\n",
        "    *   **`.prj` (Projection File):** Define el **Sistema de Coordenadas de Referencia (CRS)**. Esto le dice al software cómo interpretar las coordenadas del archivo `.shp` y cómo se \"proyectan\" en un mapa plano. Es crucial para que los mapas se muestren correctamente y se puedan alinear con otros datos.\n",
        "    *   **`.cpg` (Code Page File - Opcional pero útil):** Indica la **codificación de caracteres** usada en el archivo `.dbf`. Esto es importante para que los textos con acentos o caracteres especiales (como nombres de calles o municipios) se lean correctamente. A veces puede faltar, y en esos casos, lo crearemos con una codificación común.\n",
        "\n",
        "**La Función `extract_shapefile(...)`: Tu Descompresor de Mapas Automatizado**\n",
        "\n",
        "Para facilitarnos la vida, crearemos una función llamada `extract_shapefile`. Esta función tomará un archivo ZIP descargado (que contiene los componentes del Shapefile), el tipo de geometría que buscamos (ej. manzanas), y extraerá solo los archivos necesarios, colocándolos ordenadamente en la carpeta que le indiquemos.\n",
        "\n",
        "```python\n",
        "# def extract_shapefile(estados_geo_zip_filenames, zip_directory, output_shp_dir, shape_type_suffix):\n",
        "#     # ... (código que veremos en la siguiente celda) ...\n",
        "```\n",
        "\n",
        "*   **Automatización Inteligente:**\n",
        "    La función buscará los archivos `.shp`, `.shx`, `.dbf`, `.prj` y `.cpg` dentro del ZIP.\n",
        "*   **Manejo del `.cpg`:**\n",
        "    Si el archivo `.cpg` no se encuentra en el ZIP (lo cual es común), la función creará uno con una codificación estándar (como UTF-8 o ISO-8859-1), lo que ayuda a evitar problemas al leer los datos más adelante.\n",
        "*   **Verificación de Existencia:**\n",
        "    Al igual que la función `download`, esta función también verificará si los archivos ya fueron extraídos para no repetir el trabajo innecesariamente.\n",
        "*   **Organización:**\n",
        "    Depositará los archivos extraídos (ej. `09m.shp`, `09m.dbf`, etc.) directamente en la carpeta de salida especificada, listos para ser usados por GeoPandas.\n",
        "\n",
        "**Beneficios de la Extracción Automatizada:**\n",
        "\n",
        "*   **Eficiencia y Precisión:** Evita el tedioso trabajo manual de descomprimir y buscar archivos uno por uno.\n",
        "*   **Consistencia:** Asegura que siempre se extraigan los mismos archivos y de la misma manera.\n",
        "*   **Preparación para el Análisis:** Deja los datos listos para ser cargados y analizados con herramientas como GeoPandas y DuckDB."
      ],
      "metadata": {
        "id": "iRK1MxcPmOqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 4: Función para Extraer Componentes de Shapefiles desde Archivos ZIP\n",
        "# -----------------------------------------------------------------------\n",
        "# Esta función se encarga de abrir un archivo ZIP que contiene datos geoespaciales\n",
        "# del INEGI y extraer los archivos esenciales que componen un Shapefile\n",
        "# (como .shp, .dbf, .shx, .prj y, opcionalmente, .cpg).\n",
        "\n",
        "def extract_shapefile(list_of_zip_filenames, zip_file_directory, target_shp_output_dir, shape_type_suffix):\n",
        "    \"\"\"\n",
        "    Extrae los componentes de un Shapefile (.shp, .shx, .dbf, .prj, .cpg)\n",
        "    desde los archivos ZIP especificados y los guarda en 'target_shp_output_dir'.\n",
        "    Los archivos extraídos se renombran para no incluir la estructura de carpetas del ZIP.\n",
        "    Si el archivo .cpg no existe en el ZIP, se crea uno por defecto con codificación UTF-8.\n",
        "\n",
        "    Args:\n",
        "        list_of_zip_filenames (list): Lista de nombres de archivo ZIP (ej. [\"09_ciudaddemexico.zip\"]).\n",
        "        zip_file_directory (str): Directorio donde se encuentran los archivos ZIP.\n",
        "        target_shp_output_dir (str): Directorio donde se guardarán los archivos Shapefile extraídos.\n",
        "                                     (ej. ./inegi/marco_geoestadistico/shp_extraidos/m/)\n",
        "        shape_type_suffix (str): Sufijo que identifica el tipo de Shapefile en los nombres de archivo\n",
        "                                 dentro del ZIP (ej. \"m\" para manzanas, \"a\" para AGEB).\n",
        "    \"\"\"\n",
        "    # Crear el directorio de salida para los SHP si no existe\n",
        "    os.makedirs(target_shp_output_dir, exist_ok=True)\n",
        "\n",
        "    for zip_filename in list_of_zip_filenames:  # ej: \"09_ciudaddemexico.zip\"\n",
        "        # Obtener el código del estado del nombre del archivo ZIP (ej: \"09\")\n",
        "        # Esto asume el formato \"XX_nombre.zip\" o \"XXnombre.zip\"\n",
        "        if '_' in zip_filename:\n",
        "            state_code = zip_filename.split('_')[0]\n",
        "        else: # Si no hay guion bajo, tomar los primeros caracteres si son dígitos\n",
        "            potential_code = zip_filename[:2] # Asumimos código de 2 dígitos\n",
        "            if potential_code.isdigit():\n",
        "                state_code = potential_code\n",
        "            else: # Si no podemos determinar un código, usamos un placeholder o el nombre base\n",
        "                state_code = os.path.splitext(zip_filename)[0]\n",
        "                print(f\"  Advertencia: No se pudo determinar el código de estado para {zip_filename}. Usando '{state_code}' como base.\")\n",
        "\n",
        "\n",
        "        full_zip_path = os.path.join(zip_file_directory, zip_filename)\n",
        "\n",
        "        if not os.path.exists(full_zip_path):\n",
        "            print(f\"¡ERROR! Archivo ZIP no encontrado: {full_zip_path}. Saltando este archivo.\")\n",
        "            continue\n",
        "\n",
        "        # Definir los nombres base de los archivos Shapefile que esperamos extraer y guardar\n",
        "        # Ejemplo: '09m.shp', '09m.cpg', '09m.dbf', '09m.prj', '09m.shx'\n",
        "        expected_output_basenames = [\n",
        "            f'{state_code}{shape_type_suffix}.shp',\n",
        "            f'{state_code}{shape_type_suffix}.cpg',\n",
        "            f'{state_code}{shape_type_suffix}.dbf',\n",
        "            f'{state_code}{shape_type_suffix}.prj',\n",
        "            f'{state_code}{shape_type_suffix}.shx'\n",
        "        ]\n",
        "\n",
        "        # Rutas completas donde se guardarán los archivos extraídos\n",
        "        expected_output_filepaths = [os.path.join(target_shp_output_dir, basename) for basename in expected_output_basenames]\n",
        "\n",
        "        # Nombres/rutas de los archivos TAL COMO ESTÁN DENTRO DEL ZIP\n",
        "        # Comúnmente, el INEGI los tiene dentro de una carpeta 'conjunto_de_datos/'\n",
        "        # Ejemplo: 'conjunto_de_datos/09m.shp'\n",
        "        paths_in_zip = [f'conjunto_de_datos/{basename}' for basename in expected_output_basenames]\n",
        "\n",
        "        # 1. Verificar si TODOS los archivos finales ya existen para evitar re-extraer\n",
        "        if all(os.path.exists(filepath) for filepath in expected_output_filepaths):\n",
        "            print(f\"Todos los archivos Shapefile para '{state_code}{shape_type_suffix}' \"\n",
        "                  f\"ya existen en '{target_shp_output_dir}'. No se extraen de nuevo.\")\n",
        "            continue # Pasar al siguiente archivo ZIP en la lista\n",
        "\n",
        "        print(f\"\\nProcesando extracción de Shapefiles para '{state_code}{shape_type_suffix}' de '{zip_filename}'...\")\n",
        "\n",
        "        # 2. Abrir el archivo ZIP\n",
        "        try:\n",
        "            with ZipFile(full_zip_path, 'r') as zip_ref:\n",
        "                # Iterar sobre cada uno de los componentes del Shapefile que necesitamos\n",
        "                for path_in_zip_archive, target_output_filepath, output_basename in zip(paths_in_zip, expected_output_filepaths, expected_output_basenames):\n",
        "                    # Verificar si este archivo específico ya existe\n",
        "                    if os.path.exists(target_output_filepath):\n",
        "                        print(f\"  Archivo '{output_basename}' ya existe. Saltando.\")\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        # Intentar extraer el archivo del ZIP a su ruta de destino\n",
        "                        # zip_ref.open() abre un miembro del ZIP como un archivo binario\n",
        "                        with zip_ref.open(path_in_zip_archive) as source_file:\n",
        "                            # Abrir el archivo de destino en modo escritura binaria\n",
        "                            with open(target_output_filepath, 'wb') as target_file:\n",
        "                                # Copiar el contenido del archivo en el ZIP al archivo de destino\n",
        "                                shutil.copyfileobj(source_file, target_file)\n",
        "                        print(f\"  Extraído: '{output_basename}' a '{target_output_filepath}'\")\n",
        "                    except KeyError:\n",
        "                        # Si el archivo no se encuentra en el ZIP (KeyError)\n",
        "                        if output_basename.endswith('.cpg'):\n",
        "                            # El archivo .cpg es opcional. Si no está, lo creamos con una codificación por defecto.\n",
        "                            try:\n",
        "                                with open(target_output_filepath, 'w') as cpg_file:\n",
        "                                    cpg_file.write(\"ISO-8859-1\")\n",
        "                                print(f\"  ADVERTENCIA: '{output_basename}' no encontrado en el ZIP. \"\n",
        "                                      f\"Se creó '{target_output_filepath}' con codificación UTF-8.\")\n",
        "                            except Exception as e_cpg:\n",
        "                                print(f\"  ERROR al crear archivo .cpg por defecto '{target_output_filepath}': {e_cpg}\")\n",
        "\n",
        "                        else:\n",
        "                            # Si falta cualquier otro archivo esencial (.shp, .dbf, .shx, .prj), es un problema.\n",
        "                            print(f\"  ¡ERROR CRÍTICO! Archivo Shapefile esencial '{path_in_zip_archive}' \"\n",
        "                                  f\"no encontrado en '{zip_filename}'. Este componente es necesario.\")\n",
        "                            # Podríamos querer eliminar los archivos ya extraídos para este shapefile\n",
        "                            # si uno esencial falta, para evitar un shapefile incompleto.\n",
        "                            # Por simplicidad elemental, solo se reporta el error.\n",
        "                    except Exception as e_extract:\n",
        "                        print(f\"  ERROR inesperado al extraer '{path_in_zip_archive}' de '{zip_filename}': {e_extract}\")\n",
        "            print(f\"Extracción para '{state_code}{shape_type_suffix}' completada.\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "             print(f\"¡ERROR! Archivo ZIP no encontrado en la ruta: {full_zip_path}\")\n",
        "        except Exception as e_zip:\n",
        "            print(f\"Ocurrió un error general al procesar el archivo ZIP '{zip_filename}': {e_zip}\")\n",
        "\n",
        "\n",
        "# --- Ejemplo de uso (comentado para no ejecutarlo ahora) ---\n",
        "# if __name__ == '__main__':\n",
        "# # Crear directorios de prueba\n",
        "#     test_zip_dir = \"./temp_zip_storage\"\n",
        "#     test_shp_output_dir_m = \"./temp_shp_output/m\"\n",
        "#     os.makedirs(test_zip_dir, exist_ok=True)\n",
        "#     os.makedirs(test_shp_output_dir_m, exist_ok=True)\n",
        "\n",
        "# # Supongamos que tenemos un archivo ZIP de prueba llamado \"99_estado_prueba.zip\" en test_zip_dir\n",
        "# # y dentro tiene \"conjunto_de_datos/99m.shp\", \"conjunto_de_datos/99m.dbf\", etc.\n",
        "# # Para probar, necesitarías crear manualmente un ZIP de ejemplo.\n",
        "# # Ejemplo: crear un dummy zip\n",
        "#     dummy_zip_path = os.path.join(test_zip_dir, \"99_estado_prueba.zip\")\n",
        "#     with ZipFile(dummy_zip_path, 'w') as zf:\n",
        "#         zf.writestr(\"conjunto_de_datos/99m.shp\", \"dummy shp content\")\n",
        "#         zf.writestr(\"conjunto_de_datos/99m.dbf\", \"dummy dbf content\")\n",
        "#         zf.writestr(\"conjunto_de_datos/99m.shx\", \"dummy shx content\")\n",
        "#         zf.writestr(\"conjunto_de_datos/99m.prj\", \"dummy prj content\")\n",
        "# # No incluimos el .cpg para probar su creación automática.\n",
        "\n",
        "#     print(\"Iniciando extracción de prueba...\")\n",
        "#     extract_shapefile(\n",
        "#         list_of_zip_filenames=[\"99_estado_prueba.zip\"],\n",
        "#         zip_file_directory=test_zip_dir,\n",
        "#         target_shp_output_dir=test_shp_output_dir_m,\n",
        "#         shape_type_suffix=\"m\"\n",
        "#     )\n",
        "\n",
        "# # Verificar archivos creados\n",
        "#     print(\"\\nArchivos en el directorio de salida:\")\n",
        "#     if os.path.exists(test_shp_output_dir_m):\n",
        "#         for item in os.listdir(test_shp_output_dir_m):\n",
        "#             print(os.path.join(test_shp_output_dir_m, item))\n",
        "\n",
        "# # Limpiar (opcional)\n",
        "# # shutil.rmtree(\"./temp_zip_storage\")\n",
        "# # shutil.rmtree(\"./temp_shp_output\")\n",
        "# # print(\"\\nDirectorios de prueba eliminados.\")"
      ],
      "metadata": {
        "id": "FwxS2L6hed9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Variables, Carpetas y Organización de la Información: La Base de un Proyecto Ordenado**\n",
        "\n",
        "**Concepto Clave: Definir un Espacio de Trabajo Claro y Configurable**\n",
        "\n",
        "Antes de empezar a descargar y procesar datos, es fundamental organizar nuestro espacio de trabajo. Una buena organización desde el inicio nos ahorrará muchos dolores de cabeza, facilitará la reutilización del código y hará que nuestro proyecto sea más comprensible.\n",
        "\n",
        "1.  **Variables de Configuración: Control Centralizado**\n",
        "    *   En lugar de escribir nombres de archivos o códigos de estado directamente en cada parte del código, los definiremos como **variables** al principio. Por ejemplo, si queremos procesar los datos de la Ciudad de México (código \"09\"), crearemos variables como:\n",
        "        ```python\n",
        "        # ESTADO_GEO_ZIP = \"09_ciudaddemexico.zip\"\n",
        "        # CODIGO_ESTADO_STR = \"09\"\n",
        "        ```\n",
        "    *   **¿Por qué es importante?**\n",
        "        Si más adelante queremos procesar otro estado, solo tendremos que cambiar el valor de estas variables en un solo lugar, en vez de buscar y reemplazar en múltiples sitios del código. Esto hace nuestro script más **flexible y fácil de adaptar**.\n",
        "\n",
        "2.  **Rutas de Carpetas: Un Lugar para Cada Cosa**\n",
        "    *   Definiremos variables para las rutas de las carpetas donde guardaremos los diferentes tipos de archivos: los ZIP descargados, los CSV del censo, los Shapefiles extraídos, etc.\n",
        "        ```python\n",
        "        # DIR_BASE_INEGI = \"./inegi\"\n",
        "        # DIR_CENSO_CSV = os.path.join(DIR_BASE_INEGI, \"censo_csv\")\n",
        "        # DIR_MARCO_GEO = os.path.join(DIR_BASE_INEGI, \"marco_geoestadistico\")\n",
        "        ```\n",
        "    *   **¿Por qué es fundamental?**\n",
        "        Mantiene nuestros datos organizados. Sabremos exactamente dónde encontrar los datos crudos, los archivos intermedios y los resultados. Usar `os.path.join` para construir las rutas asegura que funcionen correctamente en cualquier sistema operativo.\n",
        "\n",
        "3.  **Limpieza Previa de Carpetas (Opcional pero Recomendado para Desarrollo):**\n",
        "    *   Para asegurar que cada ejecución del script comience desde un \"estado limpio\", podemos optar por eliminar las carpetas de datos generadas en ejecuciones anteriores. Esto es especialmente útil durante el desarrollo y las pruebas para evitar usar archivos obsoletos o resultados parciales de una corrida anterior.\n",
        "    *   Usaremos `shutil.rmtree(ruta_de_carpeta)` para eliminar una carpeta y todo su contenido. **¡Cuidado! Esta operación es irreversible.**\n",
        "    *   **¿Por qué hacerlo?**\n",
        "        *   Garantiza que los resultados se basen únicamente en la ejecución actual del script.\n",
        "        *   Evita inconsistencias debidas a archivos residuales de ejecuciones previas.\n",
        "        *   Asegura un punto de partida reproducible cada vez que corremos el proceso.\n",
        "\n",
        "4.  **Creación de Carpetas:**\n",
        "    *   Después de definir las rutas (y opcionalmente limpiar las viejas), nos aseguraremos de que todas las carpetas necesarias existan antes de intentar guardar archivos en ellas.\n",
        "    *   Usaremos `os.makedirs(ruta_de_carpeta, exist_ok=True)`. El argumento `exist_ok=True` es muy útil porque evita que el programa lance un error si la carpeta ya existe.\n",
        "\n",
        "En la siguiente celda de código, pondremos en práctica estos principios: definiremos nuestras variables de configuración, estableceremos las rutas para nuestros datos y prepararemos la estructura de carpetas. Esta base organizada es crucial para un flujo de trabajo de datos eficiente y confiable."
      ],
      "metadata": {
        "id": "-X-kMN19ndms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5: Definición de Variables de Configuración y Organización de Carpetas\n",
        "# ---------------------------------------------------------------------------\n",
        "# En esta celda, establecemos las variables clave que controlarán qué datos\n",
        "# procesamos y dónde los almacenamos. También preparamos la estructura\n",
        "# de carpetas necesaria para nuestro proyecto.\n",
        "\n",
        "# --- 1. Variables de Configuración del Estado a Procesar ---\n",
        "# Para este ejercicio, nos centraremos en un solo estado.\n",
        "# Modifica estas variables si deseas procesar un estado diferente.\n",
        "# Asegúrate de que los nombres de archivo y códigos coincidan con los\n",
        "# proporcionados por el INEGI.\n",
        "\n",
        "NOMBRE_ESTADO = \"Ciudad de Mexico\" # Nombre descriptivo del estado\n",
        "CODIGO_ESTADO_NUM = 9             # Código numérico del estado (ej. 9 para CDMX)\n",
        "CODIGO_ESTADO_STR = f\"{CODIGO_ESTADO_NUM:02d}\" # Código como string con padding (ej. \"09\")\n",
        "\n",
        "# Nombre del archivo ZIP del Marco Geoestadístico (Shapefiles)\n",
        "# Ejemplo: \"09_ciudaddemexico.zip\". Ajusta si el INEGI cambia el patrón de nombres.\n",
        "# Usaremos una f-string por si el nombre del zip varía con el código o nombre.\n",
        "ESTADO_GEO_ZIP_BASENAME = f\"{CODIGO_ESTADO_STR}_ciudaddemexico\" # Parte base del nombre\n",
        "ESTADO_GEO_ZIP_FILENAME = f\"{ESTADO_GEO_ZIP_BASENAME}.zip\"\n",
        "\n",
        "# Sufijo para el tipo de Shapefile a extraer (ej. 'm' para manzanas)\n",
        "TIPO_SHAPEFILE_MANZANAS = \"m\"\n",
        "\n",
        "print(f\"--- Configuración para el Estado: {NOMBRE_ESTADO} (Código: {CODIGO_ESTADO_STR}) ---\")\n",
        "print(f\"Archivo ZIP del Marco Geoestadístico a buscar: {ESTADO_GEO_ZIP_FILENAME}\")\n",
        "print(f\"Tipo de Shapefile a extraer: Manzanas (sufijo '{TIPO_SHAPEFILE_MANZANAS}')\")\n",
        "\n",
        "# --- 2. Definición de Rutas de Carpetas ---\n",
        "# Usaremos os.path.join para construir rutas de forma que sean compatibles\n",
        "# con cualquier sistema operativo.\n",
        "\n",
        "# Carpeta raíz para todos los datos de este proyecto INEGI\n",
        "DIR_BASE_INEGI = \"./inegi_data\" # Renombrado para evitar conflicto con el nombre del paquete 'inegi' si existiera\n",
        "\n",
        "# Directorio para los datos del Censo (CSVs)\n",
        "DIR_CENSO_CSV_BASE = os.path.join(DIR_BASE_INEGI, \"censo_poblacion_vivienda_csv\")\n",
        "DIR_CENSO_CSV_DESCARGAS = os.path.join(DIR_CENSO_CSV_BASE, \"descargas_zip\") # Donde se guardan los ZIPs de CSV\n",
        "DIR_CENSO_CSV_EXTRAIDOS = os.path.join(DIR_CENSO_CSV_BASE, \"csv_extraidos\") # Donde se guardan los CSVs extraídos\n",
        "\n",
        "# Directorio para los datos del Marco Geoestadístico (Shapefiles)\n",
        "DIR_MARCO_GEO_BASE = os.path.join(DIR_BASE_INEGI, \"marco_geoestadistico_shp\")\n",
        "DIR_MARCO_GEO_DESCARGAS_ZIP = os.path.join(DIR_MARCO_GEO_BASE, \"descargas_zip\") # Donde se guardan los ZIPs de SHP\n",
        "DIR_MARCO_GEO_SHP_EXTRAIDOS = os.path.join(DIR_MARCO_GEO_BASE, \"shp_extraidos\") # Carpeta base para SHP extraídos\n",
        "\n",
        "# Subdirectorio específico para los Shapefiles de manzanas\n",
        "DIR_SHP_MANZANAS_EXTRAIDOS = os.path.join(DIR_MARCO_GEO_SHP_EXTRAIDOS, TIPO_SHAPEFILE_MANZANAS)\n",
        "\n",
        "# Archivo de la base de datos DuckDB\n",
        "DB_FILENAME = \"inegi_analisis.duckdb\"\n",
        "DB_FILE_PATH = os.path.join(DIR_BASE_INEGI, DB_FILENAME)\n",
        "\n",
        "print(f\"\\n--- Rutas de Carpetas Definidas ---\")\n",
        "print(f\"Directorio Base del Proyecto: {os.path.abspath(DIR_BASE_INEGI)}\")\n",
        "print(f\"  CSVs (Descargas ZIP): {os.path.abspath(DIR_CENSO_CSV_DESCARGAS)}\")\n",
        "print(f\"  CSVs (Extraídos): {os.path.abspath(DIR_CENSO_CSV_EXTRAIDOS)}\")\n",
        "print(f\"  Shapefiles (Descargas ZIP): {os.path.abspath(DIR_MARCO_GEO_DESCARGAS_ZIP)}\")\n",
        "print(f\"  Shapefiles Manzanas (Extraídos): {os.path.abspath(DIR_SHP_MANZANAS_EXTRAIDOS)}\")\n",
        "print(f\"  Archivo Base de Datos DuckDB: {os.path.abspath(DB_FILE_PATH)}\")\n",
        "\n",
        "\n",
        "# --- 3. Limpieza Opcional de Directorios Existentes ---\n",
        "# ADVERTENCIA: Las siguientes líneas eliminarán las carpetas y TODO su contenido\n",
        "# si ya existen. Esto es útil para asegurar un inicio limpio en cada ejecución\n",
        "# durante el desarrollo. Comenta estas líneas si quieres conservar los datos\n",
        "# descargados y procesados entre ejecuciones.\n",
        "\n",
        "LIMPIAR_DIRECTORIOS_ANTES_DE_EJECUTAR = True # Cambia a False para no limpiar\n",
        "\n",
        "if LIMPIAR_DIRECTORIOS_ANTES_DE_EJECUTAR:\n",
        "    print(\"\\n--- Limpieza de Directorios (si existen) ---\")\n",
        "    # Lista de directorios base que, si se eliminan, eliminan su contenido (subdirectorios)\n",
        "    directorios_a_limpiar_base = [DIR_CENSO_CSV_BASE, DIR_MARCO_GEO_BASE]\n",
        "    # También el archivo de la base de datos\n",
        "    if os.path.exists(DB_FILE_PATH):\n",
        "        print(f\"Eliminando archivo de base de datos existente: {DB_FILE_PATH}\")\n",
        "        try:\n",
        "            os.remove(DB_FILE_PATH)\n",
        "        except Exception as e:\n",
        "            print(f\"  No se pudo eliminar {DB_FILE_PATH}: {e}\")\n",
        "\n",
        "\n",
        "    for directorio_base in directorios_a_limpiar_base:\n",
        "        if os.path.exists(directorio_base):\n",
        "            print(f\"Eliminando directorio base existente y su contenido: {directorio_base}\")\n",
        "            try:\n",
        "                shutil.rmtree(directorio_base)\n",
        "            except Exception as e:\n",
        "                print(f\"  No se pudo eliminar {directorio_base}: {e}\")\n",
        "        else:\n",
        "            print(f\"Directorio base {directorio_base} no existe, no se necesita limpieza.\")\n",
        "else:\n",
        "    print(\"\\n--- Limpieza de Directorios Omitida ---\")\n",
        "\n",
        "# --- 4. Creación de la Estructura de Carpetas Necesaria ---\n",
        "# Usamos os.makedirs con exist_ok=True para crear las carpetas.\n",
        "# Esto no dará error si las carpetas ya existen.\n",
        "\n",
        "print(\"\\n--- Creación de Estructura de Carpetas Necesarias ---\")\n",
        "directorios_a_crear = [\n",
        "    DIR_BASE_INEGI, # Asegurar que la raíz exista\n",
        "    DIR_CENSO_CSV_DESCARGAS,\n",
        "    DIR_CENSO_CSV_EXTRAIDOS,\n",
        "    DIR_MARCO_GEO_DESCARGAS_ZIP,\n",
        "    # DIR_MARCO_GEO_SHP_EXTRAIDOS, # Se creará implícitamente al crear la de manzanas\n",
        "    DIR_SHP_MANZANAS_EXTRAIDOS\n",
        "]\n",
        "\n",
        "for directorio in directorios_a_crear:\n",
        "    try:\n",
        "        os.makedirs(directorio, exist_ok=True)\n",
        "        print(f\"Directorio asegurado/creado: {directorio}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al crear directorio {directorio}: {e}. Verifica permisos o ruta.\")\n",
        "        # Si un directorio crucial no se puede crear, el script podría fallar más adelante.\n",
        "\n",
        "print(\"\\n--- Configuración de variables y carpetas completada. ---\")"
      ],
      "metadata": {
        "id": "i2ybWEfGndeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DuckDB + Spatial: Tu Base de Datos Analítica Embebida y Geoespacial**\n",
        "\n",
        "**Concepto Clave: Una Base de Datos Potente y Sencilla para tus Análisis**\n",
        "\n",
        "1.  **¿Qué es DuckDB y por qué es tan útil aquí?**\n",
        "    *   **DuckDB** es un sistema de gestión de bases de datos (como PostgreSQL o MySQL) pero con características que lo hacen ideal para el análisis de datos y, especialmente, para proyectos como el nuestro:\n",
        "        *   **Analítico:** Está optimizado para consultas complejas que involucran agregaciones, uniones (joins) y análisis sobre grandes volúmenes de datos, que es justo lo que haremos.\n",
        "        *   **Embebido (o \"en proceso\"):** ¡Esta es la gran ventaja! No necesitas instalar ni configurar un servidor de base de datos separado. DuckDB funciona directamente dentro de tu aplicación Python y guarda toda la base de datos en un **único archivo** en tu computadora (por ejemplo, `inegi_analisis.duckdb`). Esto lo hace increíblemente fácil de usar y transportar.\n",
        "        *   **Rápido:** Utiliza técnicas modernas como el procesamiento columnar y la vectorización de consultas para ser muy veloz.\n",
        "        *   **Amigable con SQL:** Puedes usar el lenguaje SQL estándar que quizás ya conozcas para interactuar con tus datos.\n",
        "\n",
        "2.  **La Extensión `spatial`: DuckDB Entiende de Mapas**\n",
        "    *   Por sí solo, DuckDB maneja datos tabulares (filas y columnas). Pero, ¡puede hacer más! Podemos cargar **extensiones** para añadirle nuevas funcionalidades.\n",
        "    *   La extensión **`spatial`** le da a DuckDB superpoderes para trabajar con **datos geoespaciales**. Una vez cargada, DuckDB puede:\n",
        "        *   Almacenar geometrías (puntos, líneas, polígonos) en columnas especiales.\n",
        "        *   Leer formatos de archivo geoespaciales como GeoParquet.\n",
        "        *   Ejecutar funciones espaciales directamente en SQL (por ejemplo, calcular áreas, intersecciones, distancias, etc.).\n",
        "    *   En el código, verás estas líneas:\n",
        "        ```python\n",
        "        # con.execute(\"INSTALL spatial;\") # Descarga e instala la extensión (solo una vez)\n",
        "        # con.execute(\"LOAD spatial;\")   # Carga la extensión en la sesión actual\n",
        "        ```\n",
        "        El `INSTALL` podría necesitar conexión a internet la primera vez que se ejecuta en un entorno nuevo. `LOAD` se necesita en cada sesión que vaya a usar las funciones espaciales.\n",
        "\n",
        "3.  **Creando la Conexión y el Archivo de Base de Datos**\n",
        "    *   Nos conectaremos a DuckDB especificando la ruta al archivo que contendrá nuestra base de datos:\n",
        "        ```python\n",
        "        # DB_FILE_PATH = os.path.join(DIR_BASE_INEGI, \"inegi_analisis.duckdb\")\n",
        "        # con = duckdb.connect(database=DB_FILE_PATH)\n",
        "        ```\n",
        "    *   Si el archivo `inegi_analisis.duckdb` no existe, DuckDB lo creará automáticamente. ¡Así de simple!\n",
        "\n",
        "4.  **Ventajas de Usar DuckDB en este Proyecto:**\n",
        "    *   **Simplicidad:** Fácil de instalar (`pip install duckdb`) y de usar (un solo archivo).\n",
        "    *   **Velocidad:** Excelente rendimiento para las consultas analíticas y espaciales que haremos.\n",
        "    *   **Integración Geoespacial:** La extensión `spatial` nos permite manejar los datos del censo y los mapas en un mismo lugar y con un mismo lenguaje (SQL).\n",
        "    *   **Portabilidad:** Puedes copiar el archivo `.duckdb` a otra máquina y seguir trabajando con tus datos fácilmente.\n",
        "\n",
        "DuckDB será el corazón de nuestro sistema de análisis, donde cargaremos, transformaremos y uniremos los datos censales tabulares con la información geográfica de los mapas."
      ],
      "metadata": {
        "id": "eQMaDI_1op7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 6: Conexión a DuckDB e Instalación/Carga de la Extensión Espacial\n",
        "# --------------------------------------------------------------------\n",
        "# En esta celda, establecemos la conexión a nuestra base de datos DuckDB.\n",
        "# DuckDB es una base de datos analítica embebida, lo que significa que\n",
        "# se ejecuta dentro de nuestro script y almacena los datos en un único archivo.\n",
        "# También instalaremos (si es necesario) y cargaremos la extensión 'spatial',\n",
        "# que permite a DuckDB trabajar con datos y funciones geoespaciales.\n",
        "\n",
        "# La ruta al archivo de la base de datos fue definida en la celda anterior\n",
        "# como DB_FILE_PATH (ej. ./inegi_data/inegi_analisis.duckdb)\n",
        "\n",
        "print(f\"--- Configuración de DuckDB ---\")\n",
        "\n",
        "# Opcional: Verificar si el archivo de la base de datos ya existe.\n",
        "# La limpieza general de directorios (si está activada en la celda anterior)\n",
        "# ya debería haber eliminado un archivo DB preexistente.\n",
        "if os.path.exists(DB_FILE_PATH):\n",
        "    print(f\"Archivo de base de datos ya existe en: {DB_FILE_PATH}\")\n",
        "    # Podríamos optar por eliminarlo aquí de nuevo si queremos asegurar una BD fresca\n",
        "    # independientemente de la limpieza general, pero usualmente no es necesario si la celda anterior lo hizo.\n",
        "    # os.remove(DB_FILE_PATH)\n",
        "    # print(f\"Base de datos preexistente eliminada.\")\n",
        "else:\n",
        "    print(f\"Archivo de base de datos no encontrado. Se creará en: {DB_FILE_PATH}\")\n",
        "\n",
        "# 1. Conectar a DuckDB\n",
        "# Se creará el archivo de base de datos si no existe.\n",
        "# 'read_only=False' permite realizar escrituras y modificaciones.\n",
        "print(f\"Conectando a la base de datos DuckDB en: '{DB_FILE_PATH}'...\")\n",
        "try:\n",
        "    con = duckdb.connect(database=DB_FILE_PATH, read_only=False)\n",
        "    print(\"Conexión a DuckDB establecida exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"¡ERROR CRÍTICO al conectar con DuckDB!: {e}\")\n",
        "    print(\"El script no puede continuar sin una conexión a la base de datos.\")\n",
        "    # Podríamos detener el script aquí si la conexión falla.\n",
        "    raise  # Re-lanzar la excepción para detener la ejecución.\n",
        "\n",
        "# 2. Instalar y Cargar la Extensión Espacial ('spatial')\n",
        "# INSTALL: Descarga e instala la extensión. Solo es realmente necesario una vez\n",
        "#          por instalación de DuckDB o si la extensión no está presente.\n",
        "#          DuckDB es suficientemente inteligente para no reinstalar si ya existe.\n",
        "#          Puede requerir conexión a internet la primera vez.\n",
        "# LOAD: Activa la extensión para la conexión actual. Necesario en cada sesión\n",
        "#       que vaya a utilizar funcionalidades espaciales.\n",
        "\n",
        "print(\"\\nInstalando (si es necesario) y cargando la extensión 'spatial' de DuckDB...\")\n",
        "try:\n",
        "    con.execute(\"INSTALL spatial;\")\n",
        "    con.execute(\"LOAD spatial;\")\n",
        "    print(\"Extensión 'spatial' de DuckDB instalada y cargada correctamente.\")\n",
        "    print(\"DuckDB ahora tiene capacidades geoespaciales.\")\n",
        "\n",
        "    # Opcional: Verificar si la extensión está activa (para depuración)\n",
        "    # extensions_df = con.execute(\"SELECT * FROM duckdb_extensions();\").fetchdf()\n",
        "    # spatial_loaded = extensions_df[extensions_df['name'] == 'spatial']['loaded'].iloc[0]\n",
        "    # print(f\"Estado de la extensión 'spatial' (cargada): {spatial_loaded}\")\n",
        "\n",
        "except duckdb.IOException as e:\n",
        "    print(f\"¡ERROR DE ENTRADA/SALIDA (IOException) al instalar/cargar la extensión 'spatial'!: {e}\")\n",
        "    print(\"Esto puede ocurrir si no hay conexión a internet para descargar la extensión la primera vez,\")\n",
        "    print(\"o si hay problemas de permisos para escribir en el directorio de extensiones de DuckDB.\")\n",
        "    print(\"Las funcionalidades geoespaciales NO estarán disponibles.\")\n",
        "    print(\"Por favor, verifica tu conexión a internet y/o los permisos del directorio de extensiones de DuckDB.\")\n",
        "    # Considerar si el script debe detenerse aquí si la extensión es crucial.\n",
        "    # Para un script elemental, podemos dejar que falle más adelante si se intenta usar una función espacial.\n",
        "    # raise # Descomentar para detener el script si la extensión espacial es indispensable.\n",
        "except Exception as e:\n",
        "    print(f\"¡ERROR GENERAL al instalar/cargar la extensión 'spatial'!: {e}\")\n",
        "    print(\"Las funcionalidades geoespaciales podrían no estar disponibles.\")\n",
        "    # raise # Descomentar para detener el script.\n",
        "\n",
        "print(\"\\n--- Configuración de DuckDB completada. ---\")"
      ],
      "metadata": {
        "id": "YIn1aXa8opfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "337cp-KKsiJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 7: Descarga y Extracción del Archivo CSV con Datos Censales\n",
        "# -----------------------------------------------------------------\n",
        "# En esta celda, vamos a descargar el archivo ZIP que contiene los datos\n",
        "# censales (en formato CSV) para el estado que configuramos anteriormente.\n",
        "# Luego, extraeremos específicamente el archivo CSV que necesitamos.\n",
        "\n",
        "print(f\"--- Iniciando Proceso de Descarga y Extracción de CSV para el Estado: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "# --- 1. Definición de URLs y Nombres de Archivo para el CSV del Censo ---\n",
        "\n",
        "# URL base donde el INEGI almacena los datos abiertos del Censo de Población y Vivienda 2020\n",
        "# para AGEB y Manzana Urbana.\n",
        "URL_BASE_CENSO_CSV_INEGI = \"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/datosabiertos/ageb_manzana/\"\n",
        "\n",
        "# Nombre del archivo ZIP específico para nuestro estado.\n",
        "# El patrón es \"ageb_mza_urbana_[CODIGO_ESTADO]_cpv2020_csv.zip\"\n",
        "NOMBRE_ZIP_CENSO = f\"ageb_mza_urbana_{CODIGO_ESTADO_STR}_cpv2020_csv.zip\"\n",
        "URL_COMPLETA_CENSO_CSV_ZIP = f\"{URL_BASE_CENSO_CSV_INEGI}{NOMBRE_ZIP_CENSO}\"\n",
        "\n",
        "# Ruta completa donde se guardará el archivo ZIP descargado.\n",
        "# Usamos el directorio definido en la Celda 5: DIR_CENSO_CSV_DESCARGAS\n",
        "RUTA_DESCARGA_ZIP_CENSO = os.path.join(DIR_CENSO_CSV_DESCARGAS, NOMBRE_ZIP_CENSO)\n",
        "\n",
        "# Información sobre el archivo CSV DENTRO del ZIP:\n",
        "# El INEGI suele colocar los CSV dentro de una estructura de carpetas.\n",
        "# Debemos especificar la ruta interna completa del CSV que queremos.\n",
        "# Estructura típica: \"ageb_mza_urbana_[CODIGO_ESTADO]_cpv2020/conjunto_de_datos/conjunto_de_datos_ageb_urbana_[CODIGO_ESTADO]_cpv2020.csv\"\n",
        "CARPETA_RAIZ_EN_ZIP_CENSO = f\"ageb_mza_urbana_{CODIGO_ESTADO_STR}_cpv2020\"\n",
        "SUBPATH_CSV_EN_ZIP_CENSO = \"conjunto_de_datos\"\n",
        "NOMBRE_CSV_ORIGINAL_EN_ZIP = f\"conjunto_de_datos_ageb_urbana_{CODIGO_ESTADO_STR}_cpv2020.csv\"\n",
        "\n",
        "PATH_COMPLETO_CSV_DENTRO_DEL_ZIP = os.path.join(CARPETA_RAIZ_EN_ZIP_CENSO,\n",
        "                                               SUBPATH_CSV_EN_ZIP_CENSO,\n",
        "                                               NOMBRE_CSV_ORIGINAL_EN_ZIP)\n",
        "\n",
        "# Nombre y ruta final para el archivo CSV una vez extraído.\n",
        "# Lo guardaremos directamente en DIR_CENSO_CSV_EXTRAIDOS con un nombre más simple.\n",
        "NOMBRE_CSV_FINAL_EXTRAIDO = f\"censo_manzanas_urbanas_{CODIGO_ESTADO_STR}_cpv2020.csv\"\n",
        "RUTA_FINAL_CSV_EXTRAIDO = os.path.join(DIR_CENSO_CSV_EXTRAIDOS, NOMBRE_CSV_FINAL_EXTRAIDO)\n",
        "\n",
        "print(f\"URL para descarga del ZIP del censo: {URL_COMPLETA_CENSO_CSV_ZIP}\")\n",
        "print(f\"Ruta de descarga del ZIP: {RUTA_DESCARGA_ZIP_CENSO}\")\n",
        "print(f\"Ruta del CSV dentro del ZIP: {PATH_COMPLETO_CSV_DENTRO_DEL_ZIP}\")\n",
        "print(f\"Ruta final del CSV extraído: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "\n",
        "# --- 2. Descarga del Archivo ZIP del Censo ---\n",
        "# Verificamos si el ZIP ya existe antes de intentar descargarlo.\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_CENSO):\n",
        "    print(f\"\\nDescargando '{NOMBRE_ZIP_CENSO}'...\")\n",
        "    # Usamos la función 'download' definida en la Celda 3.\n",
        "    # La función 'download' ya maneja errores HTTP y la barra de progreso.\n",
        "    try:\n",
        "        download(URL_COMPLETA_CENSO_CSV_ZIP, DIR_CENSO_CSV_DESCARGAS)\n",
        "    except Exception as e:\n",
        "        print(f\"  La descarga del ZIP del censo falló. El error fue: {e}\")\n",
        "        print(f\"  No se puede continuar con la extracción del CSV sin el archivo ZIP.\")\n",
        "        # En un flujo elemental, podríamos dejar que el script termine aquí o falle en el siguiente paso.\n",
        "        # Por ahora, imprimimos el error y el script intentará continuar (y probablemente fallará si el ZIP es necesario).\n",
        "else:\n",
        "    print(f\"\\nEl archivo ZIP '{NOMBRE_ZIP_CENSO}' ya existe en '{DIR_CENSO_CSV_DESCARGAS}'. No se descarga de nuevo.\")\n",
        "\n",
        "# --- 3. Extracción del Archivo CSV Específico del ZIP ---\n",
        "# Verificamos si el CSV final ya existe antes de intentar extraerlo.\n",
        "if not os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"\\nExtrayendo '{NOMBRE_CSV_ORIGINAL_EN_ZIP}' de '{NOMBRE_ZIP_CENSO}'...\")\n",
        "\n",
        "    # Primero, nos aseguramos de que el archivo ZIP exista (pudo haber fallado la descarga)\n",
        "    if not os.path.exists(RUTA_DESCARGA_ZIP_CENSO):\n",
        "        print(f\"  ¡ERROR! No se encontró el archivo ZIP '{RUTA_DESCARGA_ZIP_CENSO}'. \"\n",
        "              f\"No se puede extraer el CSV.\")\n",
        "    else:\n",
        "        try:\n",
        "            # Abrir el archivo ZIP en modo lectura ('r')\n",
        "            with ZipFile(RUTA_DESCARGA_ZIP_CENSO, 'r') as zip_ref:\n",
        "                # Intentar abrir el archivo CSV específico DENTRO del ZIP\n",
        "                with zip_ref.open(PATH_COMPLETO_CSV_DENTRO_DEL_ZIP) as source_csv_in_zip:\n",
        "                    # Abrir el archivo de destino donde guardaremos el CSV extraído, en modo escritura binaria ('wb')\n",
        "                    with open(RUTA_FINAL_CSV_EXTRAIDO, 'wb') as target_csv_file:\n",
        "                        # Copiar el contenido del archivo CSV desde el ZIP al archivo de destino\n",
        "                        shutil.copyfileobj(source_csv_in_zip, target_csv_file)\n",
        "            print(f\"  Archivo CSV extraído exitosamente a: '{RUTA_FINAL_CSV_EXTRAIDO}'\")\n",
        "        except KeyError:\n",
        "            # Esto ocurre si PATH_COMPLETO_CSV_DENTRO_DEL_ZIP no se encuentra en el archivo ZIP.\n",
        "            print(f\"  ¡ERROR! No se encontró la ruta del archivo CSV '{PATH_COMPLETO_CSV_DENTRO_DEL_ZIP}' \"\n",
        "                  f\"dentro del archivo ZIP '{NOMBRE_ZIP_CENSO}'.\")\n",
        "            print(f\"  Verifica los nombres y la estructura interna del ZIP del INEGI.\")\n",
        "        except FileNotFoundError: # Podría ocurrir si RUTA_DESCARGA_ZIP_CENSO se eliminó entre la comprobación y el uso.\n",
        "             print(f\"  ¡ERROR! El archivo ZIP '{RUTA_DESCARGA_ZIP_CENSO}' desapareció antes de la extracción.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ¡ERROR! Ocurrió un error inesperado durante la extracción del CSV: {e}\")\n",
        "else:\n",
        "    print(f\"\\nEl archivo CSV '{NOMBRE_CSV_FINAL_EXTRAIDO}' ya existe en '{DIR_CENSO_CSV_EXTRAIDOS}'. \"\n",
        "          f\"No se extrae de nuevo.\")\n",
        "\n",
        "print(\"\\n--- Proceso de Descarga y Extracción de CSV completado (o intentado). ---\")\n",
        "\n",
        "# Verificar si el archivo CSV final existe después de todo el proceso\n",
        "if os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"Confirmado: El archivo CSV está listo en: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: El archivo CSV final NO se encuentra en: {RUTA_FINAL_CSV_EXTRAIDO}. \"\n",
        "          f\"Revisa los mensajes de error anteriores.\")"
      ],
      "metadata": {
        "id": "vfbpx-A6siQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creando la Tabla `censo_all` en DuckDB: Consolidando los Datos Censales**\n",
        "\n",
        "**Concepto Clave: Transformar el Archivo CSV en una Tabla de Base de Datos Eficiente para el Análisis**\n",
        "\n",
        "Una vez que tenemos el archivo CSV con los datos censales descargado y extraído, el siguiente paso es cargarlo en nuestra base de datos DuckDB. Almacenar estos datos en una tabla de DuckDB nos ofrece varias ventajas sobre trabajar directamente con el archivo CSV:\n",
        "\n",
        "*   **Consultas Rápidas y Flexibles:** Podremos usar el lenguaje SQL para filtrar, agrupar, unir y analizar los datos de manera mucho más potente y eficiente.\n",
        "*   **Manejo Eficiente de Tipos de Datos:** DuckDB puede inferir o permitirnos definir los tipos de datos correctos para cada columna (números, texto, fechas, etc.), lo que es crucial para análisis precisos.\n",
        "*   **Integración con Datos Espaciales:** Más adelante, podremos unir fácilmente esta tabla de datos censales con nuestras tablas de datos geoespaciales (mapas) directamente dentro de DuckDB.\n",
        "*   **Menor Uso de Memoria (en algunos casos):** Para operaciones complejas, DuckDB puede optimizar cómo accede a los datos, a menudo siendo más eficiente que cargar un CSV gigante completamente en la memoria de Python con Pandas para cada operación.\n",
        "\n",
        "**El Proceso de Creación de la Tabla `censo_all`:**\n",
        "\n",
        "1.  **`DROP TABLE IF EXISTS censo_all;`**\n",
        "    *   Antes de crear la tabla, es una buena práctica incluir esta instrucción. Si la tabla `censo_all` ya existe de una ejecución anterior del script, se eliminará. Esto asegura que siempre empecemos con una tabla limpia y evitemos errores o datos duplicados.\n",
        "\n",
        "2.  **`CREATE TABLE censo_all AS SELECT ... FROM read_csv_auto(...);`**\n",
        "    *   Esta es la instrucción SQL principal que usaremos. Desglosemos sus partes:\n",
        "        *   **`CREATE TABLE censo_all AS ...`**: Le dice a DuckDB que cree una nueva tabla llamada `censo_all`. El `AS` indica que la estructura y los datos de la tabla se definirán por el resultado de la consulta que sigue (`SELECT ...`).\n",
        "        *   **`SELECT * FROM read_csv_auto('ruta_al_csv.csv', ...)`**: Esta es la parte mágica.\n",
        "            *   `read_csv_auto()`: Es una función muy potente de DuckDB que lee un archivo CSV. \"Auto\" significa que intentará inferir automáticamente los nombres de las columnas (si tiene encabezado), los tipos de datos de cada columna, y el delimitador (usualmente comas).\n",
        "            *   `'ruta_al_csv.csv'`: Aquí especificaremos la ruta al archivo CSV que extrajimos en el paso anterior (`RUTA_FINAL_CSV_EXTRAIDO`).\n",
        "            *   **Parámetros importantes de `read_csv_auto`:**\n",
        "                *   `NULLSTR=['N/A','N/D','*','']`: Le dice a DuckDB qué cadenas de texto en el CSV deben interpretarse como valores nulos (datos faltantes). El INEGI a menudo usa `*`, `N/D` o `N/A`. Incluir `''` (cadena vacía) también es buena idea.\n",
        "                *   `SAMPLE_SIZE=-1`: Instruye a DuckDB a leer el archivo CSV completo para inferir los tipos de datos. Esto es más preciso que solo tomar una muestra pequeña, especialmente si hay valores atípicos o columnas con muchos nulos al principio.\n",
        "                *   `HEADER=TRUE`: Indica que la primera fila del CSV contiene los nombres de las columnas.\n",
        "            *   `SELECT *`: Selecciona todas las columnas del archivo CSV leído.\n",
        "        *   **`WHERE MZA != '0'` (Opcional pero común):**\n",
        "            *   Los datos del INEGI a veces incluyen registros a nivel de AGEB (donde el código de manzana `MZA` podría ser '0' o '000') además de los registros por manzana. Si solo nos interesan los datos a nivel de manzana individual, este filtro nos ayuda a seleccionar solo esos registros.\n",
        "\n",
        "3.  **Transacciones (`BEGIN TRANSACTION;` / `COMMIT;` / `ROLLBACK;`) - Simplificado:**\n",
        "    *   Para operaciones que modifican la base de datos (como crear tablas e insertar datos), es buena práctica envolverlas en una **transacción**.\n",
        "    *   `BEGIN TRANSACTION;`: Inicia una transacción.\n",
        "    *   `COMMIT;`: Si todas las operaciones dentro de la transacción son exitosas, `COMMIT` guarda los cambios permanentemente.\n",
        "    *   `ROLLBACK;`: Si ocurre un error, `ROLLBACK` deshace todos los cambios realizados desde el `BEGIN TRANSACTION;`, dejando la base de datos en el estado en que estaba antes.\n",
        "    *   Para una sola instrucción `CREATE TABLE AS SELECT`, DuckDB a menudo la maneja de forma atómica. Sin embargo, si tuviéramos múltiples pasos de inserción o modificación, las transacciones explícitas serían más críticas. Por simplicidad \"elemental\", podríamos confiar en el comportamiento transaccional por defecto de DuckDB para una sola instrucción, o incluir un `try-except` básico que haga `ROLLBACK` en caso de error.\n",
        "\n",
        "Al final de este paso, los datos del censo que estaban en un archivo CSV \"plano\" estarán estructurados, tipificados y almacenados eficientemente en la tabla `censo_all` dentro de nuestra base de datos DuckDB, listos para ser consultados y combinados con nuestros datos geoespaciales."
      ],
      "metadata": {
        "id": "tn9z4ii6uGKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8: Cargar el CSV de Datos Censales a una Tabla en DuckDB\n",
        "# -------------------------------------------------------------\n",
        "# Ahora que tenemos el archivo CSV con los datos del censo, lo cargaremos\n",
        "# en una tabla dentro de nuestra base de datos DuckDB. Esto nos permitirá\n",
        "# realizar consultas SQL sobre los datos de manera eficiente.\n",
        "# La tabla se llamará 'censo_all'.\n",
        "\n",
        "print(f\"--- Cargando Datos del CSV a la Tabla 'censo_all' en DuckDB ---\")\n",
        "\n",
        "# La ruta al archivo CSV extraído fue definida en la Celda 7\n",
        "# como RUTA_FINAL_CSV_EXTRAIDO (ej. ./inegi_data/censo_poblacion_vivienda_csv/csv_extraidos/censo_manzanas_urbanas_09_cpv2020.csv)\n",
        "\n",
        "# 1. Verificar que el archivo CSV exista antes de intentar cargarlo\n",
        "if not os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"¡ERROR CRÍTICO! No se encontró el archivo CSV de censo en: '{RUTA_FINAL_CSV_EXTRAIDO}'.\")\n",
        "    print(f\"La tabla 'censo_all' no se puede crear.\")\n",
        "    print(f\"Asegúrate de que la Celda 7 (descarga y extracción de CSV) se haya ejecutado correctamente.\")\n",
        "    # Detener el script si el archivo crucial no existe.\n",
        "    # Descomenta la siguiente línea para forzar la detención:\n",
        "    # raise FileNotFoundError(f\"Archivo CSV del censo no encontrado: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "else:\n",
        "    print(f\"Archivo CSV encontrado: '{RUTA_FINAL_CSV_EXTRAIDO}'. Procediendo a crear la tabla 'censo_all'.\")\n",
        "\n",
        "    try:\n",
        "        # 2. Eliminar la tabla 'censo_all' si ya existe (para empezar de cero)\n",
        "        # Esto evita errores si el script se ejecuta múltiples veces.\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_all;\")\n",
        "        print(\"Tabla 'censo_all' eliminada si existía previamente.\")\n",
        "\n",
        "        # 3. Crear la tabla 'censo_all' directamente desde el archivo CSV\n",
        "        # Usamos 'CREATE TABLE ... AS SELECT ... FROM read_csv_auto(...)'\n",
        "        # read_csv_auto intentará inferir tipos de datos y estructura.\n",
        "        #\n",
        "        # Parámetros importantes para read_csv_auto:\n",
        "        #   - RUTA_FINAL_CSV_EXTRAIDO: El archivo a leer.\n",
        "        #   - NULLSTR: Lista de cadenas que deben interpretarse como valores NULL (faltantes).\n",
        "        #              El INEGI usa '*', 'N/D', 'N/A'. También es bueno incluir cadenas vacías ('').\n",
        "        #   - SAMPLE_SIZE: Cuántas filas leer para inferir tipos. -1 significa leer todo el archivo,\n",
        "        #                  lo que es más robusto para la inferencia de tipos.\n",
        "        #   - HEADER=TRUE: Indica que la primera fila del CSV contiene los nombres de las columnas.\n",
        "        #   - ALL_VARCHAR=FALSE: (Por defecto es FALSE) Intenta convertir a tipos más específicos.\n",
        "        #                         Si se pone TRUE, todo se lee como VARCHAR, útil para inspeccionar,\n",
        "        #                         pero no para análisis numérico directo.\n",
        "        #\n",
        "        # Filtro 'WHERE MZA != '0'':\n",
        "        #   Los datos del INEGI a nivel manzana urbana a veces incluyen registros agregados\n",
        "        #   a nivel AGEB donde la manzana (MZA) es '0' o '000'.\n",
        "        #   Si solo queremos datos a nivel de manzana individual, aplicamos este filtro.\n",
        "        #   ¡Asegúrate de que la columna 'MZA' exista en tu CSV!\n",
        "\n",
        "        # Nota sobre tipos de datos: read_csv_auto es bueno, pero revisa columnas clave.\n",
        "        # Si una columna numérica crucial es leída como texto (VARCHAR) debido a valores\n",
        "        # no numéricos inesperados (distintos de los NULLSTR), necesitarás un CAST explícito\n",
        "        # o limpieza previa. Por ahora, confiaremos en la inferencia.\n",
        "\n",
        "        sql_create_table_from_csv = f\"\"\"\n",
        "        CREATE TABLE censo_all AS\n",
        "        SELECT *\n",
        "        FROM read_csv_auto('{RUTA_FINAL_CSV_EXTRAIDO}',\n",
        "                           NULLSTR=['N/A', 'N/D', '*', ''],\n",
        "                           SAMPLE_SIZE=-1,\n",
        "                           HEADER=TRUE\n",
        "                          )\n",
        "        WHERE MZA != '0';\n",
        "        \"\"\"\n",
        "        # Si la columna MZA se llama diferente en tu CSV, ajusta el WHERE.\n",
        "        # Ejemplo: Si se llama 'MANZANA', sería WHERE MANZANA != '0';\n",
        "\n",
        "        print(\"\\nEjecutando la creación de la tabla 'censo_all' desde el CSV...\")\n",
        "        con.execute(\"BEGIN TRANSACTION;\") # Iniciar transacción para atomicidad\n",
        "        con.execute(sql_create_table_from_csv)\n",
        "        con.execute(\"COMMIT;\") # Confirmar transacción si todo fue bien\n",
        "        print(\"¡Tabla 'censo_all' creada y poblada exitosamente desde el archivo CSV!\")\n",
        "\n",
        "        # 4. Verificar la tabla creada (opcional, pero muy recomendable)\n",
        "        print(\"\\nVerificando la tabla 'censo_all'...\")\n",
        "\n",
        "        # Contar filas en la nueva tabla\n",
        "        num_filas = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas en 'censo_all' (con MZA != '0'): {num_filas}\")\n",
        "\n",
        "        if num_filas == 0:\n",
        "            print(\"  ADVERTENCIA: La tabla 'censo_all' está vacía. Verifica:\")\n",
        "            print(\"    - Que el archivo CSV no esté vacío.\")\n",
        "            print(\"    - Que el filtro 'WHERE MZA != '0'' no haya eliminado todas las filas.\")\n",
        "            print(\"    - Que la columna 'MZA' exista y tenga los valores esperados.\")\n",
        "\n",
        "        # Mostrar la estructura de algunas columnas y las primeras filas\n",
        "        print(\"\\n  Estructura (primeras 5 columnas) y primeras 3 filas de 'censo_all':\")\n",
        "        # Describe puede ser muy largo, así que seleccionamos algunas columnas para vista previa.\n",
        "        # Para una vista previa rápida de las columnas:\n",
        "        # print(con.execute(\"DESCRIBE censo_all;\").fetchdf().head())\n",
        "        # O mejor, ver algunas columnas de los datos:\n",
        "        preview_df = con.execute(\"SELECT ENTIDAD, NOM_ENT, MUN, NOM_MUN, LOC, NOM_LOC, AGEB, MZA, POBTOT FROM censo_all LIMIT 3;\").fetchdf()\n",
        "        if preview_df.empty and num_filas > 0:\n",
        "             print(\"  No se pudieron obtener las columnas de vista previa, pero la tabla tiene filas.\")\n",
        "        elif not preview_df.empty:\n",
        "            print(preview_df)\n",
        "        else:\n",
        "            print(\"  La tabla 'censo_all' parece estar vacía, no hay datos para mostrar en la vista previa.\")\n",
        "\n",
        "\n",
        "    except duckdb.CatalogException as e:\n",
        "        print(f\"¡ERROR DE CATÁLOGO de DuckDB al crear 'censo_all'!: {e}\")\n",
        "        print(\"  Esto puede ocurrir si hay un problema con los nombres de tabla o columna, o tipos.\")\n",
        "        try: con.execute(\"ROLLBACK;\") # Intentar revertir si la transacción estaba abierta\n",
        "        except: pass\n",
        "    except duckdb.ConversionException as e:\n",
        "        print(f\"¡ERROR DE CONVERSIÓN de DuckDB al leer el CSV para 'censo_all'!: {e}\")\n",
        "        print(\"  Esto usualmente significa que DuckDB encontró un valor en una columna que no pudo\")\n",
        "        print(\"  convertir al tipo de dato que infirió para esa columna (ej. texto en una columna numérica).\")\n",
        "        print(f\"  Revisa el archivo CSV '{RUTA_FINAL_CSV_EXTRAIDO}' alrededor del error indicado si es posible.\")\n",
        "        print(\"  Considera usar la opción ALL_VARCHAR=TRUE en read_csv_auto para importar todo como texto\")\n",
        "        print(\"  y luego limpiar y convertir tipos con más control si este error persiste.\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'censo_all' desde CSV!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "\n",
        "print(\"\\n--- Proceso de carga de CSV a DuckDB completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "wmWMMNwBtFdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Explorando `censo_all` con SQL Básico: Primeros Pasos**\n",
        "\n",
        "Ahora que los datos censales residen en la tabla `censo_all` dentro de nuestra base de datos DuckDB, podemos empezar a \"hacerle preguntas\" usando SQL. SQL (Structured Query Language) es el lenguaje estándar para interactuar con bases de datos relacionales.\n",
        "\n",
        "Veamos algunos ejemplos sencillos para familiarizarnos con la tabla y las operaciones básicas de SQL:\n",
        "\n",
        "1.  **`SELECT` y `FROM`**: Para elegir qué columnas queremos ver (`SELECT`) y de qué tabla (`FROM`).\n",
        "2.  **`LIMIT`**: Para restringir el número de filas que nos devuelve la consulta, útil para vistas previas.\n",
        "3.  **`WHERE`**: Para filtrar filas basadas en una o más condiciones.\n",
        "4.  **`COUNT(*)`**: Para contar el número total de filas.\n",
        "5.  **`DISTINCT`**: Para ver los valores únicos en una columna.\n",
        "6.  **`ORDER BY`**: Para ordenar los resultados.\n",
        "7.  **`GROUP BY` y Funciones de Agregación (ej. `SUM()`, `AVG()`)**: Para agrupar filas y calcular estadísticas.\n",
        "\n",
        "Estos ejemplos nos darán una idea de la riqueza de los datos que hemos cargado.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Py4xNa3fvhvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8.1: Ejemplos de Consultas SQL Básicas sobre la Tabla 'censo_all'\n",
        "# --------------------------------------------------------------------\n",
        "# Estos ejemplos asumen que la Celda 8 (creación de 'censo_all') se ejecutó\n",
        "# correctamente y la conexión 'con' a DuckDB está activa.\n",
        "\n",
        "print(f\"--- Ejemplos de Consultas SQL sobre la tabla 'censo_all' ---\")\n",
        "\n",
        "# Antes de empezar, verificamos si la tabla 'censo_all' existe y tiene datos.\n",
        "try:\n",
        "    num_filas_censo_all = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "    if num_filas_censo_all == 0:\n",
        "        print(\"ADVERTENCIA: La tabla 'censo_all' está vacía. Los siguientes ejemplos SQL podrían no devolver resultados.\")\n",
        "        # Puedes decidir si detener el script o simplemente mostrar mensajes vacíos.\n",
        "    else:\n",
        "        print(f\"La tabla 'censo_all' contiene {num_filas_censo_all} filas.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al verificar la tabla 'censo_all': {e}. No se pueden ejecutar los ejemplos SQL.\")\n",
        "    # Detener si la tabla base no está accesible\n",
        "    raise\n",
        "\n",
        "if num_filas_censo_all > 0:\n",
        "    # Ejemplo 1: Ver las primeras 5 filas completas de la tabla\n",
        "    # SELECT * selecciona todas las columnas.\n",
        "    print(\"\\n--- Ejemplo 1: Primeras 5 filas de 'censo_all' (todas las columnas) ---\")\n",
        "    try:\n",
        "        df_ej1 = con.execute(\"SELECT * FROM censo_all LIMIT 5;\").fetchdf()\n",
        "        print(df_ej1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 1: {e}\")\n",
        "\n",
        "    # Ejemplo 2: Seleccionar columnas específicas (nombre de entidad, nombre de municipio, población total)\n",
        "    # para las primeras 5 filas.\n",
        "    # Asumimos que las columnas se llaman NOM_ENT, NOM_MUN, POBTOT. ¡Verifica los nombres en tu CSV!\n",
        "    print(\"\\n--- Ejemplo 2: Columnas específicas (NOM_ENT, NOM_MUN, POBTOT) de las primeras 5 filas ---\")\n",
        "    try:\n",
        "        df_ej2 = con.execute(\"SELECT NOM_ENT, NOM_MUN, POBTOT FROM censo_all LIMIT 5;\").fetchdf()\n",
        "        print(df_ej2)\n",
        "    except duckdb.CatalogException: # Error común si los nombres de columna no existen\n",
        "        print(\"  Error: Una o más columnas (NOM_ENT, NOM_MUN, POBTOT) no existen en 'censo_all'.\")\n",
        "        print(\"  Por favor, verifica los nombres exactos de las columnas en tu archivo CSV o en la tabla.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 2: {e}\")\n",
        "\n",
        "\n",
        "    # Ejemplo 3: Contar cuántas manzanas hay por cada municipio.\n",
        "    # Usamos GROUP BY para agrupar por NOM_MUN y COUNT(*) para contar las filas (manzanas) en cada grupo.\n",
        "    # Asumimos que NOM_MUN existe.\n",
        "    print(\"\\n--- Ejemplo 3: Número de manzanas por municipio (primeros 10 municipios) ---\")\n",
        "    try:\n",
        "        # Usaremos TRY_CAST para NOM_MUN por si acaso se leyó como otro tipo, aunque debería ser VARCHAR\n",
        "        df_ej3 = con.execute(\"\"\"\n",
        "            SELECT\n",
        "                TRY_CAST(NOM_MUN AS VARCHAR) AS NombreMunicipio,\n",
        "                COUNT(*) AS NumeroDeManzanas\n",
        "            FROM censo_all\n",
        "            GROUP BY NombreMunicipio\n",
        "            ORDER BY NumeroDeManzanas DESC\n",
        "            LIMIT 10;\n",
        "        \"\"\").fetchdf()\n",
        "        print(df_ej3)\n",
        "    except duckdb.CatalogException:\n",
        "        print(\"  Error: La columna NOM_MUN no existe o no se puede agrupar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 3: {e}\")\n",
        "\n",
        "    # Ejemplo 4: Encontrar las 5 manzanas con la mayor población total (POBTOT).\n",
        "    # Asumimos que POBTOT es una columna numérica.\n",
        "    print(\"\\n--- Ejemplo 4: Las 5 manzanas con mayor población total ---\")\n",
        "    try:\n",
        "        # Es importante que POBTOT sea numérico para ordenar correctamente.\n",
        "        # read_csv_auto debería haberlo inferido, pero un TRY_CAST no hace daño.\n",
        "        df_ej4 = con.execute(\"\"\"\n",
        "            SELECT NOM_ENT, NOM_MUN, AGEB, MZA, TRY_CAST(POBTOT AS DOUBLE) AS PoblacionTotal\n",
        "            FROM censo_all\n",
        "            ORDER BY PoblacionTotal DESC NULLS LAST\n",
        "            LIMIT 5;\n",
        "        \"\"\").fetchdf() # NULLS LAST para que los nulos no aparezcan primero si se ordena descendentemente\n",
        "        print(df_ej4)\n",
        "    except duckdb.CatalogException:\n",
        "        print(\"  Error: Alguna de las columnas (NOM_ENT, NOM_MUN, AGEB, MZA, POBTOT) no existe.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 4: {e}\")\n",
        "\n",
        "    # Ejemplo 5: Calcular la población total para un municipio específico.\n",
        "    # Reemplaza 'CIUDAD DE MEXICO' o el nombre de un municipio que sepas que existe en tus datos.\n",
        "    # (Nota: Si tu NOM_MUN tiene nombres de alcaldías y NOM_ENT es CDMX, ajusta)\n",
        "    # Para este ejemplo, vamos a tomar el primer nombre de municipio que encontremos.\n",
        "    try:\n",
        "        primer_municipio_df = con.execute(\"SELECT DISTINCT NOM_MUN FROM censo_all WHERE NOM_MUN IS NOT NULL LIMIT 1;\").fetchdf()\n",
        "        if not primer_municipio_df.empty:\n",
        "            nombre_municipio_ejemplo = primer_municipio_df['NOM_MUN'].iloc[0]\n",
        "            print(f\"\\n--- Ejemplo 5: Población total para el municipio '{nombre_municipio_ejemplo}' ---\")\n",
        "\n",
        "            df_ej5 = con.execute(f\"\"\"\n",
        "                SELECT\n",
        "                    NOM_MUN,\n",
        "                    SUM(TRY_CAST(POBTOT AS DOUBLE)) AS PoblacionTotalEnMunicipio\n",
        "                FROM censo_all\n",
        "                WHERE NOM_MUN = '{nombre_municipio_ejemplo.replace(\"'\", \"''\")}'  -- Escapar comillas simples en SQL\n",
        "                GROUP BY NOM_MUN;\n",
        "            \"\"\").fetchdf()\n",
        "            print(df_ej5)\n",
        "        else:\n",
        "            print(\"\\n--- Ejemplo 5: No se encontraron municipios para el ejemplo. ---\")\n",
        "\n",
        "    except duckdb.CatalogException:\n",
        "        print(\"  Error en Ejemplo 5: Alguna columna (NOM_MUN, POBTOT) no existe.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 5: {e}\")\n",
        "\n",
        "\n",
        "    # Ejemplo 6: Ver los distintos nombres de entidades federativas presentes en la tabla.\n",
        "    # Útil para confirmar qué datos se cargaron.\n",
        "    print(\"\\n--- Ejemplo 6: Nombres de Entidades Federativas distintas en la tabla ---\")\n",
        "    try:\n",
        "        df_ej6 = con.execute(\"SELECT DISTINCT NOM_ENT FROM censo_all;\").fetchdf()\n",
        "        print(df_ej6)\n",
        "    except duckdb.CatalogException:\n",
        "        print(\"  Error: La columna NOM_ENT no existe.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Ejemplo 6: {e}\")\n",
        "\n",
        "else: # Si num_filas_censo_all == 0\n",
        "    print(\"\\nNo se pueden ejecutar los ejemplos SQL porque la tabla 'censo_all' está vacía o no se pudo verificar.\")\n",
        "\n",
        "print(\"\\n--- Fin de los ejemplos SQL básicos. ---\")"
      ],
      "metadata": {
        "id": "3NoQTwbEvmdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Segunda Descarga y Extracción del Shapefile: Obteniendo los Mapas de Manzanas**\n",
        "\n",
        "**Concepto Clave: Adquisición de la Información Geográfica (las \"Formas\" de las Manzanas)**\n",
        "\n",
        "Ya tenemos los datos *tabulares* del censo en nuestra base de datos. Ahora necesitamos la contraparte: los datos *geoespaciales*, es decir, los mapas digitales que representan las formas (polígonos) de cada manzana. El INEGI proporciona estos datos en formato **Shapefile**, usualmente dentro de archivos ZIP separados, como parte de su Marco Geoestadístico.\n",
        "\n",
        "1.  **Descarga Focalizada en el Marco Geoestadístico:**\n",
        "    *   A diferencia de los CSV del censo que pueden tener una URL por tipo de dato y estado, los Shapefiles del Marco Geoestadístico a menudo se agrupan por estado. Necesitaremos la URL del archivo ZIP que contiene el marco geoestadístico para el estado que estamos analizando (por ejemplo, para la Ciudad de México, será un archivo como `09_ciudaddemexico.zip`).\n",
        "    *   Estos archivos ZIP se descargarán a la carpeta que designamos para ello: `DIR_MARCO_GEO_DESCARGAS_ZIP`.\n",
        "\n",
        "2.  **Extracción Específica del Shapefile de Manzanas:**\n",
        "    *   Un solo ZIP del Marco Geoestadístico puede contener Shapefiles para diferentes niveles geográficos (localidades, AGEBs, municipios, manzanas, etc.). Nosotros estamos interesados específicamente en las **manzanas**.\n",
        "    *   Usaremos nuestra función `extract_shapefile(...)` que preparamos anteriormente. Le indicaremos:\n",
        "        *   El nombre del archivo ZIP a procesar.\n",
        "        *   El directorio donde se encuentra ese ZIP.\n",
        "        *   El directorio de salida donde queremos los componentes del Shapefile de manzanas (`DIR_SHP_MANZANAS_EXTRAIDOS`).\n",
        "        *   Un **sufijo o identificador de tipo** que nos permita decirle a la función qué archivos buscar dentro del ZIP. Por ejemplo, si los archivos de manzana se llaman `09m.shp`, `09m.dbf`, etc., el sufijo de tipo sería `\"m\"`.\n",
        "    *   **¿Por qué un `shape_type_suffix`?** El INEGI usa diferentes letras o códigos en los nombres de archivo para distinguir los niveles geográficos. Usar un parámetro para esto hace nuestra función de extracción más flexible.\n",
        "\n",
        "3.  **Componentes Esenciales del Shapefile:**\n",
        "    *   Nuestra función `extract_shapefile` se encargará de buscar y extraer los archivos cruciales: `.shp` (geometrías), `.dbf` (atributos), `.shx` (índice espacial) y `.prj` (sistema de coordenadas).\n",
        "    *   También manejará la creación de un archivo `.cpg` (codificación de caracteres) si no está presente en el ZIP, lo cual es importante para la correcta interpretación de los textos en los atributos.\n",
        "\n",
        "4.  **Importancia de las Manzanas:**\n",
        "    *   La manzana es, a menudo, la unidad geográfica más pequeña para la cual el INEGI publica datos censales detallados en áreas urbanas.\n",
        "    *   Trabajar a este nivel de granularidad nos permite realizar análisis espaciales muy finos, como identificar la distribución de la población cuadra por cuadra, planificar servicios locales, estudiar la accesibilidad, etc.\n",
        "\n",
        "Al finalizar este paso, tendremos los archivos (`.shp`, `.dbf`, etc.) que definen los polígonos de cada manzana de nuestro estado de interés, guardados en una carpeta específica (`DIR_SHP_MANZANAS_EXTRAIDOS`). Estos archivos son la representación visual y geométrica que luego uniremos con los datos censales que ya están en DuckDB."
      ],
      "metadata": {
        "id": "rWnfKbmRwLXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 9: Descarga y Extracción del Shapefile de Manzanas\n",
        "# --------------------------------------------------------\n",
        "# En esta celda, descargaremos el archivo ZIP que contiene el Marco Geoestadístico\n",
        "# del INEGI para nuestro estado. Luego, extraeremos de ese ZIP los componentes\n",
        "# del Shapefile que corresponden específicamente a las 'manzanas'.\n",
        "\n",
        "print(f\"--- Iniciando Proceso de Descarga y Extracción de Shapefiles de Manzanas para: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "# --- 1. Definición de URLs y Nombres de Archivo para el Marco Geoestadístico (Shapefiles) ---\n",
        "\n",
        "# URL base donde el INEGI almacena los productos del Marco Geoestadístico Censal.\n",
        "# Esta URL puede cambiar, ¡verifica la fuente oficial del INEGI si hay problemas!\n",
        "URL_BASE_MARCO_GEO_INEGI = \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/\"\n",
        "\n",
        "# Nombre del archivo ZIP que contiene los Shapefiles para nuestro estado.\n",
        "# Usamos ESTADO_GEO_ZIP_FILENAME definido en la Celda 5 (ej. \"09_ciudaddemexico.zip\")\n",
        "URL_COMPLETA_MARCO_GEO_ZIP = f\"{URL_BASE_MARCO_GEO_INEGI}{ESTADO_GEO_ZIP_FILENAME}\"\n",
        "\n",
        "# Ruta completa donde se guardará el archivo ZIP descargado.\n",
        "# Usamos el directorio definido en la Celda 5: DIR_MARCO_GEO_DESCARGAS_ZIP\n",
        "RUTA_DESCARGA_ZIP_MARCO_GEO = os.path.join(DIR_MARCO_GEO_DESCARGAS_ZIP, ESTADO_GEO_ZIP_FILENAME)\n",
        "\n",
        "# Recordatorio de variables de la Celda 5 que usará la función extract_shapefile:\n",
        "# - ESTADO_GEO_ZIP_FILENAME: Nombre del zip a procesar (ej. \"09_ciudaddemexico.zip\")\n",
        "# - DIR_MARCO_GEO_DESCARGAS_ZIP: Directorio donde está el ZIP.\n",
        "# - DIR_SHP_MANZANAS_EXTRAIDOS: Directorio de salida para los archivos .shp, .dbf, etc., de manzanas.\n",
        "# - TIPO_SHAPEFILE_MANZANAS: Sufijo para el tipo de shape (ej. \"m\" para manzanas).\n",
        "\n",
        "print(f\"URL para descarga del ZIP del Marco Geoestadístico: {URL_COMPLETA_MARCO_GEO_ZIP}\")\n",
        "print(f\"Ruta de descarga del ZIP: {RUTA_DESCARGA_ZIP_MARCO_GEO}\")\n",
        "print(f\"Directorio de salida para Shapefiles de manzanas extraídos: {DIR_SHP_MANZANAS_EXTRAIDOS}\")\n",
        "\n",
        "# --- 2. Descarga del Archivo ZIP del Marco Geoestadístico ---\n",
        "# Verificamos si el ZIP ya existe antes de intentar descargarlo.\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_MARCO_GEO):\n",
        "    print(f\"\\nDescargando '{ESTADO_GEO_ZIP_FILENAME}' (Marco Geoestadístico)...\")\n",
        "    # Usamos la función 'download' definida en la Celda 3.\n",
        "    try:\n",
        "        download(URL_COMPLETA_MARCO_GEO_ZIP, DIR_MARCO_GEO_DESCARGAS_ZIP)\n",
        "    except Exception as e:\n",
        "        print(f\"  La descarga del ZIP del Marco Geoestadístico falló. El error fue: {e}\")\n",
        "        print(f\"  No se puede continuar con la extracción de Shapefiles sin este archivo ZIP.\")\n",
        "else:\n",
        "    print(f\"\\nEl archivo ZIP '{ESTADO_GEO_ZIP_FILENAME}' (Marco Geoestadístico) ya existe \"\n",
        "          f\"en '{DIR_MARCO_GEO_DESCARGAS_ZIP}'. No se descarga de nuevo.\")\n",
        "\n",
        "# --- 3. Extracción de los Componentes del Shapefile de Manzanas ---\n",
        "# La función 'extract_shapefile' (definida en la Celda 4) se encargará de:\n",
        "#   - Abrir el ZIP.\n",
        "#   - Buscar los archivos .shp, .dbf, .shx, .prj, .cpg correspondientes a las manzanas.\n",
        "#   - Extraerlos al directorio DIR_SHP_MANZANAS_EXTRAIDOS.\n",
        "#   - Crear un .cpg por defecto si no existe.\n",
        "#   - Verificar si los archivos ya fueron extraídos previamente.\n",
        "\n",
        "print(f\"\\nExtrayendo componentes del Shapefile de tipo '{TIPO_SHAPEFILE_MANZANAS}' (Manzanas)...\")\n",
        "\n",
        "# Primero, nos aseguramos de que el archivo ZIP exista (pudo haber fallado la descarga)\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_MARCO_GEO):\n",
        "    print(f\"  ¡ERROR CRÍTICO! No se encontró el archivo ZIP '{RUTA_DESCARGA_ZIP_MARCO_GEO}'.\")\n",
        "    print(f\"  No se pueden extraer los Shapefiles. Asegúrate de que la descarga fue exitosa.\")\n",
        "    # Detener si el archivo crucial no existe.\n",
        "    # Descomenta la siguiente línea para forzar la detención:\n",
        "    # raise FileNotFoundError(f\"Archivo ZIP del Marco Geoestadístico no encontrado: {RUTA_DESCARGA_ZIP_MARCO_GEO}\")\n",
        "else:\n",
        "    try:\n",
        "        extract_shapefile(\n",
        "            list_of_zip_filenames=[ESTADO_GEO_ZIP_FILENAME], # La función espera una lista\n",
        "            zip_file_directory=DIR_MARCO_GEO_DESCARGAS_ZIP,\n",
        "            target_shp_output_dir=DIR_SHP_MANZANAS_EXTRAIDOS,\n",
        "            shape_type_suffix=TIPO_SHAPEFILE_MANZANAS\n",
        "        )\n",
        "        print(f\"Proceso de extracción de Shapefiles de manzanas intentado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Ocurrió un error inesperado durante la llamada a extract_shapefile: {e}\")\n",
        "\n",
        "print(\"\\n--- Proceso de Descarga y Extracción de Shapefiles de Manzanas completado (o intentado). ---\")\n",
        "\n",
        "# Verificar si se crearon los archivos esperados (ej. el .shp)\n",
        "# Esto es una comprobación simple; la función extract_shapefile debería haber impreso más detalles.\n",
        "archivo_shp_esperado = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{CODIGO_ESTADO_STR}{TIPO_SHAPEFILE_MANZANAS}.shp\")\n",
        "if os.path.exists(archivo_shp_esperado):\n",
        "    print(f\"Confirmado: El archivo '{os.path.basename(archivo_shp_esperado)}' existe en '{DIR_SHP_MANZANAS_EXTRAIDOS}'.\")\n",
        "    print(f\"  (Y deberían existir también sus archivos hermanos: .dbf, .shx, .prj)\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: El archivo principal del Shapefile ('{os.path.basename(archivo_shp_esperado)}') \"\n",
        "          f\"NO se encuentra en '{DIR_SHP_MANZANAS_EXTRAIDOS}'. Revisa los mensajes de error anteriores.\")"
      ],
      "metadata": {
        "id": "0Zd8M1lEvo6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conversión a GeoParquet: Eficiencia y Modernidad en Datos Geoespaciales**\n",
        "\n",
        "**Concepto Clave: Adoptando un Formato Optimizado para el Análisis Geoespacial**\n",
        "\n",
        "Hemos extraído los componentes del Shapefile (`.shp`, `.dbf`, etc.). Si bien el Shapefile es un formato clásico y ampliamente compatible, tiene algunas desventajas para el análisis moderno de datos, especialmente con volúmenes grandes:\n",
        "\n",
        "*   **Múltiples Archivos:** Un solo \"mapa\" Shapefile en realidad consta de varios archivos. Esto puede ser engorroso de manejar y transferir.\n",
        "*   **Limitaciones de Tamaño y Atributos:** Tiene restricciones en el tamaño de los archivos y en los nombres de las columnas de atributos.\n",
        "*   **Rendimiento:** Su rendimiento de lectura/escritura puede no ser óptimo comparado con formatos más nuevos.\n",
        "\n",
        "Aquí es donde entra **GeoParquet**.\n",
        "\n",
        "1.  **¿Qué es Parquet y GeoParquet?**\n",
        "    *   **Apache Parquet:** Es un formato de almacenamiento **columnar** de código abierto. \"Columnar\" significa que los datos se organizan por columnas en lugar de por filas. Esto es extremadamente eficiente para consultas analíticas, ya que a menudo solo necesitas leer un subconjunto de columnas, y Parquet permite hacerlo sin leer todo el archivo. Ofrece excelente compresión y rendimiento.\n",
        "    *   **GeoParquet:** Es una **especificación estándar** sobre cómo almacenar datos geoespaciales (geometrías) dentro de un archivo Parquet. Básicamente, es un archivo Parquet que incluye metadatos geoespaciales estándar (como el Sistema de Coordenadas de Referencia - CRS) y una columna que contiene las geometrías.\n",
        "\n",
        "2.  **Ventajas de Convertir de Shapefile a GeoParquet:**\n",
        "    *   **Un Solo Archivo:** Un GeoDataFrame completo (mapa + atributos) se guarda en un único archivo `.geoparquet`. ¡Adiós a la colección de archivos del Shapefile!\n",
        "    *   **Rendimiento Superior:** La lectura y escritura de archivos GeoParquet suelen ser significativamente más rápidas, especialmente con herramientas modernas como DuckDB (con su extensión espacial) y GeoPandas.\n",
        "    *   **Mejor Compresión:** Parquet generalmente logra mejores tasas de compresión que los componentes de un Shapefile, lo que resulta en archivos más pequeños.\n",
        "    *   **Tipos de Datos Ricos:** Mejor soporte para diversos tipos de datos en las columnas de atributos.\n",
        "    *   **Estándar Abierto y Creciente Adopción:** GeoParquet se está convirtiendo rápidamente en el formato preferido para el intercambio y análisis de datos geoespaciales vectoriales.\n",
        "\n",
        "3.  **Proceso de Conversión con GeoPandas:**\n",
        "    *   La librería `geopandas` hace que esta conversión sea muy sencilla:\n",
        "        1.  **Leer el Shapefile:**\n",
        "            ```python\n",
        "            # gdf = gpd.read_file('ruta/al/manzanas.shp', encoding='ISO-8859-1')\n",
        "            ```\n",
        "            GeoPandas lee el `.shp` y su `.dbf` asociado (y otros componentes) en un `GeoDataFrame`. Especificar la `encoding` (como `ISO-8859-1`, común para datos del INEGI) es importante para los atributos de texto.\n",
        "        2.  **Verificar y Asignar/Reproyectar el CRS (Sistema de Coordenadas):**\n",
        "            *   Es **crucial** que nuestros datos geoespaciales tengan un CRS definido correctamente. GeoPandas intentará leerlo del archivo `.prj`.\n",
        "            *   Si el CRS no se detecta (`gdf.crs is None`), debemos asignarle el CRS correcto que sabemos que tienen los datos originales del INEGI (por ejemplo, `EPSG:6372` para ITRF2008).\n",
        "            *   Una vez que tenemos un CRS de origen, es una **excelente práctica reproyectar** las geometrías a un CRS estándar global como **`EPSG:4326` (WGS 84)**. Este es el sistema de coordenadas que usan GPS, Google Maps, y muchos servicios web, lo que facilita la interoperabilidad.\n",
        "                ```python\n",
        "                # if gdf.crs is None:\n",
        "                #     gdf.set_crs(\"EPSG:6372\", inplace=True) # Asignar si no tiene\n",
        "                # gdf = gdf.to_crs(\"EPSG:4326\") # Reproyectar a WGS 84\n",
        "                ```\n",
        "        3.  **Guardar como GeoParquet:**\n",
        "            ```python\n",
        "            # gdf.to_parquet('ruta/al/manzanas.geoparquet', index=False)\n",
        "            ```\n",
        "            El `index=False` evita que se guarde el índice del GeoDataFrame como una columna en el archivo Parquet, lo cual generalmente es deseable.\n",
        "\n",
        "Al convertir nuestros Shapefiles a GeoParquet, estamos modernizando nuestro flujo de datos, haciéndolo más eficiente, más fácil de manejar y preparándolo para un análisis de alto rendimiento con DuckDB."
      ],
      "metadata": {
        "id": "YqYytSRGxjqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 10: Conversión de Shapefile a Formato GeoParquet\n",
        "# ----------------------------------------------------\n",
        "# En esta celda, tomaremos el Shapefile de manzanas que extrajimos\n",
        "# y lo convertiremos al formato GeoParquet. GeoParquet es un formato\n",
        "# moderno y eficiente para almacenar datos geoespaciales, que ofrece\n",
        "# mejor rendimiento y manejo de archivos que el tradicional Shapefile.\n",
        "\n",
        "print(f\"--- Iniciando Proceso de Conversión de Shapefile a GeoParquet para: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "# --- 1. Definición de Rutas de Entrada y Salida ---\n",
        "\n",
        "# Ruta del archivo .shp de entrada (de las manzanas extraídas)\n",
        "# Construido a partir de variables definidas en celdas anteriores:\n",
        "# DIR_SHP_MANZANAS_EXTRAIDOS, CODIGO_ESTADO_STR, TIPO_SHAPEFILE_MANZANAS\n",
        "NOMBRE_SHP_BASE = f\"{CODIGO_ESTADO_STR}{TIPO_SHAPEFILE_MANZANAS}\" # ej: \"09m\"\n",
        "RUTA_SHP_ENTRADA = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{NOMBRE_SHP_BASE}.shp\")\n",
        "\n",
        "# Ruta del archivo .geoparquet de salida\n",
        "# Lo guardaremos en el mismo directorio que los Shapefiles extraídos.\n",
        "RUTA_GEOPARQUET_SALIDA = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{NOMBRE_SHP_BASE}.geoparquet\")\n",
        "\n",
        "print(f\"Archivo Shapefile de entrada: {RUTA_SHP_ENTRADA}\")\n",
        "print(f\"Archivo GeoParquet de salida: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "\n",
        "# --- 2. Proceso de Conversión ---\n",
        "\n",
        "# Verificar si el archivo .shp de entrada existe\n",
        "if not os.path.exists(RUTA_SHP_ENTRADA):\n",
        "    print(f\"  ¡ERROR CRÍTICO! No se encontró el archivo Shapefile de entrada: '{RUTA_SHP_ENTRADA}'.\")\n",
        "    print(f\"  No se puede realizar la conversión a GeoParquet.\")\n",
        "    print(f\"  Asegúrate de que la Celda 9 (descarga y extracción de Shapefiles) se haya ejecutado correctamente.\")\n",
        "    # Detener si el archivo crucial no existe\n",
        "    # Descomenta la siguiente línea para forzar la detención:\n",
        "    # raise FileNotFoundError(f\"Archivo Shapefile de entrada no encontrado: {RUTA_SHP_ENTRADA}\")\n",
        "\n",
        "# Verificar si el archivo GeoParquet de salida ya existe para no repetir el trabajo\n",
        "elif os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"\\nEl archivo GeoParquet '{os.path.basename(RUTA_GEOPARQUET_SALIDA)}' ya existe. No se convierte de nuevo.\")\n",
        "else:\n",
        "    print(f\"\\nIniciando conversión de '{os.path.basename(RUTA_SHP_ENTRADA)}' a GeoParquet...\")\n",
        "    try:\n",
        "        # 2a. Leer el Shapefile usando GeoPandas\n",
        "        # Es importante especificar la codificación correcta para leer los atributos\n",
        "        # del archivo .dbf. 'ISO-8859-1' (o 'latin1') es común para datos del INEGI.\n",
        "        # Si hay errores de codificación, podrías probar con 'utf-8' o detectarla.\n",
        "        print(f\"  Leyendo Shapefile: '{RUTA_SHP_ENTRADA}'...\")\n",
        "        gdf = gpd.read_file(RUTA_SHP_ENTRADA, encoding='ISO-8859-1')\n",
        "        print(f\"    Shapefile leído exitosamente. Contiene {len(gdf)} geometrías.\")\n",
        "        print(f\"    CRS (Sistema de Coordenadas de Referencia) original detectado: {gdf.crs}\")\n",
        "\n",
        "        # 2b. Manejo del CRS (Sistema de Coordenadas de Referencia)\n",
        "        # Es crucial que los datos tengan un CRS correcto.\n",
        "        # Si GeoPandas no pudo determinar el CRS (es decir, gdf.crs es None),\n",
        "        # necesitamos asignarle uno. Para datos recientes del INEGI en México,\n",
        "        # un CRS común es EPSG:6372 (ITRF2008).\n",
        "        # ¡ESTA ASIGNACIÓN ES UNA SUPOSICIÓN SI FALTA EL .PRJ O ES INVÁLIDO!\n",
        "        # Siempre es mejor que el .prj original sea correcto.\n",
        "        if gdf.crs is None:\n",
        "            crs_asignado_por_defecto = \"EPSG:6372\" # ITRF2008 / Mexico\n",
        "            print(f\"    ADVERTENCIA: No se detectó CRS en el Shapefile (faltaba .prj o era inválido).\")\n",
        "            print(f\"    Asignando CRS por defecto: {crs_asignado_por_defecto}. ¡VERIFICA QUE ESTA ASIGNACIÓN SEA CORRECTA PARA TUS DATOS!\")\n",
        "            try:\n",
        "                gdf.set_crs(crs_asignado_por_defecto, inplace=True) # inplace=True modifica gdf directamente\n",
        "                print(f\"    CRS asignado: {gdf.crs}\")\n",
        "            except Exception as e_set_crs:\n",
        "                print(f\"    ¡ERROR al asignar CRS por defecto {crs_asignado_por_defecto}!: {e_set_crs}\")\n",
        "                print(f\"    La conversión podría fallar o resultar en datos geoespaciales incorrectos.\")\n",
        "                raise # Detener si no podemos asignar un CRS base\n",
        "\n",
        "        # 2c. Reproyectar a un CRS estándar global: EPSG:4326 (WGS 84)\n",
        "        # Esto es una buena práctica para la interoperabilidad y consistencia.\n",
        "        # WGS 84 usa coordenadas de latitud/longitud.\n",
        "        crs_destino = \"EPSG:4326\" # WGS 84\n",
        "        if gdf.crs != crs_destino: # Solo reproyectar si no está ya en el CRS destino\n",
        "            print(f\"    Reproyectando geometrías de {gdf.crs} a {crs_destino} (WGS 84)...\")\n",
        "            try:\n",
        "                gdf = gdf.to_crs(crs_destino)\n",
        "                print(f\"    Reproyección completada. Nuevo CRS: {gdf.crs}\")\n",
        "            except Exception as e_to_crs:\n",
        "                print(f\"    ¡ERROR al reproyectar a {crs_destino}!: {e_to_crs}\")\n",
        "                print(f\"    La conversión podría usar el CRS original o fallar.\")\n",
        "                raise # Detener si la reproyección es crítica y falla\n",
        "        else:\n",
        "            print(f\"    Las geometrías ya están en el CRS destino ({crs_destino}). No se necesita reproyección.\")\n",
        "\n",
        "\n",
        "        # 2d. Guardar el GeoDataFrame como archivo GeoParquet\n",
        "        # 'index=False' evita que el índice de GeoPandas se guarde como una columna en el Parquet.\n",
        "        print(f\"  Guardando GeoDataFrame como GeoParquet en: '{RUTA_GEOPARQUET_SALIDA}'...\")\n",
        "        gdf.to_parquet(RUTA_GEOPARQUET_SALIDA, index=False)\n",
        "        print(f\"    ¡Conversión a GeoParquet completada exitosamente!\")\n",
        "\n",
        "    except FileNotFoundError: # Específicamente si un componente del SHP falta y gpd.read_file falla\n",
        "        print(f\"  ¡ERROR! No se encontró el Shapefile o uno de sus componentes necesarios (ej. .dbf, .shx) en '{os.path.dirname(RUTA_SHP_ENTRADA)}'.\")\n",
        "    except importlib.metadata.PackageNotFoundError as e_arrow: # Común si falta pyarrow\n",
        "        print(f\"  ¡ERROR DE DEPENDENCIA! Parece que falta 'pyarrow', que es necesario para 'to_parquet'.\")\n",
        "        print(f\"  Detalle del error: {e_arrow}\")\n",
        "        print(f\"  Asegúrate de haberlo instalado (ej. pip install pyarrow).\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ¡ERROR GENERAL durante la conversión a GeoParquet!: {e}\")\n",
        "\n",
        "print(\"\\n--- Proceso de Conversión a GeoParquet completado (o intentado). ---\")\n",
        "\n",
        "# Verificar si el archivo GeoParquet final existe después de todo el proceso\n",
        "if os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"Confirmado: El archivo GeoParquet está listo en: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: El archivo GeoParquet final NO se encuentra en: {RUTA_GEOPARQUET_SALIDA}. \"\n",
        "          f\"Revisa los mensajes de error anteriores.\")"
      ],
      "metadata": {
        "id": "Q7Ur-eIOxkKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./inegi_data/marco_geoestadistico_shp/shp_extraidos/m/09m.geoparquet')"
      ],
      "metadata": {
        "id": "Tln-4dARyV5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación de la Tabla `manzanas` en DuckDB: Integrando los Mapas a la Base de Datos**\n",
        "\n",
        "**Concepto Clave: Hacer que Nuestras Geometrías (Mapas) sean Consultables con SQL**\n",
        "\n",
        "Ya hemos convertido nuestros Shapefiles de manzanas al eficiente formato GeoParquet. El siguiente paso es cargar estos datos geoespaciales en nuestra base de datos DuckDB. Al hacerlo, crearemos una tabla (que llamaremos `manzanas`) donde cada fila representará una manzana y contendrá tanto sus atributos (información descriptiva que venía en el `.dbf` original) como, lo más importante, su **geometría** (el polígono que define su forma).\n",
        "\n",
        "1.  **Lectura Directa de GeoParquet por DuckDB:**\n",
        "    *   Una de las grandes ventajas de DuckDB, cuando se usa con su extensión `spatial`, es que puede **leer archivos GeoParquet directamente** y entender su contenido geoespacial.\n",
        "    *   No necesitamos un proceso de importación complejo. Podemos usar una función similar a `read_csv_auto` que vimos antes, pero específica para Parquet: `read_parquet()`.\n",
        "\n",
        "2.  **Creación de la Tabla `manzanas` en DuckDB:**\n",
        "    *   Al igual que con la tabla `censo_all`, usaremos una instrucción `CREATE TABLE AS SELECT` para construir nuestra tabla `manzanas`:\n",
        "        ```sql\n",
        "        -- DROP TABLE IF EXISTS manzanas; -- Para empezar limpio\n",
        "        -- CREATE TABLE manzanas AS\n",
        "        -- SELECT *\n",
        "        -- FROM read_parquet('ruta/a/manzanas.geoparquet');\n",
        "        ```\n",
        "    *   **`DROP TABLE IF EXISTS manzanas;`**: Elimina la tabla si ya existe, para asegurar una creación limpia en cada ejecución.\n",
        "    *   **`CREATE TABLE manzanas AS SELECT * ...`**: Crea la tabla `manzanas` con la estructura y datos provenientes de la lectura del archivo GeoParquet.\n",
        "    *   **`FROM read_parquet('ruta/a/manzanas.geoparquet')`**: DuckDB leerá todas las columnas del archivo GeoParquet. Crucialmente, si el GeoParquet está bien formado (como el que creamos con GeoPandas), DuckDB reconocerá la columna que contiene las geometrías y la tratará como un tipo de dato espacial especial.\n",
        "\n",
        "3.  **La Columna `geometry`:**\n",
        "    *   Dentro de la tabla `manzanas` que se crea, habrá una columna (usualmente llamada `geometry` por convención de GeoPandas y GeoParquet) que almacena los datos geométricos de cada manzana.\n",
        "    *   Con la extensión `spatial` de DuckDB activa, podremos realizar **consultas y operaciones espaciales directamente sobre esta columna `geometry` usando SQL** (por ejemplo, verificar si un punto está dentro de una manzana, calcular el área de las manzanas, unir manzanas con otras capas espaciales, etc.).\n",
        "\n",
        "4.  **¿Por Qué Crear una Tabla en DuckDB en Lugar de Usar el GeoParquet Directamente Siempre?**\n",
        "    *   **Persistencia y Organización:** Tener los datos en una tabla dentro de nuestro archivo `.duckdb` los mantiene organizados junto con nuestros datos censales.\n",
        "    *   **Rendimiento en Consultas Repetidas:** Aunque `read_parquet()` es rápido, si vamos a consultar estos datos geoespaciales muchas veces o en combinación con otras tablas, tenerlos ya cargados en una tabla de DuckDB puede ser más eficiente. DuckDB puede aplicar sus propias optimizaciones internas, crear índices (si fuera necesario en escenarios más avanzados), etc.\n",
        "    *   **Unificación del Entorno de Análisis:** Nos permite usar SQL como el lenguaje principal para interactuar tanto con los datos tabulares del censo como con los datos geoespaciales de los mapas, todo dentro del mismo entorno de DuckDB.\n",
        "\n",
        "Al finalizar este paso, tendremos dos tablas principales en nuestra base de datos DuckDB:\n",
        "*   `censo_all`: Con los datos demográficos y socioeconómicos por manzana.\n",
        "*   `manzanas`: Con los atributos y, fundamentalmente, las geometrías (polígonos) de cada manzana.\n",
        "\n",
        "El siguiente gran paso será unir estas dos tablas para tener una visión completa: cada manzana con sus datos censales Y su forma geográfica."
      ],
      "metadata": {
        "id": "Y2oSqO1uzH-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 11: Creación de la Tabla 'manzanas' en DuckDB desde GeoParquet\n",
        "# -----------------------------------------------------------------\n",
        "# En esta celda, cargaremos el archivo GeoParquet (que contiene las geometrías\n",
        "# y atributos de las manzanas) en una nueva tabla dentro de nuestra base de\n",
        "# datos DuckDB. Esta tabla se llamará 'manzanas'.\n",
        "\n",
        "print(f\"--- Creando la Tabla 'manzanas' en DuckDB desde el archivo GeoParquet ---\")\n",
        "\n",
        "# La ruta al archivo GeoParquet de salida fue definida en la Celda 10\n",
        "# como RUTA_GEOPARQUET_SALIDA (ej. ./inegi_data/marco_geoestadistico_shp/shp_extraidos/m/09m.geoparquet)\n",
        "\n",
        "# 1. Verificar que el archivo GeoParquet exista\n",
        "if not os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"¡ERROR CRÍTICO! No se encontró el archivo GeoParquet en: '{RUTA_GEOPARQUET_SALIDA}'.\")\n",
        "    print(f\"La tabla 'manzanas' no se puede crear.\")\n",
        "    print(f\"Asegúrate de que la Celda 10 (conversión a GeoParquet) se haya ejecutado correctamente.\")\n",
        "    # Detener el script si el archivo crucial no existe.\n",
        "    # Descomenta la siguiente línea para forzar la detención:\n",
        "    # raise FileNotFoundError(f\"Archivo GeoParquet no encontrado: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "else:\n",
        "    print(f\"Archivo GeoParquet encontrado: '{RUTA_GEOPARQUET_SALIDA}'. Procediendo a crear la tabla 'manzanas'.\")\n",
        "\n",
        "    try:\n",
        "        # 2. Eliminar la tabla 'manzanas' si ya existe (para empezar de cero)\n",
        "        con.execute(\"DROP TABLE IF EXISTS manzanas;\")\n",
        "        print(\"Tabla 'manzanas' eliminada si existía previamente.\")\n",
        "\n",
        "        # 3. Crear la tabla 'manzanas' directamente desde el archivo GeoParquet\n",
        "        # DuckDB (con la extensión 'spatial' cargada) puede leer GeoParquet\n",
        "        # y reconocerá automáticamente la columna de geometría.\n",
        "        # 'SELECT *' tomará todas las columnas del GeoParquet.\n",
        "        sql_create_table_from_geoparquet = f\"\"\"\n",
        "        CREATE TABLE manzanas AS\n",
        "        SELECT *\n",
        "        FROM read_parquet('{RUTA_GEOPARQUET_SALIDA}');\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nEjecutando la creación de la tabla 'manzanas' desde GeoParquet...\")\n",
        "        con.execute(\"BEGIN TRANSACTION;\") # Iniciar transacción\n",
        "        con.execute(sql_create_table_from_geoparquet)\n",
        "        con.execute(\"COMMIT;\") # Confirmar transacción\n",
        "        print(\"¡Tabla 'manzanas' creada y poblada exitosamente desde el archivo GeoParquet!\")\n",
        "\n",
        "        # 4. Verificar la tabla creada (opcional, pero muy recomendable)\n",
        "        print(\"\\nVerificando la tabla 'manzanas'...\")\n",
        "\n",
        "        # Contar filas en la nueva tabla\n",
        "        num_filas_manzanas = con.execute(\"SELECT COUNT(*) FROM manzanas;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas (manzanas) en la tabla 'manzanas': {num_filas_manzanas}\")\n",
        "\n",
        "        if num_filas_manzanas == 0:\n",
        "            print(\"  ADVERTENCIA: La tabla 'manzanas' está vacía. Verifica el archivo GeoParquet.\")\n",
        "\n",
        "        # Mostrar la estructura (nombres de columna y tipos)\n",
        "        print(\"\\n  Estructura de la tabla 'manzanas' (DESCRIBE):\")\n",
        "        describe_manzanas_df = con.execute(\"DESCRIBE manzanas;\").fetchdf()\n",
        "        print(describe_manzanas_df)\n",
        "\n",
        "        # Verificar si la columna 'geometry' existe y qué tipo tiene\n",
        "        geometry_col_info = describe_manzanas_df[describe_manzanas_df['column_name'].str.lower() == 'geometry']\n",
        "        if not geometry_col_info.empty:\n",
        "            print(f\"\\n  Información de la columna 'geometry':\")\n",
        "            print(geometry_col_info)\n",
        "            if 'GEOMETRY' not in geometry_col_info['column_type'].iloc[0].upper():\n",
        "                print(f\"    ADVERTENCIA: El tipo de la columna 'geometry' es '{geometry_col_info['column_type'].iloc[0]}', no parece ser un tipo GEOMETRY. \"\n",
        "                      \"Esto podría indicar un problema con el GeoParquet o la extensión espacial de DuckDB.\")\n",
        "            else:\n",
        "                print(f\"    La columna 'geometry' parece tener un tipo espacial correcto.\")\n",
        "        else:\n",
        "            print(\"\\n  ADVERTENCIA: No se encontró una columna llamada 'geometry' (ignorando mayúsculas/minúsculas) en la tabla 'manzanas'.\")\n",
        "            print(\"    Esto es inesperado para datos geoespaciales. Verifica el contenido del GeoParquet.\")\n",
        "\n",
        "\n",
        "        # Mostrar algunas columnas de las primeras filas, incluyendo una representación WKT de la geometría\n",
        "        # si la columna 'geometry' fue reconocida correctamente.\n",
        "        if not geometry_col_info.empty and 'GEOMETRY' in geometry_col_info['column_type'].iloc[0].upper():\n",
        "            print(\"\\n  Primeras 3 filas de 'manzanas' (con geometría como WKT abreviado):\")\n",
        "            # Seleccionar algunas columnas de atributos comunes del Marco Geoestadístico y la geometría.\n",
        "            # Los nombres CVEGEO, CVE_ENT, etc. son comunes. Ajusta si tus columnas se llaman diferente.\n",
        "            preview_cols = []\n",
        "            for col in ['CVEGEO', 'CVE_ENT', 'CVE_MUN', 'CVE_LOC', 'CVE_AGEB', 'CVE_MZA']:\n",
        "                if col in describe_manzanas_df['column_name'].tolist():\n",
        "                    preview_cols.append(col)\n",
        "\n",
        "            if preview_cols:\n",
        "                sql_preview_manzanas = f\"\"\"\n",
        "                SELECT {', '.join(preview_cols)}, ST_AsText(geometry) AS geometria_wkt\n",
        "                FROM manzanas\n",
        "                LIMIT 3;\n",
        "                \"\"\"\n",
        "                df_preview_manzanas = con.execute(sql_preview_manzanas).fetchdf()\n",
        "                print(df_preview_manzanas)\n",
        "            else:\n",
        "                print(\"    No se encontraron columnas de clave geográfica comunes para la vista previa, mostrando solo geometrías.\")\n",
        "                df_preview_manzanas_geom_only = con.execute(\"SELECT ST_AsText(geometry) AS geometria_wkt FROM manzanas LIMIT 3;\").fetchdf()\n",
        "                print(df_preview_manzanas_geom_only)\n",
        "        else:\n",
        "            print(\"\\n  No se puede mostrar la vista previa de geometrías porque la columna 'geometry' no se detectó correctamente.\")\n",
        "\n",
        "\n",
        "    except duckdb.CatalogException as e:\n",
        "        print(f\"¡ERROR DE CATÁLOGO de DuckDB al crear 'manzanas'!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "    except duckdb.IOException as e: # Podría ocurrir si hay problemas leyendo el Parquet\n",
        "        print(f\"¡ERROR DE ENTRADA/SALIDA (IOException) de DuckDB al leer GeoParquet para 'manzanas'!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'manzanas' desde GeoParquet!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "\n",
        "print(\"\\n--- Proceso de creación de la tabla 'manzanas' completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "QU2nghfZyZrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unión de Datos Censales y Geometrías: Creando la Tabla `censo_geo`**\n",
        "\n",
        "**Concepto Clave: ¡La Fusión Mágica! Combinando Estadísticas con Mapas**\n",
        "\n",
        "Este es uno de los momentos más importantes de nuestro proceso. Hasta ahora, tenemos dos conjuntos de datos principales en nuestra base de datos DuckDB:\n",
        "\n",
        "1.  **`censo_all`**: Una tabla con una gran cantidad de variables demográficas y socioeconómicas provenientes del censo (población, vivienda, educación, etc.), donde cada fila idealmente representa una manzana.\n",
        "2.  **`manzanas`**: Una tabla que contiene los atributos geográficos (como claves de identificación) y, crucialmente, las **geometrías** (los polígonos que dibujan la forma) de cada manzana.\n",
        "\n",
        "El objetivo ahora es **unir estas dos tablas** para crear una nueva tabla, que llamaremos `censo_geo`. En esta tabla `censo_geo`, cada fila seguirá representando una manzana, pero ahora tendrá **tanto sus datos censales como su geometría asociada**. ¡Esto nos permitirá hacer mapas temáticos, análisis espaciales y mucho más!\n",
        "\n",
        "**La Clave de la Unión: `CVEGEO` (Clave Geoestadística)**\n",
        "\n",
        "*   ¿Cómo sabe la base de datos qué fila de `censo_all` corresponde a qué fila (y por tanto, a qué polígono) de la tabla `manzanas`? La respuesta está en una **clave única de identificación geográfica**.\n",
        "*   El INEGI utiliza una **Clave Geoestadística (`CVEGEO`)** que identifica de manera única a cada unidad geográfica (estado, municipio, localidad, AGEB, y manzana). Esta clave se construye concatenando (uniendo) los códigos de cada uno de estos niveles. Para una manzana, la estructura típica es:\n",
        "    *   `[Código de Entidad (2 dígitos)]`\n",
        "    *   `[Código de Municipio (3 dígitos)]`\n",
        "    *   `[Código de Localidad (4 dígitos)]`\n",
        "    *   `[Código de AGEB (4 dígitos)]`\n",
        "    *   `[Código de Manzana (3 dígitos)]`\n",
        "    *   Ejemplo: `0900200011234001` (donde `09` es CDMX, `002` es una alcaldía, `0001` una localidad, `1234` un AGEB, y `001` una manzana).\n",
        "\n",
        "*   **Nuestra Tarea:**\n",
        "    1.  Nos aseguraremos de que tanto la tabla `censo_all` como la tabla `manzanas` tengan una columna que represente esta `CVEGEO` completa.\n",
        "        *   En `censo_all`, la construiremos concatenando las columnas `ENTIDAD`, `MUN`, `LOC`, `AGEB`, `MZA` (asegurándonos de usar `LPAD` para que cada código tenga la longitud correcta con ceros a la izquierda si es necesario).\n",
        "        *   En `manzanas`, el Shapefile original del INEGI a menudo ya incluye columnas como `CVE_ENT`, `CVE_MUN`, `CVE_LOC`, `CVE_AGEB`, `CVE_MZA`, o incluso una columna `CVEGEO` ya construida. Si no, la construiremos de manera similar.\n",
        "    2.  Once both tables have this common `CVEGEO` column, we can join them using an SQL `JOIN` operation.\n",
        "\n",
        "**Construcción de la Tabla `censo_geo` con SQL y CTEs**\n",
        "\n",
        "Usaremos una consulta SQL organizada con **`Common Table Expressions` (CTEs)**.\n",
        "*   **¿Qué es una CTE?** Una CTE (definida con la cláusula `WITH`) es como una **tabla temporal con nombre** que existe solo durante la ejecución de una única consulta SQL. Nos ayudan a dividir consultas complejas en pasos más pequeños y legibles, haciendo el código SQL más fácil de entender y mantener.\n",
        "\n",
        "Nuestra consulta SQL tendrá la siguiente estructura:\n",
        "\n",
        "1.  **CTE `censo_con_cvegeo`**: Usando `WITH`, definiremos esta \"tabla temporal\" que tomará los datos de `censo_all` y le añadirá una nueva columna `CVEGEO`, construida a partir de sus componentes (`ENTIDAD`, `MUN`, etc.).\n",
        "2.  **CTE `manzanas_con_cvegeo`**: Similarmente, definiremos esta otra \"tabla temporal\" que tomará los datos de `manzanas` (especialmente la columna `geometry`) y también generará o se asegurará de que tenga la columna `CVEGEO`.\n",
        "3.  **`SELECT` Final con `INNER JOIN`**:\n",
        "    *   La consulta principal `SELECT` unirá (`JOIN`) las dos CTEs que acabamos de definir, usando la condición `censo_con_cvegeo.CVEGEO = manzanas_con_cvegeo.CVEGEO`.\n",
        "    *   Usaremos un `INNER JOIN`. Esto significa que solo se incluirán en `censo_geo` aquellas manzanas que tengan una entrada correspondiente tanto en la tabla del censo como en la tabla de geometrías. Si una manzana aparece en el censo pero no tiene geometría, o viceversa, no se incluirá en el resultado final de `censo_geo`.\n",
        "    *   Seleccionaremos las columnas deseadas: el `CVEGEO` unificado, todas las variables censales de la CTE del censo, y la columna `geometry` de la CTE de manzanas.\n",
        "    *   El resultado de esta consulta `SELECT` se usará para crear la nueva tabla `censo_geo` (`CREATE TABLE censo_geo AS ...`).\n",
        "\n",
        "**¿Por Qué una Nueva Tabla `censo_geo`?**\n",
        "\n",
        "*   **Datos Enriquecidos en un Solo Lugar:** `censo_geo` contendrá la información completa: cada manzana con sus características demográficas y su representación espacial.\n",
        "*   **Facilidad para Análisis y Visualización:** Tener todo en una tabla simplifica enormemente la creación de mapas temáticos (ej. pintar manzanas según su población), la realización de consultas espaciales (ej. \"¿cuántas personas viven a menos de 500 metros de este punto?\"), y la exportación de datos para otras herramientas.\n",
        "\n",
        "La tabla `censo_geo` es la **culminación de nuestro proceso de integración de datos**. Es el conjunto de datos enriquecido que nos permitirá realizar análisis geoespaciales significativos."
      ],
      "metadata": {
        "id": "qWXLuNdy0JvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 12: Unión de Datos Censales y Geometrías para Crear 'censo_geo'\n",
        "# --------------------------------------------------------------------\n",
        "# Este es un paso crucial donde combinamos nuestros datos censales (de 'censo_all')\n",
        "# con nuestros datos geoespaciales (de 'manzanas').\n",
        "# La unión se realizará utilizando una Clave Geoestadística (CVEGEO) común,\n",
        "# que construiremos para ambas tablas si es necesario.\n",
        "# La tabla resultante, 'censo_geo', contendrá tanto los atributos censales\n",
        "# como la geometría para cada manzana.\n",
        "\n",
        "print(f\"--- Creando la Tabla 'censo_geo' mediante la unión de 'censo_all' y 'manzanas' ---\")\n",
        "\n",
        "# 1. Verificar que las tablas de entrada ('censo_all' y 'manzanas') existan y tengan datos\n",
        "error_preparacion = False\n",
        "try:\n",
        "    num_filas_censo_all = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "    if num_filas_censo_all == 0:\n",
        "        print(\"ADVERTENCIA: La tabla 'censo_all' está vacía. La unión no producirá resultados.\")\n",
        "        error_preparacion = True\n",
        "    else:\n",
        "        print(f\"Tabla 'censo_all' verificada, contiene {num_filas_censo_all} filas.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al verificar 'censo_all': {e}. No se puede continuar.\")\n",
        "    error_preparacion = True\n",
        "\n",
        "try:\n",
        "    num_filas_manzanas = con.execute(\"SELECT COUNT(*) FROM manzanas;\").fetchone()[0]\n",
        "    if num_filas_manzanas == 0:\n",
        "        print(\"ADVERTENCIA: La tabla 'manzanas' está vacía. La unión no producirá resultados.\")\n",
        "        error_preparacion = True\n",
        "    else:\n",
        "        print(f\"Tabla 'manzanas' verificada, contiene {num_filas_manzanas} filas.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al verificar 'manzanas': {e}. No se puede continuar.\")\n",
        "    error_preparacion = True\n",
        "\n",
        "if error_preparacion:\n",
        "    print(\"¡ERROR CRÍTICO! Una o ambas tablas de entrada ('censo_all', 'manzanas') están vacías o no son accesibles.\")\n",
        "    print(\"La tabla 'censo_geo' no se creará. Revisa las celdas anteriores.\")\n",
        "    # Detener si las tablas base no están listas\n",
        "    # Descomenta la siguiente línea para forzar la detención:\n",
        "    # raise ValueError(\"Tablas de entrada para la unión no están listas.\")\n",
        "else:\n",
        "    print(\"\\nTablas de entrada ('censo_all' y 'manzanas') listas para la unión.\")\n",
        "    try:\n",
        "        # 2. Eliminar la tabla 'censo_geo' si ya existe\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_geo;\")\n",
        "        print(\"Tabla 'censo_geo' eliminada si existía previamente.\")\n",
        "\n",
        "        # 3. Construir la consulta SQL para crear 'censo_geo'\n",
        "        # Usaremos Common Table Expressions (CTEs) para mayor claridad:\n",
        "        #   - Una CTE para preparar 'censo_all' con su CVEGEO.\n",
        "        #   - Una CTE para preparar 'manzanas' con su CVEGEO.\n",
        "        # Luego, unimos estas CTEs.\n",
        "\n",
        "        # Obtener la lista de columnas de 'censo_all' para seleccionarlas dinámicamente\n",
        "        # y evitar listar manualmente cientos de columnas.\n",
        "        # Excluimos las columnas que forman parte de la clave CVEGEO individualmente,\n",
        "        # ya que tendremos la CVEGEO completa.\n",
        "        describe_censo_all_df = con.execute(\"DESCRIBE censo_all;\").fetchdf()\n",
        "        columnas_censo_all = describe_censo_all_df['column_name'].tolist()\n",
        "\n",
        "        # Columnas a excluir de la selección directa de 'censo_all' porque ya estarán en CVEGEO o son redundantes\n",
        "        # Se pueden ajustar según sea necesario.\n",
        "        cols_a_excluir_de_censo_select = ['ENTIDAD', 'MUN', 'LOC', 'AGEB', 'MZA']\n",
        "        # Algunas implementaciones de EXCLUDE pueden necesitar que las columnas existan.\n",
        "        # Asegurémonos de que solo intentamos excluir las que realmente están.\n",
        "        cols_a_excluir_filtradas = [col for col in cols_a_excluir_de_censo_select if col in columnas_censo_all]\n",
        "\n",
        "\n",
        "        select_cols_censo_str = \", \".join([f\"c.\\\"{col}\\\"\" for col in columnas_censo_all if col not in cols_a_excluir_filtradas])\n",
        "        # Si la lista de columnas es muy larga, o por simplicidad, se podría usar c.* y luego manejar duplicados si los hay.\n",
        "        # O usar la sintaxis `c.* EXCLUDE (ENTIDAD, MUN, LOC, AGEB, MZA)` si la versión de DuckDB lo soporta bien.\n",
        "        # Por robustez con nombres de columnas, la enumeración explícita o el filtrado como arriba es más seguro.\n",
        "\n",
        "        # Nombres de las columnas que forman la clave en la tabla 'manzanas'.\n",
        "        # Comúnmente son CVE_ENT, CVE_MUN, etc. ¡Verifica esto con tu tabla 'manzanas'!\n",
        "        # Puedes usar DESCRIBE manzanas; para ver los nombres exactos.\n",
        "        # Por ahora, asumimos los nombres comunes del Marco Geoestadístico del INEGI.\n",
        "        manzanas_cols_cve = {\n",
        "            'ent': 'CVE_ENT', 'mun': 'CVE_MUN', 'loc': 'CVE_LOC',\n",
        "            'ageb': 'CVE_AGEB', 'mza': 'CVE_MZA'\n",
        "        }\n",
        "        # Verificar que estas columnas existan en 'manzanas'\n",
        "        describe_manzanas_df = con.execute(\"DESCRIBE manzanas;\").fetchdf()\n",
        "        manzanas_actual_cols = describe_manzanas_df['column_name'].tolist()\n",
        "        for key, col_name in manzanas_cols_cve.items():\n",
        "            if col_name not in manzanas_actual_cols:\n",
        "                print(f\"  ADVERTENCIA: La columna esperada '{col_name}' para construir CVEGEO no se encontró en la tabla 'manzanas'.\")\n",
        "                print(f\"  La unión podría fallar o ser incorrecta. Verifica los nombres de columna en 'manzanas'.\")\n",
        "                # Podrías querer reemplazar con un nombre alternativo o detener si es crítico.\n",
        "\n",
        "\n",
        "        sql_create_censo_geo = f\"\"\"\n",
        "        CREATE TABLE censo_geo AS\n",
        "        WITH censo_con_cvegeo AS (\n",
        "            SELECT\n",
        "                -- Construir CVEGEO: ENT(2)MUN(3)LOC(4)AGEB(4)MZA(3)\n",
        "                -- Asegurar CAST a VARCHAR antes de LPAD si las columnas son numéricas.\n",
        "                CONCAT(\n",
        "                    LPAD(CAST(ENTIDAD AS VARCHAR), 2, '0'),\n",
        "                    LPAD(CAST(MUN AS VARCHAR), 3, '0'),\n",
        "                    LPAD(CAST(LOC AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(AGEB AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(MZA AS VARCHAR), 3, '0')\n",
        "                ) AS CVEGEO_Censo,\n",
        "                * -- Seleccionar todas las columnas de censo_all\n",
        "            FROM censo_all\n",
        "            -- El filtro MZA != '0' ya se aplicó al crear censo_all\n",
        "        ),\n",
        "        manzanas_con_cvegeo AS (\n",
        "            SELECT\n",
        "                -- Construir CVEGEO para la tabla de manzanas\n",
        "                -- Los nombres de columna (CVE_ENT, etc.) deben coincidir con los de tu tabla 'manzanas'\n",
        "                CONCAT(\n",
        "                    LPAD(CAST({manzanas_cols_cve['ent']} AS VARCHAR), 2, '0'),\n",
        "                    LPAD(CAST({manzanas_cols_cve['mun']} AS VARCHAR), 3, '0'),\n",
        "                    LPAD(CAST({manzanas_cols_cve['loc']} AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST({manzanas_cols_cve['ageb']} AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST({manzanas_cols_cve['mza']} AS VARCHAR), 3, '0')\n",
        "                ) AS CVEGEO_Manzana,\n",
        "                geometry -- Solo necesitamos la geometría de las manzanas (y cualquier otro atributo relevante si lo hay)\n",
        "                -- Si hay otros atributos en 'manzanas' que quieras conservar, seleccionalos aquí.\n",
        "                -- Por ejemplo: , OTRO_ATRIBUTO_MANZANA\n",
        "            FROM manzanas\n",
        "        )\n",
        "        SELECT\n",
        "            c.CVEGEO_Censo AS CVEGEO, -- Usar el CVEGEO de la tabla del censo como el final\n",
        "            -- Seleccionar todas las columnas originales de censo_all (excepto las usadas para CVEGEO si se desea)\n",
        "            -- usando la lista generada dinámicamente:\n",
        "            {select_cols_censo_str},\n",
        "            -- Si prefieres la sintaxis EXCLUDE (más concisa pero dependiente de la versión de DuckDB):\n",
        "            -- c.* EXCLUDE (ENTIDAD, MUN, LOC, AGEB, MZA, CVEGEO_Censo),\n",
        "            m.geometry\n",
        "        FROM censo_con_cvegeo c\n",
        "        INNER JOIN manzanas_con_cvegeo m ON c.CVEGEO_Censo = m.CVEGEO_Manzana;\n",
        "        -- Usamos INNER JOIN para asegurar que solo se incluyan manzanas presentes en ambas tablas.\n",
        "        -- El original usaba LEFT JOIN + WHERE s.CVEGEO IS NOT NULL, que es equivalente a INNER JOIN.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nEjecutando la creación de la tabla 'censo_geo' (unión)...\")\n",
        "        # print(\"\\nConsulta SQL para crear 'censo_geo':\") # Descomentar para depurar la consulta\n",
        "        # print(sql_create_censo_geo)\n",
        "        con.execute(\"BEGIN TRANSACTION;\")\n",
        "        con.execute(sql_create_censo_geo)\n",
        "        con.execute(\"COMMIT;\")\n",
        "        print(\"¡Tabla 'censo_geo' creada exitosamente mediante la unión!\")\n",
        "\n",
        "        # 4. Verificar la tabla 'censo_geo'\n",
        "        print(\"\\nVerificando la tabla 'censo_geo'...\")\n",
        "        num_filas_censo_geo = con.execute(\"SELECT COUNT(*) FROM censo_geo;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas en 'censo_geo': {num_filas_censo_geo}\")\n",
        "\n",
        "        if num_filas_censo_geo == 0:\n",
        "            print(\"  ADVERTENCIA: La tabla 'censo_geo' está vacía. Esto podría indicar problemas con:\")\n",
        "            print(\"    - La construcción de CVEGEO en una o ambas tablas (longitudes, nombres de columna).\")\n",
        "            print(\"    - Que no haya coincidencias de CVEGEO entre 'censo_all' y 'manzanas'.\")\n",
        "            print(\"    - Que las tablas de entrada estuvieran vacías.\")\n",
        "        else:\n",
        "            print(\"\\n  Estructura (primeras 5 columnas) y primeras 3 filas de 'censo_geo':\")\n",
        "            # Para una vista previa rápida de las columnas:\n",
        "            # print(con.execute(\"DESCRIBE censo_geo;\").fetchdf().head())\n",
        "            # O mejor, ver algunas columnas de los datos, incluyendo la geometría.\n",
        "            # Asegurarse de que 'geometry' y 'POBTOT' (o una columna similar) existan en censo_geo.\n",
        "            preview_cols_final = ['CVEGEO', 'POBTOT'] # Ajusta POBTOT si tu columna de población se llama diferente\n",
        "            describe_censo_geo_df = con.execute(\"DESCRIBE censo_geo;\").fetchdf()\n",
        "            final_cols_for_preview = [col for col in preview_cols_final if col in describe_censo_geo_df['column_name'].tolist()]\n",
        "\n",
        "            if 'geometry' in describe_censo_geo_df['column_name'].tolist() and final_cols_for_preview:\n",
        "                 sql_preview_final = f\"\"\"\n",
        "                 SELECT {', '.join(final_cols_for_preview)}, ST_AsText(geometry) AS geometria_wkt\n",
        "                 FROM censo_geo\n",
        "                 LIMIT 3;\n",
        "                 \"\"\"\n",
        "                 print(con.execute(sql_preview_final).fetchdf())\n",
        "            elif 'geometry' in describe_censo_geo_df['column_name'].tolist():\n",
        "                print(con.execute(\"SELECT CVEGEO, ST_AsText(geometry) AS geometria_wkt FROM censo_geo LIMIT 3;\").fetchdf())\n",
        "            else:\n",
        "                print(\"    No se pudo generar una vista previa con geometría. Verifica la estructura de 'censo_geo'.\")\n",
        "\n",
        "\n",
        "    except duckdb.BinderException as e: # Error común si hay problemas con nombres de columna o funciones\n",
        "        print(f\"¡ERROR DE VINCULACIÓN (BinderException) de DuckDB al crear 'censo_geo'!: {e}\")\n",
        "        print(\"  Esto usualmente significa que un nombre de columna, tabla o función no se encontró o es ambiguo.\")\n",
        "        print(\"  Revisa cuidadosamente los nombres de las columnas en las CTEs y en la unión final,\")\n",
        "        print(\"  especialmente los usados para construir CVEGEO y los seleccionados.\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'censo_geo'!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "\n",
        "print(\"\\n--- Proceso de creación de 'censo_geo' completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "4EfB6msK0KVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Limpieza Final y Revisión: Puliendo el Entorno de Trabajo**\n",
        "\n",
        "**Concepto Clave: Buenas Prácticas para Concluir un Proceso de Datos**\n",
        "\n",
        "Hemos llegado al final de nuestro proceso de integración de datos. Creamos la tabla `censo_geo` que combina la información censal con las geometrías de las manzanas. Antes de dar por terminado nuestro trabajo, es una buena práctica realizar algunas acciones de limpieza y revisión para mantener nuestro entorno de base de datos ordenado y asegurar que todo esté como esperamos.\n",
        "\n",
        "1.  **Eliminación de Tablas Intermedias (Opcional pero Recomendado):**\n",
        "    *   Durante nuestro proceso, creamos tablas como `censo_all` (datos censales crudos) y `manzanas` (datos geométricos crudos). Una vez que hemos creado la tabla final `censo_geo` que las combina, estas tablas originales podrían considerarse **intermedias** o temporales, ya que sus datos ya están integrados en `censo_geo`.\n",
        "    *   Para mantener nuestra base de datos (`.duckdb`) más ligera y evitar confusión con tablas que ya no son el producto final principal, podemos eliminarlas usando la instrucción SQL:\n",
        "        ```sql\n",
        "        -- DROP TABLE IF EXISTS censo_all;\n",
        "        -- DROP TABLE IF EXISTS manzanas;\n",
        "        ```\n",
        "    *   Usar `IF EXISTS` es importante porque evita errores si las tablas ya fueron eliminadas o si el script se ejecuta parcialmente.\n",
        "    *   **Beneficios:**\n",
        "        *   Reduce el tamaño del archivo de la base de datos.\n",
        "        *   Simplifica el esquema de la base de datos, dejando solo las tablas más relevantes.\n",
        "        *   Evita el uso accidental de datos intermedios en análisis futuros si `censo_geo` es la fuente autorizada.\n",
        "\n",
        "2.  **Verificación de Tablas Restantes:**\n",
        "    *   Después de la limpieza (opcional), es una buena idea verificar qué tablas quedan realmente en nuestra base de datos.\n",
        "    *   La consulta `SHOW TABLES;` en DuckDB nos listará todas las tablas existentes. Esto nos ayuda a confirmar que la limpieza se realizó como esperábamos y que nuestra tabla `censo_geo` está presente.\n",
        "    *   Conocer el inventario final de tablas es esencial para la transparencia y para documentar el contenido de nuestra base de datos.\n",
        "\n",
        "3.  **Confirmación de Cambios (`COMMIT`) y Cierre de Conexión (`CLOSE`):**\n",
        "    *   **`con.commit()` (Opcional en algunos contextos con DuckDB):** DuckDB a menudo opera en modo de autocommit para sentencias DDL (como `DROP TABLE`) o DML fuera de transacciones explícitas. Sin embargo, si ha habido transacciones explícitas (`BEGIN TRANSACTION;`) que no se han cerrado con un `COMMIT` o `ROLLBACK`, o si queremos ser absolutamente explícitos, un `con.commit()` final asegura que todos los cambios pendientes se escriban de forma permanente en el archivo de la base de datos.\n",
        "    *   **`con.close()` (Esencial):** Siempre debemos cerrar la conexión a la base de datos cuando hayamos terminado de trabajar con ella. Esto:\n",
        "        *   Libera los recursos que la conexión estaba utilizando.\n",
        "        *   Asegura que todos los datos se escriban correctamente en el disco (flushing).\n",
        "        *   Previene posibles problemas de corrupción o bloqueo del archivo de la base de datos si el script termina abruptamente sin cerrar la conexión.\n",
        "\n",
        "**Ventajas de un Flujo de Trabajo \"Limpio\":**\n",
        "\n",
        "*   **Mantenibilidad:** Un entorno ordenado es más fácil de entender y mantener a largo plazo.\n",
        "*   **Claridad:** Es evidente cuáles son los datos de entrada, los intermedios y los productos finales.\n",
        "*   **Eficiencia:** Evita la acumulación de datos u objetos innecesarios que pueden ralentizar las operaciones o consumir espacio.\n",
        "*   **Profesionalismo:** Demuestra una metodología de trabajo de datos cuidadosa y completa, desde la adquisición hasta la limpieza final.\n",
        "\n",
        "Finalizar nuestro script con estos pasos de limpieza y cierre asegura que nuestro proceso sea robusto, reproducible y que deje la base de datos en un estado predecible y optimizado."
      ],
      "metadata": {
        "id": "whHQvZyK2N8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 13: Limpieza Final de Tablas Intermedias y Cierre de la Conexión\n",
        "# ---------------------------------------------------------------------\n",
        "# Para concluir nuestro proceso, realizaremos algunas acciones de limpieza\n",
        "# y cerraremos la conexión a nuestra base de datos DuckDB.\n",
        "\n",
        "print(f\"--- Iniciando Limpieza Final y Cierre de Conexión ---\")\n",
        "\n",
        "# 1. Eliminación de Tablas Intermedias (Opcional pero Recomendado)\n",
        "# -----------------------------------------------------------------\n",
        "# Una vez que 'censo_geo' ha sido creada, las tablas 'censo_all' y 'manzanas'\n",
        "# pueden considerarse intermedias, ya que sus datos están contenidos o representados\n",
        "# en 'censo_geo'. Eliminarlas puede ayudar a mantener la base de datos más ligera\n",
        "# y organizada.\n",
        "\n",
        "ELIMINAR_TABLAS_INTERMEDIAS = True # Cambia a False si deseas conservar estas tablas\n",
        "\n",
        "if ELIMINAR_TABLAS_INTERMEDIAS:\n",
        "    print(\"\\nEliminando tablas intermedias ('censo_all' y 'manzanas')...\")\n",
        "    try:\n",
        "        # Usamos 'IF EXISTS' para evitar errores si las tablas no existen o ya fueron eliminadas.\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_all;\")\n",
        "        print(\"  Tabla 'censo_all' eliminada (si existía).\")\n",
        "        con.execute(\"DROP TABLE IF EXISTS manzanas;\")\n",
        "        print(\"  Tabla 'manzanas' eliminada (si existía).\")\n",
        "        print(\"Limpieza de tablas intermedias completada.\")\n",
        "    except Exception as e:\n",
        "        # Aunque 'IF EXISTS' debería prevenir la mayoría de los errores,\n",
        "        # capturamos cualquier otra excepción inesperada durante el DROP.\n",
        "        print(f\"  Ocurrió un error durante la eliminación de tablas intermedias: {e}\")\n",
        "else:\n",
        "    print(\"\\nSe conservarán las tablas intermedias 'censo_all' y 'manzanas'.\")\n",
        "\n",
        "# 2. Verificar Tablas Restantes en la Base de Datos\n",
        "# -------------------------------------------------\n",
        "# Es una buena práctica ver qué tablas quedan en la base de datos.\n",
        "print(\"\\nVerificando tablas finales en la base de datos...\")\n",
        "try:\n",
        "    tablas_finales_df = con.execute(\"SHOW TABLES;\").fetchdf()\n",
        "    if not tablas_finales_df.empty:\n",
        "        print(\"Tablas actualmente en la base de datos:\")\n",
        "        print(tablas_finales_df)\n",
        "        # Verificar si 'censo_geo' está presente\n",
        "        if 'censo_geo' in tablas_finales_df['name'].tolist():\n",
        "            print(\"\\n  ¡La tabla principal 'censo_geo' está presente!\")\n",
        "        else:\n",
        "            print(\"\\n  ADVERTENCIA: ¡La tabla principal 'censo_geo' NO se encontró en la base de datos!\")\n",
        "    else:\n",
        "        print(\"No se encontraron tablas en la base de datos (o la base de datos está vacía).\")\n",
        "except Exception as e:\n",
        "    print(f\"  Ocurrió un error al intentar mostrar las tablas: {e}\")\n",
        "\n",
        "# 3. Confirmación de Cambios y Cierre de la Conexión a DuckDB\n",
        "# -----------------------------------------------------------\n",
        "# DuckDB a menudo autocomite transacciones para DDL/DML fuera de bloques explícitos.\n",
        "# Sin embargo, un COMMIT explícito antes de cerrar no hace daño si hubo transacciones\n",
        "# que no se cerraron o para ser absolutamente seguro.\n",
        "# Lo más importante es cerrar la conexión para liberar recursos y asegurar\n",
        "# que todos los datos se escriban correctamente en el archivo de la base de datos.\n",
        "\n",
        "print(\"\\nCerrando la conexión a la base de datos DuckDB...\")\n",
        "try:\n",
        "    # con.commit() # Opcional: DuckDB usualmente autocomite, pero no es dañino.\n",
        "    #                 Si se usaron bloques BEGIN/COMMIT no finalizados, sería necesario.\n",
        "    con.close()\n",
        "    print(\"Conexión a DuckDB cerrada exitosamente.\")\n",
        "\n",
        "    # Verificar si la conexión está realmente cerrada (opcional, para aprendizaje)\n",
        "    # Intentar usar la conexión después de cerrarla debería generar un error.\n",
        "    # try:\n",
        "    #     con.execute(\"SELECT 1;\")\n",
        "    # except Exception as e_closed:\n",
        "    #     print(f\"  (Intento de usar conexión cerrada generó el error esperado: {e_closed})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  Ocurrió un error al cerrar la conexión a DuckDB: {e}\")\n",
        "    print(f\"  Es posible que algunos cambios no se hayan guardado correctamente si la conexión no se cerró bien.\")\n",
        "\n",
        "print(\"\\n--- Script de Procesamiento de Datos Geoespaciales y Censales Finalizado ---\")"
      ],
      "metadata": {
        "id": "zGUOLMGv2Obh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 14: Exportar la tabla 'censo_geo' a un archivo GeoPackage (usando WKT)\n",
        "# ---------------------------------------------------------------------------\n",
        "# En esta celda, leeremos la tabla 'censo_geo' de DuckDB, solicitando la\n",
        "# geometría como WKT (Well-Known Text). Luego, convertiremos estas cadenas WKT\n",
        "# a objetos de geometría de Shapely para crear un GeoDataFrame, y finalmente\n",
        "# lo guardaremos en formato GeoPackage (.gpkg).\n",
        "# Es crucial REABRIR la conexión a DuckDB, ya que la celda anterior la cierra.\n",
        "\n",
        "print(f\"--- Exportando 'censo_geo' a GeoPackage (usando WKT para geometrías) ---\")\n",
        "\n",
        "# 1. Reabrir Conexión a DuckDB y Cargar Extensión Espacial\n",
        "# -------------------------------------------------------\n",
        "con_export = None\n",
        "# DB_FILE_PATH debe estar definido en celdas anteriores\n",
        "print(f\"Intentando reabrir conexión a DuckDB en: {DB_FILE_PATH}\")\n",
        "try:\n",
        "    con_export = duckdb.connect(database=DB_FILE_PATH, read_only=False)\n",
        "    print(\"  Conexión a DuckDB reabierta exitosamente para exportación.\")\n",
        "\n",
        "    print(\"  Cargando la extensión 'spatial' de DuckDB...\")\n",
        "    con_export.execute(\"INSTALL spatial;\")\n",
        "    con_export.execute(\"LOAD spatial;\")\n",
        "    print(\"  Extensión 'spatial' de DuckDB cargada/verificada en la nueva conexión.\")\n",
        "\n",
        "except Exception as e_conn:\n",
        "    print(f\"  ¡ERROR CRÍTICO al reabrir la conexión o cargar la extensión 'spatial'!: {e_conn}\")\n",
        "    # raise # Descomentar para detener.\n",
        "\n",
        "# 2. Leer la Tabla 'censo_geo' solicitando Geometrías como WKT\n",
        "# ----------------------------------------------------------\n",
        "gdf_censo_geo = None\n",
        "if con_export:\n",
        "    print(f\"\\nLeyendo la tabla 'censo_geo' de DuckDB (solicitando geometría como WKT)...\")\n",
        "    try:\n",
        "        table_check = con_export.execute(\"SELECT COUNT(*) FROM information_schema.tables WHERE table_name = 'censo_geo';\").fetchone()\n",
        "        if not table_check or table_check[0] == 0:\n",
        "            print(\"  ¡ERROR! La tabla 'censo_geo' no existe en la base de datos. No se puede exportar.\")\n",
        "        else:\n",
        "            # Consulta SQL para seleccionar todas las columnas y la geometría como WKT\n",
        "            # Usamos ST_AsText(geometry) y le damos un alias, por ejemplo, 'geom_wkt'.\n",
        "            # También seleccionamos todas las demás columnas de 'censo_geo'.\n",
        "            # Para evitar seleccionar la columna 'geometry' original (que podría ser binaria) y la WKT,\n",
        "            # podemos listar explícitamente las columnas de atributos o usar EXCLUDE si funciona bien.\n",
        "            # Por simplicidad aquí, seleccionaremos todo y luego `drop` la original `geometry` si existe además de `geom_wkt`.\n",
        "\n",
        "            sql_query_censo_geo_wkt = \"SELECT *, ST_AsText(geometry) AS geom_wkt FROM censo_geo;\"\n",
        "            df_from_duckdb = con_export.execute(sql_query_censo_geo_wkt).df()\n",
        "\n",
        "            if df_from_duckdb.empty:\n",
        "                print(\"  ADVERTENCIA: La tabla 'censo_geo' está vacía (o la consulta no devolvió filas). \"\n",
        "                      \"Se creará un GeoPackage vacío (si es posible).\")\n",
        "                gdf_censo_geo = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
        "\n",
        "            elif 'geom_wkt' not in df_from_duckdb.columns:\n",
        "                print(\"  ¡ERROR! La columna 'geom_wkt' (geometría como WKT) no se encontró después de la consulta a DuckDB.\")\n",
        "                print(f\"  Columnas disponibles: {df_from_duckdb.columns.tolist()}\")\n",
        "            else:\n",
        "                print(f\"  Datos leídos. Procesando la columna 'geom_wkt' para crear geometrías de Shapely...\")\n",
        "                from shapely import wkt, errors as shapely_errors # Importar para WKT y manejo de errores\n",
        "\n",
        "                # Función para convertir WKT (string) a objeto Shapely, manejando None y errores\n",
        "                def parse_wkt_geometry(wkt_string):\n",
        "                    if wkt_string is None or not isinstance(wkt_string, str) or wkt_string.strip() == \"\":\n",
        "                        return None\n",
        "                    try:\n",
        "                        return wkt.loads(wkt_string)\n",
        "                    except shapely_errors.GEOSException as e_wkt: # Error común al parsear WKT\n",
        "                        # print(f\"    Advertencia: Error al leer WKT '{wkt_string[:50]}...': {e_wkt}. Se devolverá None.\")\n",
        "                        return None\n",
        "                    except Exception as e_gen:\n",
        "                        # print(f\"    Advertencia: Error inesperado al procesar WKT: {e_gen}. Se devolverá None.\")\n",
        "                        return None\n",
        "\n",
        "                parsed_geometries = df_from_duckdb['geom_wkt'].apply(parse_wkt_geometry)\n",
        "\n",
        "                # Crear el GeoDataFrame con las geometrías parseadas y los demás atributos.\n",
        "                # Excluimos la columna 'geom_wkt' y también la columna 'geometry' original\n",
        "                # si fue seleccionada por el SELECT * para evitar duplicados o confusión.\n",
        "                attributes_df = df_from_duckdb.drop(columns=['geom_wkt', 'geometry'], errors='ignore')\n",
        "                gdf_censo_geo = gpd.GeoDataFrame(attributes_df, geometry=parsed_geometries, crs=\"EPSG:4326\")\n",
        "\n",
        "                null_geometries_count = gdf_censo_geo.geometry.isnull().sum()\n",
        "                total_geometries = len(gdf_censo_geo)\n",
        "                print(f\"  GeoDataFrame 'gdf_censo_geo' creado con {total_geometries} filas.\")\n",
        "                if null_geometries_count > 0:\n",
        "                    print(f\"    ADVERTENCIA: {null_geometries_count} de {total_geometries} geometrías son nulas después de la conversión WKT.\")\n",
        "                    print(f\"    Esto podría indicar problemas con los datos de geometría originales o con la función ST_AsText.\")\n",
        "\n",
        "                if gdf_censo_geo.crs is None: # Debería heredar el CRS del constructor, pero por si acaso.\n",
        "                    print(\"    ADVERTENCIA: CRS del GeoDataFrame es None. Reasignando a EPSG:4326.\")\n",
        "                    gdf_censo_geo.set_crs(\"EPSG:4326\", inplace=True)\n",
        "\n",
        "    except Exception as e_read:\n",
        "        print(f\"  ¡ERROR Inesperado al leer 'censo_geo' y/o convertir geometrías WKT!: {e_read}\")\n",
        "        gdf_censo_geo = None\n",
        "\n",
        "# 3. Guardar el GeoDataFrame como Archivo GeoPackage\n",
        "# -------------------------------------------------\n",
        "if gdf_censo_geo is not None:\n",
        "    if gdf_censo_geo.empty and len(gdf_censo_geo.columns) <=1 :\n",
        "         print(f\"\\nADVERTENCIA: El GeoDataFrame 'gdf_censo_geo' está completamente vacío o solo tiene una columna de geometría vacía.\")\n",
        "         print(f\"  Guardar esto resultará en un GeoPackage vacío o podría fallar.\")\n",
        "\n",
        "    NOMBRE_GEOPACKAGE_SALIDA = \"censo_geo_wkt.gpkg\" # Nombre diferente para esta prueba\n",
        "    RUTA_GEOPACKAGE_SALIDA = os.path.join(DIR_BASE_INEGI, NOMBRE_GEOPACKAGE_SALIDA)\n",
        "\n",
        "    print(f\"\\nGuardando GeoDataFrame como GeoPackage en: '{RUTA_GEOPACKAGE_SALIDA}'...\")\n",
        "    try:\n",
        "        if os.path.exists(RUTA_GEOPACKAGE_SALIDA):\n",
        "            print(f\"  Un archivo GeoPackage existente se encontró. Será eliminado y reemplazado.\")\n",
        "            os.remove(RUTA_GEOPACKAGE_SALIDA)\n",
        "\n",
        "        if 'geometry' in gdf_censo_geo.columns or gdf_censo_geo.empty:\n",
        "            gdf_censo_geo.to_file(RUTA_GEOPACKAGE_SALIDA, driver=\"GPKG\", layer=\"censo_manzanas_inegi_wkt\")\n",
        "            print(f\"  ¡GeoDataFrame guardado exitosamente como GeoPackage!\")\n",
        "            print(f\"  Archivo: '{RUTA_GEOPACKAGE_SALIDA}', Capa: 'censo_manzanas_inegi_wkt'\")\n",
        "        else:\n",
        "             print(\"  ADVERTENCIA: El GeoDataFrame final no contiene una columna de geometría. No se guardará el GeoPackage.\")\n",
        "\n",
        "    except Exception as e_save:\n",
        "        print(f\"  ¡ERROR al guardar el GeoDataFrame como GeoPackage!: {e_save}\")\n",
        "else:\n",
        "    print(\"\\nNo se pudo crear el GeoDataFrame 'gdf_censo_geo' o la conexión falló. No se guardará el GeoPackage.\")\n",
        "\n",
        "# 4. Cerrar la Nueva Conexión a DuckDB\n",
        "# ------------------------------------\n",
        "if con_export:\n",
        "    print(\"\\nCerrando la conexión a DuckDB utilizada para la exportación...\")\n",
        "    try:\n",
        "        con_export.close()\n",
        "        print(\"  Conexión de exportación a DuckDB cerrada.\")\n",
        "    except Exception as e_close:\n",
        "        print(f\"  Error al cerrar la conexión de exportación a DuckDB: {e_close}\")\n",
        "\n",
        "print(\"\\n--- Proceso de Exportación a GeoPackage (usando WKT) completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "2RqN4gZz2WF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./inegi_data/censo_geo_wkt.gpkg')"
      ],
      "metadata": {
        "id": "UANGj87u3sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hk0ix64a4fUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}