{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPODrAzYngYONaGEhA3TGEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/UP_Python_2025/blob/main/Semana_04_01_Miercoles_UP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zSuOO91TeBW"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Instalación de Librerías Esenciales\n",
        "# -------------------------------------------\n",
        "# Usamos 'pip install' para añadir a nuestro entorno Python las herramientas (librerías)\n",
        "# que necesitaremos para este proyecto. El comando '--quiet' reduce la cantidad de mensajes\n",
        "# durante la instalación.\n",
        "\n",
        "# Librerías a instalar:\n",
        "# - duckdb: Para nuestra base de datos analítica rápida y basada en archivos.\n",
        "# - geopandas: Para leer, escribir y manipular datos geoespaciales (mapas).\n",
        "# - fsspec: Una dependencia de geopandas para trabajar con diferentes sistemas de archivos.\n",
        "# - matplotlib: Aunque no graficaremos explícitamente, es una dependencia común de geopandas.\n",
        "# - tqdm: Para mostrar barras de progreso visuales durante tareas largas.\n",
        "# - requests: Para descargar archivos de internet (datos del INEGI).\n",
        "# - pyarrow: Para que geopandas y duckdb puedan trabajar eficientemente con el formato GeoParquet.\n",
        "# - folium: Para crear mapas interactivos.\n",
        "# - shapely: Para operaciones geométricas (necesaria con GeoPandas y para WKB/WKT).\n",
        "\n",
        "!pip install duckdb geopandas fsspec matplotlib tqdm requests pyarrow folium shapely --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 2: Importación de Librerías\n",
        "# ----------------------------------\n",
        "# Aquí cargamos las librerías que instalamos o que vienen con Python\n",
        "# para poder usar sus funciones en nuestro código.\n",
        "\n",
        "# --- Para interactuar con el sistema de archivos y utilidades generales ---\n",
        "import os  # Funciones para interactuar con el sistema operativo (rutas, carpetas)\n",
        "import shutil  # Operaciones de alto nivel con archivos y carpetas (ej. borrar carpetas)\n",
        "import time  # Funciones relacionadas con el tiempo (ej. pausas, aunque no la usaremos activamente)\n",
        "from zipfile import ZipFile  # Para trabajar con archivos comprimidos .zip\n",
        "import importlib.metadata # Para checar si pyarrow está instalado\n",
        "\n",
        "# --- Para descargas web y barras de progreso ---\n",
        "import requests  # Para hacer solicitudes HTTP (descargar archivos de internet)\n",
        "from tqdm import tqdm  # Para mostrar barras de progreso visuales\n",
        "\n",
        "# --- Para análisis de datos y geoespacial ---\n",
        "import duckdb  # Para la base de datos analítica DuckDB\n",
        "import geopandas as gpd  # Para trabajar con datos geoespaciales (Shapefiles, GeoParquet)\n",
        "from shapely import wkb, wkt # Para convertir entre WKB/WKT y objetos de geometría\n",
        "from shapely import errors as shapely_errors # Para manejo de errores de shapely\n",
        "\n",
        "# --- Para visualización ---\n",
        "import folium # Para mapas interactivos\n",
        "\n",
        "# (Nota: pyarrow se usa internamente por geopandas y duckdb para Parquet,\n",
        "# no necesitamos importarlo directamente aquí para las operaciones que haremos,\n",
        "# pero su instalación es crucial.)\n",
        "\n",
        "print(\"Librerías importadas exitosamente.\")"
      ],
      "metadata": {
        "id": "yK2nR8K7UMat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 3: Función de Descarga Programática\n",
        "# -----------------------------------------\n",
        "# Esta función se encarga de descargar un archivo desde una URL\n",
        "# y guardarlo en un directorio específico. Incluye una barra de\n",
        "# progreso y evita descargar archivos que ya existen.\n",
        "\n",
        "def download(url, directory):\n",
        "    \"\"\"\n",
        "    Descarga un archivo desde la URL especificada y lo guarda en 'directory'.\n",
        "\n",
        "    Si el archivo ya existe en 'directory', no realiza la descarga de nuevo.\n",
        "    Muestra una barra de progreso durante la descarga.\n",
        "    Detiene el script si ocurre un error HTTP (ej. archivo no encontrado).\n",
        "\n",
        "    Args:\n",
        "        url (str): La URL completa del archivo a descargar.\n",
        "        directory (str): La ruta de la carpeta donde se guardará el archivo.\n",
        "    \"\"\"\n",
        "    # Extraer el nombre del archivo de la URL\n",
        "    filename = url.split('/')[-1]\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"El archivo '{filename}' ya existe en '{directory}'. No se descarga de nuevo.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Descargando '{filename}' de '{url}'...\")\n",
        "    try:\n",
        "        response = requests.get(url, stream=True, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "        progress_bar_params = {\n",
        "            'desc': filename,\n",
        "            'total': total_size_in_bytes,\n",
        "            'unit': 'B',\n",
        "            'unit_scale': True,\n",
        "            'unit_divisor': 1024,\n",
        "            'ncols': 80\n",
        "        }\n",
        "        if total_size_in_bytes == 0:\n",
        "            progress_bar_params.pop('total', None)\n",
        "\n",
        "        with open(filepath, 'wb') as f, tqdm(**progress_bar_params) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "        print(f\"\\nDescarga de '{filename}' completada y guardada en '{filepath}'.\\n\")\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        print(f\"Error HTTP durante la descarga de '{filename}': {http_err}\")\n",
        "        if os.path.exists(filepath): os.remove(filepath)\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error inesperado durante la descarga de '{filename}': {e}\")\n",
        "        if os.path.exists(filepath): os.remove(filepath)\n",
        "        raise"
      ],
      "metadata": {
        "id": "45lnIlmpUQIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 4: Función para Extraer Componentes de Shapefiles desde Archivos ZIP\n",
        "# -----------------------------------------------------------------------\n",
        "def extract_shapefile(list_of_zip_filenames, zip_file_directory, target_shp_output_dir, shape_type_suffix):\n",
        "    \"\"\"\n",
        "    Extrae los componentes de un Shapefile (.shp, .shx, .dbf, .prj, .cpg)\n",
        "    desde los archivos ZIP especificados y los guarda en 'target_shp_output_dir'.\n",
        "    \"\"\"\n",
        "    os.makedirs(target_shp_output_dir, exist_ok=True)\n",
        "    for zip_filename in list_of_zip_filenames:\n",
        "        if '_' in zip_filename:\n",
        "            state_code = zip_filename.split('_')[0]\n",
        "        else:\n",
        "            potential_code = zip_filename[:2]\n",
        "            if potential_code.isdigit():\n",
        "                state_code = potential_code\n",
        "            else:\n",
        "                state_code = os.path.splitext(zip_filename)[0]\n",
        "                print(f\"  Advertencia: No se pudo determinar el código de estado para {zip_filename}. Usando '{state_code}' como base.\")\n",
        "\n",
        "        full_zip_path = os.path.join(zip_file_directory, zip_filename)\n",
        "        if not os.path.exists(full_zip_path):\n",
        "            print(f\"¡ERROR! Archivo ZIP no encontrado: {full_zip_path}. Saltando este archivo.\")\n",
        "            continue\n",
        "\n",
        "        expected_output_basenames = [\n",
        "            f'{state_code}{shape_type_suffix}.shp', f'{state_code}{shape_type_suffix}.cpg',\n",
        "            f'{state_code}{shape_type_suffix}.dbf', f'{state_code}{shape_type_suffix}.prj',\n",
        "            f'{state_code}{shape_type_suffix}.shx'\n",
        "        ]\n",
        "        expected_output_filepaths = [os.path.join(target_shp_output_dir, basename) for basename in expected_output_basenames]\n",
        "        paths_in_zip = [f'conjunto_de_datos/{basename}' for basename in expected_output_basenames]\n",
        "\n",
        "        if all(os.path.exists(filepath) for filepath in expected_output_filepaths):\n",
        "            print(f\"Todos los archivos Shapefile para '{state_code}{shape_type_suffix}' ya existen en '{target_shp_output_dir}'. No se extraen de nuevo.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcesando extracción de Shapefiles para '{state_code}{shape_type_suffix}' de '{zip_filename}'...\")\n",
        "        try:\n",
        "            with ZipFile(full_zip_path, 'r') as zip_ref:\n",
        "                for path_in_zip_archive, target_output_filepath, output_basename in zip(paths_in_zip, expected_output_filepaths, expected_output_basenames):\n",
        "                    if os.path.exists(target_output_filepath):\n",
        "                        print(f\"  Archivo '{output_basename}' ya existe. Saltando.\")\n",
        "                        continue\n",
        "                    try:\n",
        "                        with zip_ref.open(path_in_zip_archive) as source_file, open(target_output_filepath, 'wb') as target_file:\n",
        "                            shutil.copyfileobj(source_file, target_file)\n",
        "                        print(f\"  Extraído: '{output_basename}' a '{target_output_filepath}'\")\n",
        "                    except KeyError:\n",
        "                        if output_basename.endswith('.cpg'):\n",
        "                            try:\n",
        "                                with open(target_output_filepath, 'w') as cpg_file:\n",
        "                                    cpg_file.write(\"ISO-8859-1\") # O UTF-8 según necesidad\n",
        "                                print(f\"  ADVERTENCIA: '{output_basename}' no encontrado. Se creó '{target_output_filepath}' con codificación por defecto.\")\n",
        "                            except Exception as e_cpg:\n",
        "                                print(f\"  ERROR al crear archivo .cpg por defecto '{target_output_filepath}': {e_cpg}\")\n",
        "                        else:\n",
        "                            print(f\"  ¡ERROR CRÍTICO! Archivo esencial '{path_in_zip_archive}' no encontrado en '{zip_filename}'.\")\n",
        "                    except Exception as e_extract:\n",
        "                        print(f\"  ERROR inesperado al extraer '{path_in_zip_archive}': {e_extract}\")\n",
        "            print(f\"Extracción para '{state_code}{shape_type_suffix}' completada.\")\n",
        "        except FileNotFoundError:\n",
        "             print(f\"¡ERROR! Archivo ZIP no encontrado en la ruta: {full_zip_path}\")\n",
        "        except Exception as e_zip:\n",
        "            print(f\"Ocurrió un error general al procesar '{zip_filename}': {e_zip}\")"
      ],
      "metadata": {
        "id": "IbSDu18TUTse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5: Definición de Variables de Configuración y Organización de Carpetas\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# --- Lista de todos los estados de México (comentada para referencia) ---\n",
        "# estados_geo_todos = [\n",
        "#     \"01_aguascalientes.zip\", \"02_bajacalifornia.zip\", \"03_bajacaliforniasur.zip\",\n",
        "#     \"04_campeche.zip\", \"05_coahuiladezaragoza.zip\", \"06_colima.zip\",\n",
        "#     \"07_chiapas.zip\", \"08_chihuahua.zip\", \"09_ciudaddemexico.zip\",\n",
        "#     \"10_durango.zip\", \"11_guanajuato.zip\", \"12_guerrero.zip\",\n",
        "#     \"13_hidalgo.zip\", \"14_jalisco.zip\", \"15_mexico.zip\",\n",
        "#     \"16_michoacandeocampo.zip\", \"17_morelos.zip\", \"18_nayarit.zip\",\n",
        "#     \"19_nuevoleon.zip\", \"20_oaxaca.zip\", \"21_puebla.zip\",\n",
        "#     \"22_queretaro.zip\", \"23_quintanaroo.zip\", \"24_sanluispotosi.zip\",\n",
        "#     \"25_sinaloa.zip\", \"26_sonora.zip\", \"27_tabasco.zip\",\n",
        "#     \"28_tamaulipas.zip\", \"29_tlaxcala.zip\", \"30_veracruzignaciodelallave.zip\",\n",
        "#     \"31_yucatan.zip\", \"32_zacatecas.zip\"\n",
        "# ]\n",
        "# estados_num_todos = [\n",
        "#     1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
        "#     20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32\n",
        "# ]\n",
        "\n",
        "# --- 1. Variables de Configuración del Estado a Procesar (Aguascalientes) ---\n",
        "NOMBRE_ESTADO = \"Aguascalientes\"\n",
        "CODIGO_ESTADO_NUM = 1\n",
        "CODIGO_ESTADO_STR = f\"{CODIGO_ESTADO_NUM:02d}\" # Será \"01\"\n",
        "\n",
        "# Nombre del archivo ZIP del Marco Geoestadístico para Aguascalientes\n",
        "ESTADO_GEO_ZIP_BASENAME = f\"{CODIGO_ESTADO_STR}_aguascalientes\" # \"01_aguascalientes\"\n",
        "ESTADO_GEO_ZIP_FILENAME = f\"{ESTADO_GEO_ZIP_BASENAME}.zip\" # \"01_aguascalientes.zip\"\n",
        "\n",
        "TIPO_SHAPEFILE_MANZANAS = \"m\"\n",
        "\n",
        "print(f\"--- Configuración para el Estado: {NOMBRE_ESTADO} (Código: {CODIGO_ESTADO_STR}) ---\")\n",
        "print(f\"Archivo ZIP del Marco Geoestadístico a buscar: {ESTADO_GEO_ZIP_FILENAME}\")\n",
        "print(f\"Tipo de Shapefile a extraer: Manzanas (sufijo '{TIPO_SHAPEFILE_MANZANAS}')\")\n",
        "\n",
        "# --- 2. Definición de Rutas de Carpetas ---\n",
        "DIR_BASE_INEGI = \"./inegi_data_ags\" # Directorio específico para Aguascalientes\n",
        "DIR_CENSO_CSV_BASE = os.path.join(DIR_BASE_INEGI, \"censo_poblacion_vivienda_csv\")\n",
        "DIR_CENSO_CSV_DESCARGAS = os.path.join(DIR_CENSO_CSV_BASE, \"descargas_zip\")\n",
        "DIR_CENSO_CSV_EXTRAIDOS = os.path.join(DIR_CENSO_CSV_BASE, \"csv_extraidos\")\n",
        "DIR_MARCO_GEO_BASE = os.path.join(DIR_BASE_INEGI, \"marco_geoestadistico_shp\")\n",
        "DIR_MARCO_GEO_DESCARGAS_ZIP = os.path.join(DIR_MARCO_GEO_BASE, \"descargas_zip\")\n",
        "DIR_MARCO_GEO_SHP_EXTRAIDOS = os.path.join(DIR_MARCO_GEO_BASE, \"shp_extraidos\")\n",
        "DIR_SHP_MANZANAS_EXTRAIDOS = os.path.join(DIR_MARCO_GEO_SHP_EXTRAIDOS, TIPO_SHAPEFILE_MANZANAS)\n",
        "DB_FILENAME = f\"inegi_analisis_{CODIGO_ESTADO_STR}.duckdb\" # inegi_analisis_01.duckdb\n",
        "DB_FILE_PATH = os.path.join(DIR_BASE_INEGI, DB_FILENAME)\n",
        "\n",
        "print(f\"\\n--- Rutas de Carpetas Definidas ---\")\n",
        "print(f\"Directorio Base del Proyecto: {os.path.abspath(DIR_BASE_INEGI)}\")\n",
        "print(f\"  CSVs (Descargas ZIP): {os.path.abspath(DIR_CENSO_CSV_DESCARGAS)}\")\n",
        "print(f\"  CSVs (Extraídos): {os.path.abspath(DIR_CENSO_CSV_EXTRAIDOS)}\")\n",
        "print(f\"  Shapefiles (Descargas ZIP): {os.path.abspath(DIR_MARCO_GEO_DESCARGAS_ZIP)}\")\n",
        "print(f\"  Shapefiles Manzanas (Extraídos): {os.path.abspath(DIR_SHP_MANZANAS_EXTRAIDOS)}\")\n",
        "print(f\"  Archivo Base de Datos DuckDB: {os.path.abspath(DB_FILE_PATH)}\")\n",
        "\n",
        "# --- 3. Limpieza Opcional de Directorios Existentes ---\n",
        "LIMPIAR_DIRECTORIOS_ANTES_DE_EJECUTAR = True\n",
        "if LIMPIAR_DIRECTORIOS_ANTES_DE_EJECUTAR:\n",
        "    print(\"\\n--- Limpieza de Directorios (si existen) ---\")\n",
        "    directorios_a_limpiar_base = [DIR_CENSO_CSV_BASE, DIR_MARCO_GEO_BASE]\n",
        "    if os.path.exists(DB_FILE_PATH):\n",
        "        print(f\"Eliminando archivo de base de datos existente: {DB_FILE_PATH}\")\n",
        "        try: os.remove(DB_FILE_PATH)\n",
        "        except Exception as e: print(f\"  No se pudo eliminar {DB_FILE_PATH}: {e}\")\n",
        "    for directorio_base in directorios_a_limpiar_base:\n",
        "        if os.path.exists(directorio_base):\n",
        "            print(f\"Eliminando directorio base existente y su contenido: {directorio_base}\")\n",
        "            try: shutil.rmtree(directorio_base)\n",
        "            except Exception as e: print(f\"  No se pudo eliminar {directorio_base}: {e}\")\n",
        "        else:\n",
        "            print(f\"Directorio base {directorio_base} no existe, no se necesita limpieza.\")\n",
        "else:\n",
        "    print(\"\\n--- Limpieza de Directorios Omitida ---\")\n",
        "\n",
        "# --- 4. Creación de la Estructura de Carpetas Necesaria ---\n",
        "print(\"\\n--- Creación de Estructura de Carpetas Necesarias ---\")\n",
        "directorios_a_crear = [\n",
        "    DIR_BASE_INEGI, DIR_CENSO_CSV_DESCARGAS, DIR_CENSO_CSV_EXTRAIDOS,\n",
        "    DIR_MARCO_GEO_DESCARGAS_ZIP, DIR_SHP_MANZANAS_EXTRAIDOS\n",
        "]\n",
        "for directorio in directorios_a_crear:\n",
        "    try:\n",
        "        os.makedirs(directorio, exist_ok=True)\n",
        "        print(f\"Directorio asegurado/creado: {directorio}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al crear directorio {directorio}: {e}.\")\n",
        "        raise\n",
        "print(\"\\n--- Configuración de variables y carpetas completada. ---\")"
      ],
      "metadata": {
        "id": "6RpMj65MUVyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 6: Conexión a DuckDB e Instalación/Carga de la Extensión Espacial\n",
        "# --------------------------------------------------------------------\n",
        "print(f\"--- Configuración de DuckDB ---\")\n",
        "if os.path.exists(DB_FILE_PATH):\n",
        "    print(f\"Archivo de base de datos ya existe en: {DB_FILE_PATH}\")\n",
        "else:\n",
        "    print(f\"Archivo de base de datos no encontrado. Se creará en: {DB_FILE_PATH}\")\n",
        "\n",
        "print(f\"Conectando a la base de datos DuckDB en: '{DB_FILE_PATH}'...\")\n",
        "try:\n",
        "    con = duckdb.connect(database=DB_FILE_PATH, read_only=False)\n",
        "    print(\"Conexión a DuckDB establecida exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"¡ERROR CRÍTICO al conectar con DuckDB!: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\nInstalando (si es necesario) y cargando la extensión 'spatial' de DuckDB...\")\n",
        "try:\n",
        "    con.execute(\"INSTALL spatial;\")\n",
        "    con.execute(\"LOAD spatial;\")\n",
        "    print(\"Extensión 'spatial' de DuckDB instalada y cargada correctamente.\")\n",
        "except duckdb.IOException as e:\n",
        "    print(f\"¡ERROR DE ENTRADA/SALIDA (IOException) al instalar/cargar la extensión 'spatial'!: {e}\")\n",
        "    print(\"Verifica tu conexión a internet y/o los permisos del directorio de extensiones de DuckDB.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"¡ERROR GENERAL al instalar/cargar la extensión 'spatial'!: {e}\")\n",
        "    raise\n",
        "print(\"\\n--- Configuración de DuckDB completada. ---\")"
      ],
      "metadata": {
        "id": "tesk_Z64Ub2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 7: Descarga y Extracción del Archivo CSV con Datos Censales\n",
        "# -----------------------------------------------------------------\n",
        "print(f\"--- Iniciando Proceso de Descarga y Extracción de CSV para el Estado: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "URL_BASE_CENSO_CSV_INEGI = \"https://www.inegi.org.mx/contenidos/programas/ccpv/2020/datosabiertos/ageb_manzana/\"\n",
        "NOMBRE_ZIP_CENSO = f\"ageb_mza_urbana_{CODIGO_ESTADO_STR}_cpv2020_csv.zip\" # ageb_mza_urbana_01_cpv2020_csv.zip\n",
        "URL_COMPLETA_CENSO_CSV_ZIP = f\"{URL_BASE_CENSO_CSV_INEGI}{NOMBRE_ZIP_CENSO}\"\n",
        "RUTA_DESCARGA_ZIP_CENSO = os.path.join(DIR_CENSO_CSV_DESCARGAS, NOMBRE_ZIP_CENSO)\n",
        "\n",
        "CARPETA_RAIZ_EN_ZIP_CENSO = f\"ageb_mza_urbana_{CODIGO_ESTADO_STR}_cpv2020\"\n",
        "SUBPATH_CSV_EN_ZIP_CENSO = \"conjunto_de_datos\"\n",
        "# El nombre del CSV *dentro* del ZIP es usualmente \"conjunto_de_datos_ageb_urbana_[CODIGO_ESTADO]_cpv2020.csv\"\n",
        "# Sin embargo, algunos estados pueden tener una ligera variación, ej. solo \"conjunto_de_datos_ageb_mza_urbana_[CODIGO_ESTADO]_cpv2020.csv\"\n",
        "# Es crucial verificar el contenido del ZIP si la extracción falla.\n",
        "# Intentaremos con el nombre más común y luego el alternativo si falla.\n",
        "\n",
        "NOMBRE_CSV_ORIGINAL_EN_ZIP_OPCION1 = f\"conjunto_de_datos_ageb_urbana_{CODIGO_ESTADO_STR}_cpv2020.csv\"\n",
        "PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1 = os.path.join(CARPETA_RAIZ_EN_ZIP_CENSO, SUBPATH_CSV_EN_ZIP_CENSO, NOMBRE_CSV_ORIGINAL_EN_ZIP_OPCION1)\n",
        "\n",
        "# Alternativa (a veces encontrada, ej. para CDMX el nombre es un poco diferente, pero para Aguascalientes el de arriba es el correcto)\n",
        "# NOMBRE_CSV_ORIGINAL_EN_ZIP_OPCION2 = f\"conjunto_de_datos_ageb_mza_urbana_{CODIGO_ESTADO_STR}_cpv2020.csv\"\n",
        "# PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION2 = os.path.join(CARPETA_RAIZ_EN_ZIP_CENSO, SUBPATH_CSV_EN_ZIP_CENSO, NOMBRE_CSV_ORIGINAL_EN_ZIP_OPCION2)\n",
        "\n",
        "\n",
        "NOMBRE_CSV_FINAL_EXTRAIDO = f\"censo_manzanas_urbanas_{CODIGO_ESTADO_STR}_cpv2020.csv\"\n",
        "RUTA_FINAL_CSV_EXTRAIDO = os.path.join(DIR_CENSO_CSV_EXTRAIDOS, NOMBRE_CSV_FINAL_EXTRAIDO)\n",
        "\n",
        "print(f\"URL para descarga del ZIP del censo: {URL_COMPLETA_CENSO_CSV_ZIP}\")\n",
        "print(f\"Ruta de descarga del ZIP: {RUTA_DESCARGA_ZIP_CENSO}\")\n",
        "print(f\"Ruta (opción 1) del CSV dentro del ZIP: {PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1}\")\n",
        "print(f\"Ruta final del CSV extraído: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_CENSO):\n",
        "    print(f\"\\nDescargando '{NOMBRE_ZIP_CENSO}'...\")\n",
        "    try:\n",
        "        download(URL_COMPLETA_CENSO_CSV_ZIP, DIR_CENSO_CSV_DESCARGAS)\n",
        "    except Exception as e:\n",
        "        print(f\"  La descarga del ZIP del censo falló: {e}. No se puede continuar.\")\n",
        "        raise\n",
        "else:\n",
        "    print(f\"\\nEl archivo ZIP '{NOMBRE_ZIP_CENSO}' ya existe. No se descarga de nuevo.\")\n",
        "\n",
        "if not os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"\\nExtrayendo CSV de '{NOMBRE_ZIP_CENSO}'...\")\n",
        "    if not os.path.exists(RUTA_DESCARGA_ZIP_CENSO):\n",
        "        print(f\"  ¡ERROR! No se encontró '{RUTA_DESCARGA_ZIP_CENSO}'. No se puede extraer.\")\n",
        "        raise FileNotFoundError(f\"ZIP del censo no encontrado: {RUTA_DESCARGA_ZIP_CENSO}\")\n",
        "    else:\n",
        "        extracted_successfully = False\n",
        "        try:\n",
        "            with ZipFile(RUTA_DESCARGA_ZIP_CENSO, 'r') as zip_ref:\n",
        "                # Intentar Opción 1\n",
        "                print(f\"  Intentando extraer: {PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1}\")\n",
        "                zip_ref.open(PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1) # Probar si existe\n",
        "                with zip_ref.open(PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1) as source_csv, \\\n",
        "                     open(RUTA_FINAL_CSV_EXTRAIDO, 'wb') as target_csv:\n",
        "                    shutil.copyfileobj(source_csv, target_csv)\n",
        "                print(f\"  Archivo CSV extraído exitosamente a: '{RUTA_FINAL_CSV_EXTRAIDO}' usando Opción 1.\")\n",
        "                extracted_successfully = True\n",
        "        except KeyError:\n",
        "            print(f\"  ¡ERROR! No se encontró '{PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION1}' en el ZIP.\")\n",
        "            print(f\"  Verifica la estructura interna del ZIP del INEGI para el estado {CODIGO_ESTADO_STR}.\")\n",
        "            # Podrías añadir aquí el intento con PATH_COMPLETO_CSV_DENTRO_DEL_ZIP_OPCION2 si fuera necesario\n",
        "            # pero para Aguascalientes, la opción 1 es la correcta según la URL de ejemplo.\n",
        "        except Exception as e:\n",
        "            print(f\"  ¡ERROR! Ocurrió un error inesperado durante la extracción: {e}\")\n",
        "            if os.path.exists(RUTA_FINAL_CSV_EXTRAIDO): os.remove(RUTA_FINAL_CSV_EXTRAIDO) # Limpiar si se creó parcialmente\n",
        "            raise\n",
        "        if not extracted_successfully:\n",
        "             print(f\"  Fallo en la extracción del CSV. El archivo {RUTA_FINAL_CSV_EXTRAIDO} no se creó.\")\n",
        "             # Considerar detenerse si la extracción falla\n",
        "             raise RuntimeError(f\"No se pudo extraer el archivo CSV necesario del ZIP {NOMBRE_ZIP_CENSO}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nEl archivo CSV '{NOMBRE_CSV_FINAL_EXTRAIDO}' ya existe. No se extrae de nuevo.\")\n",
        "\n",
        "print(\"\\n--- Proceso de Descarga y Extracción de CSV completado (o intentado). ---\")\n",
        "if os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"Confirmado: El archivo CSV está listo en: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: El archivo CSV final NO se encuentra en: {RUTA_FINAL_CSV_EXTRAIDO}.\")\n",
        "    raise FileNotFoundError(f\"Archivo CSV final no encontrado: {RUTA_FINAL_CSV_EXTRAIDO}\")"
      ],
      "metadata": {
        "id": "ZWGnGJ5oUcQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8: Cargar el CSV de Datos Censales a una Tabla en DuckDB\n",
        "# -------------------------------------------------------------\n",
        "print(f\"--- Cargando Datos del CSV a la Tabla 'censo_all' en DuckDB ---\")\n",
        "if not os.path.exists(RUTA_FINAL_CSV_EXTRAIDO):\n",
        "    print(f\"¡ERROR CRÍTICO! No se encontró '{RUTA_FINAL_CSV_EXTRAIDO}'. La tabla 'censo_all' no se puede crear.\")\n",
        "    raise FileNotFoundError(f\"Archivo CSV del censo no encontrado: {RUTA_FINAL_CSV_EXTRAIDO}\")\n",
        "else:\n",
        "    print(f\"Archivo CSV encontrado: '{RUTA_FINAL_CSV_EXTRAIDO}'. Procediendo a crear la tabla 'censo_all'.\")\n",
        "    try:\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_all;\")\n",
        "        print(\"Tabla 'censo_all' eliminada si existía previamente.\")\n",
        "        # Asegúrate de que la columna 'MZA' exista. El INEGI a veces usa 'MANZANA'.\n",
        "        # Verifica el encabezado del CSV si hay errores aquí.\n",
        "        # Para Aguascalientes, el CSV de \"ageb_mza_urbana_01_cpv2020\" usa MZA.\n",
        "        sql_create_table_from_csv = f\"\"\"\n",
        "        CREATE TABLE censo_all AS\n",
        "        SELECT *\n",
        "        FROM read_csv_auto('{RUTA_FINAL_CSV_EXTRAIDO}',\n",
        "                           NULLSTR=['N/A', 'N/D', '*', ''],\n",
        "                           SAMPLE_SIZE=-1,\n",
        "                           HEADER=TRUE\n",
        "                          )\n",
        "        WHERE MZA != '000';\n",
        "        \"\"\"\n",
        "        print(\"\\nEjecutando la creación de la tabla 'censo_all' desde el CSV...\")\n",
        "        con.execute(\"BEGIN TRANSACTION;\")\n",
        "        con.execute(sql_create_table_from_csv)\n",
        "        con.execute(\"COMMIT;\")\n",
        "        print(\"¡Tabla 'censo_all' creada y poblada exitosamente!\")\n",
        "\n",
        "        print(\"\\nVerificando la tabla 'censo_all'...\")\n",
        "        num_filas = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas en 'censo_all' (con MZA != '000'): {num_filas}\")\n",
        "        if num_filas == 0:\n",
        "            print(\"  ADVERTENCIA: La tabla 'censo_all' está vacía. Verifica el CSV y el filtro MZA.\")\n",
        "\n",
        "        print(\"\\n  Estructura (primeras 5 columnas) y primeras 3 filas de 'censo_all':\")\n",
        "        preview_df = con.execute(\"SELECT ENTIDAD, NOM_ENT, MUN, NOM_MUN, LOC, NOM_LOC, AGEB, MZA, POBTOT FROM censo_all LIMIT 3;\").fetchdf()\n",
        "        if preview_df.empty and num_filas > 0:\n",
        "             print(\"  No se pudieron obtener las columnas de vista previa, pero la tabla tiene filas.\")\n",
        "        elif not preview_df.empty:\n",
        "            print(preview_df)\n",
        "        else:\n",
        "            print(\"  La tabla 'censo_all' parece estar vacía.\")\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'censo_all' desde CSV!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "        raise\n",
        "print(\"\\n--- Proceso de carga de CSV a DuckDB completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "0aqofrcOUfG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8.1: Ejemplos de Consultas SQL Básicas sobre la Tabla 'censo_all'\n",
        "# (Esta celda es opcional, pero útil para verificar)\n",
        "# Se omite para brevedad en la solicitud principal, pero se puede reactivar.\n",
        "print(f\"--- (Opcional) Ejemplos de Consultas SQL sobre la tabla 'censo_all' ---\")\n",
        "try:\n",
        "    num_filas_censo_all_check = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "    if num_filas_censo_all_check > 0:\n",
        "        print(f\"La tabla 'censo_all' contiene {num_filas_censo_all_check} filas.\")\n",
        "        df_ej_nom_mun = con.execute(\"SELECT DISTINCT NOM_MUN FROM censo_all LIMIT 5;\").fetchdf()\n",
        "        print(\"\\nPrimeros 5 municipios/alcaldías encontrados:\")\n",
        "        print(df_ej_nom_mun)\n",
        "\n",
        "        df_ej_pobtot_ags = con.execute(\"\"\"\n",
        "            SELECT NOM_MUN, SUM(TRY_CAST(POBTOT AS BIGINT)) AS PoblacionTotal\n",
        "            FROM censo_all\n",
        "            GROUP BY NOM_MUN\n",
        "            ORDER BY PoblacionTotal DESC;\n",
        "        \"\"\").fetchdf()\n",
        "        print(\"\\nPoblación total por municipio:\")\n",
        "        print(df_ej_pobtot_ags)\n",
        "    else:\n",
        "        print(\"La tabla 'censo_all' está vacía, no se pueden ejecutar ejemplos de consulta.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error ejecutando consultas de ejemplo: {e}\")\n",
        "print(f\"--- Fin de ejemplos SQL opcionales ---\")"
      ],
      "metadata": {
        "id": "W6VYSKIVUkEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 9: Descarga y Extracción del Shapefile de Manzanas\n",
        "# --------------------------------------------------------\n",
        "print(f\"--- Iniciando Proceso de Descarga y Extracción de Shapefiles de Manzanas para: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "URL_BASE_MARCO_GEO_INEGI = \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/\"\n",
        "# ESTADO_GEO_ZIP_FILENAME ya está definido como \"01_aguascalientes.zip\"\n",
        "URL_COMPLETA_MARCO_GEO_ZIP = f\"{URL_BASE_MARCO_GEO_INEGI}{ESTADO_GEO_ZIP_FILENAME}\"\n",
        "RUTA_DESCARGA_ZIP_MARCO_GEO = os.path.join(DIR_MARCO_GEO_DESCARGAS_ZIP, ESTADO_GEO_ZIP_FILENAME)\n",
        "\n",
        "print(f\"URL para descarga del ZIP del Marco Geoestadístico: {URL_COMPLETA_MARCO_GEO_ZIP}\")\n",
        "print(f\"Ruta de descarga del ZIP: {RUTA_DESCARGA_ZIP_MARCO_GEO}\")\n",
        "print(f\"Directorio de salida para Shapefiles de manzanas extraídos: {DIR_SHP_MANZANAS_EXTRAIDOS}\")\n",
        "\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_MARCO_GEO):\n",
        "    print(f\"\\nDescargando '{ESTADO_GEO_ZIP_FILENAME}' (Marco Geoestadístico)...\")\n",
        "    try:\n",
        "        download(URL_COMPLETA_MARCO_GEO_ZIP, DIR_MARCO_GEO_DESCARGAS_ZIP)\n",
        "    except Exception as e:\n",
        "        print(f\"  La descarga del ZIP del Marco Geoestadístico falló: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(f\"\\nEl archivo ZIP '{ESTADO_GEO_ZIP_FILENAME}' ya existe. No se descarga de nuevo.\")\n",
        "\n",
        "print(f\"\\nExtrayendo componentes del Shapefile de tipo '{TIPO_SHAPEFILE_MANZANAS}' (Manzanas)...\")\n",
        "if not os.path.exists(RUTA_DESCARGA_ZIP_MARCO_GEO):\n",
        "    print(f\"  ¡ERROR CRÍTICO! No se encontró '{RUTA_DESCARGA_ZIP_MARCO_GEO}'. No se pueden extraer Shapefiles.\")\n",
        "    raise FileNotFoundError(f\"ZIP del Marco Geoestadístico no encontrado: {RUTA_DESCARGA_ZIP_MARCO_GEO}\")\n",
        "else:\n",
        "    try:\n",
        "        extract_shapefile(\n",
        "            list_of_zip_filenames=[ESTADO_GEO_ZIP_FILENAME],\n",
        "            zip_file_directory=DIR_MARCO_GEO_DESCARGAS_ZIP,\n",
        "            target_shp_output_dir=DIR_SHP_MANZANAS_EXTRAIDOS,\n",
        "            shape_type_suffix=TIPO_SHAPEFILE_MANZANAS\n",
        "        )\n",
        "        print(f\"Proceso de extracción de Shapefiles de manzanas intentado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Ocurrió un error inesperado durante la llamada a extract_shapefile: {e}\")\n",
        "        raise\n",
        "\n",
        "print(\"\\n--- Proceso de Descarga y Extracción de Shapefiles de Manzanas completado (o intentado). ---\")\n",
        "archivo_shp_esperado = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{CODIGO_ESTADO_STR}{TIPO_SHAPEFILE_MANZANAS}.shp\")\n",
        "if os.path.exists(archivo_shp_esperado):\n",
        "    print(f\"Confirmado: '{os.path.basename(archivo_shp_esperado)}' existe en '{DIR_SHP_MANZANAS_EXTRAIDOS}'.\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: '{os.path.basename(archivo_shp_esperado)}' NO se encuentra.\")\n",
        "    raise FileNotFoundError(f\"Archivo SHP principal no encontrado: {archivo_shp_esperado}\")"
      ],
      "metadata": {
        "id": "iH2d8W-UUmF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 10: Conversión de Shapefile a Formato GeoParquet\n",
        "# ----------------------------------------------------\n",
        "print(f\"--- Iniciando Proceso de Conversión de Shapefile a GeoParquet para: {CODIGO_ESTADO_STR} ---\")\n",
        "\n",
        "NOMBRE_SHP_BASE = f\"{CODIGO_ESTADO_STR}{TIPO_SHAPEFILE_MANZANAS}\" # ej: \"01m\"\n",
        "RUTA_SHP_ENTRADA = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{NOMBRE_SHP_BASE}.shp\")\n",
        "RUTA_GEOPARQUET_SALIDA = os.path.join(DIR_SHP_MANZANAS_EXTRAIDOS, f\"{NOMBRE_SHP_BASE}.geoparquet\")\n",
        "\n",
        "print(f\"Archivo Shapefile de entrada: {RUTA_SHP_ENTRADA}\")\n",
        "print(f\"Archivo GeoParquet de salida: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "\n",
        "if not os.path.exists(RUTA_SHP_ENTRADA):\n",
        "    print(f\"  ¡ERROR CRÍTICO! No se encontró '{RUTA_SHP_ENTRADA}'. No se puede convertir.\")\n",
        "    raise FileNotFoundError(f\"Archivo Shapefile de entrada no encontrado: {RUTA_SHP_ENTRADA}\")\n",
        "elif os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"\\nEl GeoParquet '{os.path.basename(RUTA_GEOPARQUET_SALIDA)}' ya existe. No se convierte de nuevo.\")\n",
        "else:\n",
        "    print(f\"\\nIniciando conversión de '{os.path.basename(RUTA_SHP_ENTRADA)}' a GeoParquet...\")\n",
        "    try:\n",
        "        print(f\"  Leyendo Shapefile: '{RUTA_SHP_ENTRADA}'...\")\n",
        "        gdf = gpd.read_file(RUTA_SHP_ENTRADA, encoding='ISO-8859-1') # O 'UTF-8' si es necesario\n",
        "        print(f\"    Shapefile leído. Contiene {len(gdf)} geometrías. CRS original: {gdf.crs}\")\n",
        "\n",
        "        if gdf.crs is None:\n",
        "            crs_asignado_por_defecto = \"EPSG:6372\" # ITRF2008 común para INEGI\n",
        "            print(f\"    ADVERTENCIA: No se detectó CRS. Asignando por defecto: {crs_asignado_por_defecto}. ¡VERIFICAR!\")\n",
        "            gdf.set_crs(crs_asignado_por_defecto, inplace=True)\n",
        "\n",
        "        crs_destino = \"EPSG:4326\" # WGS 84\n",
        "        if gdf.crs != crs_destino:\n",
        "            print(f\"    Reproyectando geometrías de {gdf.crs} a {crs_destino} (WGS 84)...\")\n",
        "            gdf = gdf.to_crs(crs_destino)\n",
        "            print(f\"    Reproyección completada. Nuevo CRS: {gdf.crs}\")\n",
        "        else:\n",
        "            print(f\"    Las geometrías ya están en {crs_destino}. No se reproyecta.\")\n",
        "\n",
        "        print(f\"  Guardando GeoDataFrame como GeoParquet en: '{RUTA_GEOPARQUET_SALIDA}'...\")\n",
        "        gdf.to_parquet(RUTA_GEOPARQUET_SALIDA, index=False)\n",
        "        print(f\"    ¡Conversión a GeoParquet completada!\")\n",
        "    except importlib.metadata.PackageNotFoundError as e_arrow:\n",
        "        print(f\"  ¡ERROR DE DEPENDENCIA! Falta 'pyarrow', necesario para 'to_parquet'. Error: {e_arrow}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"  ¡ERROR GENERAL durante la conversión a GeoParquet!: {e}\")\n",
        "        raise\n",
        "\n",
        "print(\"\\n--- Proceso de Conversión a GeoParquet completado (o intentado). ---\")\n",
        "if os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"Confirmado: GeoParquet listo en: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "else:\n",
        "    print(f\"ADVERTENCIA: GeoParquet NO se encuentra en: {RUTA_GEOPARQUET_SALIDA}.\")\n",
        "    raise FileNotFoundError(f\"Archivo GeoParquet no encontrado: {RUTA_GEOPARQUET_SALIDA}\")"
      ],
      "metadata": {
        "id": "LER02cMWUom7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 11: Creación de la Tabla 'manzanas' en DuckDB desde GeoParquet\n",
        "# -----------------------------------------------------------------\n",
        "print(f\"--- Creando la Tabla 'manzanas' en DuckDB desde el archivo GeoParquet ---\")\n",
        "if not os.path.exists(RUTA_GEOPARQUET_SALIDA):\n",
        "    print(f\"¡ERROR CRÍTICO! No se encontró '{RUTA_GEOPARQUET_SALIDA}'. La tabla 'manzanas' no se puede crear.\")\n",
        "    raise FileNotFoundError(f\"GeoParquet no encontrado: {RUTA_GEOPARQUET_SALIDA}\")\n",
        "else:\n",
        "    print(f\"GeoParquet encontrado: '{RUTA_GEOPARQUET_SALIDA}'. Procediendo a crear la tabla 'manzanas'.\")\n",
        "    try:\n",
        "        con.execute(\"DROP TABLE IF EXISTS manzanas;\")\n",
        "        print(\"Tabla 'manzanas' eliminada si existía previamente.\")\n",
        "        sql_create_table_from_geoparquet = f\"\"\"\n",
        "        CREATE TABLE manzanas AS\n",
        "        SELECT *\n",
        "        FROM read_parquet('{RUTA_GEOPARQUET_SALIDA}');\n",
        "        \"\"\"\n",
        "        print(\"\\nEjecutando la creación de la tabla 'manzanas' desde GeoParquet...\")\n",
        "        con.execute(\"BEGIN TRANSACTION;\")\n",
        "        con.execute(sql_create_table_from_geoparquet)\n",
        "        con.execute(\"COMMIT;\")\n",
        "        print(\"¡Tabla 'manzanas' creada y poblada exitosamente!\")\n",
        "\n",
        "        print(\"\\nVerificando la tabla 'manzanas'...\")\n",
        "        num_filas_manzanas = con.execute(\"SELECT COUNT(*) FROM manzanas;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas (manzanas) en 'manzanas': {num_filas_manzanas}\")\n",
        "        if num_filas_manzanas == 0: print(\"  ADVERTENCIA: La tabla 'manzanas' está vacía.\")\n",
        "\n",
        "        describe_manzanas_df = con.execute(\"DESCRIBE manzanas;\").fetchdf()\n",
        "        print(\"\\n  Estructura de la tabla 'manzanas':\")\n",
        "        print(describe_manzanas_df)\n",
        "        geometry_col_info = describe_manzanas_df[describe_manzanas_df['column_name'].str.lower() == 'geometry']\n",
        "        if not geometry_col_info.empty:\n",
        "            print(f\"\\n  Información de 'geometry': {geometry_col_info['column_type'].iloc[0]}\")\n",
        "            if 'GEOMETRY' not in geometry_col_info['column_type'].iloc[0].upper():\n",
        "                print(\"    ADVERTENCIA: El tipo de 'geometry' no parece ser GEOMETRY.\")\n",
        "            else:\n",
        "                print(f\"    La columna 'geometry' parece tener un tipo espacial correcto.\")\n",
        "                df_preview_manzanas_geom_only = con.execute(\"SELECT ST_AsText(geometry) AS geometria_wkt FROM manzanas LIMIT 1;\").fetchdf()\n",
        "                print(\"    Ejemplo de geometría WKT:\", df_preview_manzanas_geom_only['geometria_wkt'].iloc[0][:100] + \"...\" if not df_preview_manzanas_geom_only.empty else \"N/A\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n  ADVERTENCIA: No se encontró columna 'geometry'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'manzanas'!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "        raise\n",
        "print(\"\\n--- Proceso de creación de la tabla 'manzanas' completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "oJsBcnxSUrz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 12: Unión de Datos Censales y Geometrías para Crear 'censo_geo'\n",
        "# --------------------------------------------------------------------\n",
        "print(f\"--- Creando la Tabla 'censo_geo' mediante la unión de 'censo_all' y 'manzanas' ---\")\n",
        "error_preparacion = False\n",
        "try:\n",
        "    num_filas_censo_all = con.execute(\"SELECT COUNT(*) FROM censo_all;\").fetchone()[0]\n",
        "    if num_filas_censo_all == 0: error_preparacion = True; print(\"ADVERTENCIA: 'censo_all' vacía.\")\n",
        "    else: print(f\"'censo_all' verificada, {num_filas_censo_all} filas.\")\n",
        "    num_filas_manzanas = con.execute(\"SELECT COUNT(*) FROM manzanas;\").fetchone()[0]\n",
        "    if num_filas_manzanas == 0: error_preparacion = True; print(\"ADVERTENCIA: 'manzanas' vacía.\")\n",
        "    else: print(f\"'manzanas' verificada, {num_filas_manzanas} filas.\")\n",
        "except Exception as e:\n",
        "    error_preparacion = True; print(f\"Error verificando tablas: {e}.\")\n",
        "\n",
        "if error_preparacion:\n",
        "    print(\"¡ERROR CRÍTICO! Tablas de entrada no listas. 'censo_geo' no se creará.\")\n",
        "    raise ValueError(\"Tablas de entrada para la unión no están listas.\")\n",
        "else:\n",
        "    print(\"\\nTablas de entrada ('censo_all' y 'manzanas') listas para la unión.\")\n",
        "    try:\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_geo;\")\n",
        "        print(\"Tabla 'censo_geo' eliminada si existía previamente.\")\n",
        "\n",
        "        describe_censo_all_df = con.execute(\"DESCRIBE censo_all;\").fetchdf()\n",
        "        columnas_censo_all = describe_censo_all_df['column_name'].tolist()\n",
        "        cols_a_excluir_de_censo_select = ['ENTIDAD', 'MUN', 'LOC', 'AGEB', 'MZA'] # Ya están en CVEGEO\n",
        "        select_cols_censo_str = \", \".join([f\"c.\\\"{col}\\\"\" for col in columnas_censo_all if col not in cols_a_excluir_de_censo_select])\n",
        "\n",
        "        # Columnas de clave en 'manzanas' (Shapefile del INEGI)\n",
        "        # Usualmente CVEGEO ya existe, o CVE_ENT, CVE_MUN, etc.\n",
        "        # Verificamos si CVEGEO existe en 'manzanas', si no, la construimos.\n",
        "        describe_manzanas_df = con.execute(\"DESCRIBE manzanas;\").fetchdf()\n",
        "        manzanas_cols = describe_manzanas_df['column_name'].tolist()\n",
        "\n",
        "        cvegeo_manzana_expr = \"\"\n",
        "        if 'CVEGEO' in manzanas_cols:\n",
        "            cvegeo_manzana_expr = \"m.CVEGEO\"\n",
        "            print(\"  Se usará la columna 'CVEGEO' existente en la tabla 'manzanas'.\")\n",
        "        elif all(col in manzanas_cols for col in ['CVE_ENT', 'CVE_MUN', 'CVE_LOC', 'CVE_AGEB', 'CVE_MZA']):\n",
        "            print(\"  Se construirá 'CVEGEO' para la tabla 'manzanas' a partir de sus componentes (CVE_ENT, etc.).\")\n",
        "            cvegeo_manzana_expr = \"\"\"\n",
        "                CONCAT(\n",
        "                    LPAD(CAST(m.CVE_ENT AS VARCHAR), 2, '0'),\n",
        "                    LPAD(CAST(m.CVE_MUN AS VARCHAR), 3, '0'),\n",
        "                    LPAD(CAST(m.CVE_LOC AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(m.CVE_AGEB AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(m.CVE_MZA AS VARCHAR), 3, '0')\n",
        "                )\n",
        "            \"\"\"\n",
        "        else:\n",
        "            print(\"  ADVERTENCIA: No se encontró 'CVEGEO' ni todas las columnas CVE_* en 'manzanas'. La unión podría fallar o ser incorrecta.\")\n",
        "            print(f\"  Columnas disponibles en 'manzanas': {manzanas_cols}\")\n",
        "            raise ValueError(\"No se pueden generar/encontrar las claves geoestadísticas en la tabla 'manzanas'\")\n",
        "\n",
        "\n",
        "        sql_create_censo_geo = f\"\"\"\n",
        "        CREATE TABLE censo_geo AS\n",
        "        WITH censo_con_cvegeo AS (\n",
        "            SELECT\n",
        "                CONCAT(\n",
        "                    LPAD(CAST(ENTIDAD AS VARCHAR), 2, '0'),\n",
        "                    LPAD(CAST(MUN AS VARCHAR), 3, '0'),\n",
        "                    LPAD(CAST(LOC AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(AGEB AS VARCHAR), 4, '0'),\n",
        "                    LPAD(CAST(MZA AS VARCHAR), 3, '0')\n",
        "                ) AS CVEGEO_CensoCalculado,\n",
        "                *\n",
        "            FROM censo_all\n",
        "        ),\n",
        "        manzanas_con_cvegeo AS (\n",
        "            SELECT\n",
        "                {cvegeo_manzana_expr} AS CVEGEO_ManzanaFuente,\n",
        "                m.geometry\n",
        "                -- , m.* EXCLUDE (geometry, CVEGEO) -- si CVEGEO ya existe y no queremos duplicados, o listar explícitamente otras cols de manzana\n",
        "            FROM manzanas m\n",
        "        )\n",
        "        SELECT\n",
        "            c.CVEGEO_CensoCalculado AS CVEGEO,\n",
        "            {select_cols_censo_str},\n",
        "            m_join.geometry\n",
        "        FROM censo_con_cvegeo c\n",
        "        INNER JOIN manzanas_con_cvegeo m_join ON c.CVEGEO_CensoCalculado = m_join.CVEGEO_ManzanaFuente;\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nEjecutando la creación de la tabla 'censo_geo' (unión)...\")\n",
        "        con.execute(\"BEGIN TRANSACTION;\")\n",
        "        con.execute(sql_create_censo_geo)\n",
        "        con.execute(\"COMMIT;\")\n",
        "        print(\"¡Tabla 'censo_geo' creada exitosamente!\")\n",
        "\n",
        "        print(\"\\nVerificando la tabla 'censo_geo'...\")\n",
        "        num_filas_censo_geo = con.execute(\"SELECT COUNT(*) FROM censo_geo;\").fetchone()[0]\n",
        "        print(f\"  Número total de filas en 'censo_geo': {num_filas_censo_geo}\")\n",
        "        if num_filas_censo_geo == 0:\n",
        "            print(\"  ADVERTENCIA: 'censo_geo' está vacía. Problemas con la unión o construcción de CVEGEO.\")\n",
        "        else:\n",
        "            print(\"\\n  Primeras 3 filas de 'censo_geo' (con geometría como WKT abreviado):\")\n",
        "            preview_df_final = con.execute(\"SELECT CVEGEO, POBTOT, ST_AsText(geometry) AS geometria_wkt FROM censo_geo LIMIT 3;\").fetchdf()\n",
        "            print(preview_df_final)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"¡ERROR GENERAL al crear la tabla 'censo_geo'!: {e}\")\n",
        "        try: con.execute(\"ROLLBACK;\")\n",
        "        except: pass\n",
        "        raise\n",
        "print(\"\\n--- Proceso de creación de 'censo_geo' completado (o intentado). ---\")"
      ],
      "metadata": {
        "id": "RDxKy9tKUz1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver : https://dbeaver.io/"
      ],
      "metadata": {
        "id": "Eqa2qYM_Pvfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 13: Limpieza Final de Tablas Intermedias y Cierre de la Conexión (Parcial)\n",
        "# ---------------------------------------------------------------------\n",
        "# No cerraremos la conexión todavía, ya que la usaremos para la visualización.\n",
        "# Pero sí podemos limpiar tablas intermedias.\n",
        "\n",
        "print(f\"--- Iniciando Limpieza Final de Tablas Intermedias ---\")\n",
        "ELIMINAR_TABLAS_INTERMEDIAS = True\n",
        "if ELIMINAR_TABLAS_INTERMEDIAS:\n",
        "    print(\"\\nEliminando tablas intermedias ('censo_all' y 'manzanas')...\")\n",
        "    try:\n",
        "        con.execute(\"DROP TABLE IF EXISTS censo_all;\")\n",
        "        print(\"  Tabla 'censo_all' eliminada (si existía).\")\n",
        "        con.execute(\"DROP TABLE IF EXISTS manzanas;\")\n",
        "        print(\"  Tabla 'manzanas' eliminada (si existía).\")\n",
        "        print(\"Limpieza de tablas intermedias completada.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Ocurrió un error durante la eliminación de tablas intermedias: {e}\")\n",
        "else:\n",
        "    print(\"\\nSe conservarán las tablas intermedias 'censo_all' y 'manzanas'.\")\n",
        "\n",
        "print(\"\\nVerificando tablas finales en la base de datos...\")\n",
        "try:\n",
        "    tablas_finales_df = con.execute(\"SHOW TABLES;\").fetchdf()\n",
        "    if not tablas_finales_df.empty:\n",
        "        print(\"Tablas actualmente en la base de datos:\")\n",
        "        print(tablas_finales_df)\n",
        "        if 'censo_geo' in tablas_finales_df['name'].tolist():\n",
        "            print(\"\\n  ¡La tabla principal 'censo_geo' está presente!\")\n",
        "        else:\n",
        "            print(\"\\n  ADVERTENCIA: ¡'censo_geo' NO se encontró!\")\n",
        "    else:\n",
        "        print(\"No se encontraron tablas.\")\n",
        "except Exception as e:\n",
        "    print(f\"  Error al mostrar las tablas: {e}\")\n",
        "\n",
        "print(\"\\n--- Limpieza Parcial Completada. La conexión a DuckDB se mantiene abierta para la visualización. ---\")\n",
        "\n",
        "# La Celda 14 original (exportar a gpkg) se puede ejecutar si se desea una salida de archivo.\n",
        "# Por ahora la omitimos para ir directo a la visualización desde DuckDB.\n",
        "# print(\"\\n--- Si se desea exportar 'censo_geo' a GeoPackage, se puede añadir el código de la Celda 14 aquí ---\")"
      ],
      "metadata": {
        "id": "vJefJ6pRU1Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización Interactiva de Datos Censales de Aguascalientes con Folium\n",
        "\n",
        "Ahora que hemos procesado y unido los datos censales y geoespaciales para el estado de Aguascalientes en la tabla `censo_geo` dentro de nuestra base de datos DuckDB, podemos proceder a visualizarlos. Utilizaremos `folium`, una potente librería de Python que nos permite crear mapas interactivos basados en Leaflet.js.\n",
        "\n",
        "**Pasos para la Visualización:**\n",
        "\n",
        "1.  **Lectura de Datos desde DuckDB:**\n",
        "    *   Nos conectaremos a la base de datos DuckDB (si la conexión se hubiera cerrado, la reabriríamos).\n",
        "    *   Ejecutaremos una consulta SQL para extraer los datos de la tabla `censo_geo`. Es importante obtener la columna de geometría en un formato que GeoPandas pueda interpretar fácilmente, como WKB (Well-Known Binary) o WKT (Well-Known Text). DuckDB, con su extensión espacial, puede convertir las geometrías a estos formatos.\n",
        "    *   Los datos leídos se cargarán en un GeoDataFrame de GeoPandas.\n",
        "\n",
        "2.  **Preparación del GeoDataFrame:**\n",
        "    *   Aseguraremos que la columna de geometría esté correctamente interpretada por GeoPandas.\n",
        "    *   Verificaremos que el Sistema de Coordenadas de Referencia (CRS) sea `EPSG:4326` (WGS 84), que es el estándar para la mayoría de las herramientas de mapeo web, incluido Folium. Nuestros datos ya deberían estar en este CRS debido al paso de conversión a GeoParquet.\n",
        "    *   Seleccionaremos la variable que deseamos visualizar (por ejemplo, `POBTOT` para la población total).\n",
        "\n",
        "3.  **Creación del Mapa Base con Folium:**\n",
        "    *   Calcularemos un punto central aproximado para el estado de Aguascalientes para centrar nuestro mapa. Esto se puede hacer tomando el centroide de la unión de todas las geometrías o el centroide de una geometría representativa.\n",
        "    *   Inicializaremos un objeto `folium.Map` con esta ubicación central y un nivel de zoom adecuado.\n",
        "\n",
        "4.  **Añadir Capa Coroplética (Choropleth):**\n",
        "    *   Utilizaremos la función `folium.Choropleth` para dibujar las manzanas y colorearlas según el valor de la variable seleccionada.\n",
        "    *   Esta función requiere:\n",
        "        *   `geo_data`: Los datos geoespaciales en formato GeoJSON (GeoPandas puede convertir a este formato).\n",
        "        *   `data`: El DataFrame que contiene los valores a visualizar.\n",
        "        *   `columns`: Las columnas que especifican el identificador de la geometría y el valor a mapear.\n",
        "        *   `key_on`: Una ruta en la estructura GeoJSON para encontrar el identificador que coincida con el del DataFrame.\n",
        "        *   `fill_color`: Una paleta de colores (por ejemplo, 'YlGnBu', 'RdYlGn', etc.).\n",
        "        *   `fill_opacity`, `line_opacity`: Para la transparencia.\n",
        "        *   `legend_name`: El título para la leyenda del mapa.\n",
        "\n",
        "5.  **Mostrar el Mapa Interactivo:**\n",
        "    *   Al final, mostraremos el objeto mapa de Folium. En un entorno como Google Colab o un Jupyter Notebook, esto renderizará un mapa interactivo directamente en la salida de la celda.\n",
        "\n",
        "Este enfoque nos permitirá explorar visualmente la distribución de características demográficas o de vivienda a lo largo de las manzanas de Aguascalientes.\n"
      ],
      "metadata": {
        "id": "Z_NYNG3tU-ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 15: Visualización Interactiva con Folium (Usando WKT para Geometrías)\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "import duckdb\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely import wkt # Cambiado de wkb a wkt\n",
        "from shapely import errors as shapely_errors # Para manejo de errores de shapely\n",
        "import folium\n",
        "import os\n",
        "# display para asegurar el renderizado en Colab\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "print(\"--- Iniciando Visualización Interactiva con Folium para Aguascalientes (Usando WKT) ---\")\n",
        "\n",
        "# --- Variables de Configuración (Requeridas si esta celda se ejecuta de forma aislada) ---\n",
        "CODIGO_ESTADO_STR = \"01\"\n",
        "NOMBRE_ESTADO = \"Aguascalientes\"\n",
        "DIR_BASE_INEGI = \"./inegi_data_ags\"\n",
        "DB_FILENAME = f\"inegi_analisis_{CODIGO_ESTADO_STR}.duckdb\"\n",
        "DB_FILE_PATH = os.path.join(DIR_BASE_INEGI, DB_FILENAME)\n",
        "\n",
        "try:\n",
        "    # 1. Establecer/Reestablecer la Conexión a DuckDB\n",
        "    # ---------------------------------------------\n",
        "    print(f\"Asegurando conexión a DuckDB en: {DB_FILE_PATH}\")\n",
        "    if not os.path.exists(DB_FILE_PATH):\n",
        "        print(f\"  ¡ERROR CRÍTICO! El archivo de base de datos no existe en: {DB_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Base de datos no encontrada: {DB_FILE_PATH}\")\n",
        "\n",
        "    # Verifica si la conexión 'con' ya existe y es una instancia de duckdb.DuckDBPyConnection\n",
        "    if con is not None and isinstance(con, duckdb.DuckDBPyConnection):\n",
        "        print(\"Ya existe una conexión a DuckDB.\")\n",
        "    else:\n",
        "        print(\"No existe una conexión a DuckDB o no es válida. Conectando...\")\n",
        "        con = duckdb.connect(database=DB_FILE_PATH, read_only=True)\n",
        "        print(\"Conexión establecida (solo lectura).\")\n",
        "\n",
        "    con.execute(\"LOAD spatial;\")\n",
        "    print(\"  Extensión 'spatial' cargada.\")\n",
        "\n",
        "    # 2. Leer datos de 'censo_geo' desde DuckDB (usando ST_AsText para WKT)\n",
        "    # --------------------------------------------------------------------\n",
        "    print(\"Leyendo datos de la tabla 'censo_geo' desde DuckDB (geometría como WKT)...\")\n",
        "\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        CVEGEO,\n",
        "        NOM_MUN,\n",
        "        NOM_LOC,\n",
        "        POBTOT,\n",
        "        VIVTOT,\n",
        "        TVIVHAB,\n",
        "        VPH_INTER,\n",
        "        VPH_PC,\n",
        "        VPH_CEL,\n",
        "        VPH_STVP,\n",
        "        VPH_SPMVPI,\n",
        "        VPH_CVJ,\n",
        "        GRAPROES,\n",
        "        ST_AsText(geometry) AS geom_wkt -- Cambiado a ST_AsText\n",
        "    FROM censo_geo\n",
        "    WHERE POBTOT IS NOT NULL AND POBTOT > 0;\n",
        "    \"\"\"\n",
        "    df_from_duckdb = con.execute(query).fetch_df() # Cambié el nombre para claridad\n",
        "\n",
        "    if df_from_duckdb.empty:\n",
        "        print(\"  ADVERTENCIA: No se encontraron datos en 'censo_geo' para visualizar.\")\n",
        "    else:\n",
        "        print(f\"  Datos leídos: {len(df_from_duckdb)} manzanas con población > 0.\")\n",
        "\n",
        "        # Convertir la columna WKT a geometrías de GeoPandas\n",
        "        # Adaptado del ejemplo que funcionó en el script anterior\n",
        "        def parse_wkt_geometry(wkt_string):\n",
        "            if wkt_string is None or not isinstance(wkt_string, str) or wkt_string.strip() == \"\":\n",
        "                return None\n",
        "            try:\n",
        "                return wkt.loads(wkt_string)\n",
        "            except shapely_errors.GEOSException as e_wkt:\n",
        "                # print(f\"    Advertencia: Error al leer WKT '{wkt_string[:50]}...': {e_wkt}. Se devolverá None.\")\n",
        "                return None # Silenciar warnings por ahora para no inundar la salida\n",
        "            except Exception as e_gen:\n",
        "                # print(f\"    Advertencia: Error inesperado al procesar WKT: {e_gen}. Se devolverá None.\")\n",
        "                return None\n",
        "\n",
        "        # Aplicar la función de parseo\n",
        "        parsed_geometries = df_from_duckdb['geom_wkt'].apply(parse_wkt_geometry)\n",
        "\n",
        "        # Crear el GeoDataFrame\n",
        "        gdf_ags = gpd.GeoDataFrame(df_from_duckdb.drop(columns=['geom_wkt']),\n",
        "                                   geometry=parsed_geometries,\n",
        "                                   crs=\"EPSG:4326\") # El CRS ya es 4326 por la transformación en Celda 10\n",
        "\n",
        "        print(f\"  GeoDataFrame creado. CRS: {gdf_ags.crs}\")\n",
        "\n",
        "        # Contar geometrías nulas después del parseo\n",
        "        null_geom_count = gdf_ags.geometry.isnull().sum()\n",
        "        if null_geom_count > 0:\n",
        "            print(f\"  ADVERTENCIA: {null_geom_count} geometrías son nulas después del parseo de WKT.\")\n",
        "            gdf_ags.dropna(subset=['geometry'], inplace=True) # Eliminar filas con geometrías nulas\n",
        "            print(f\"  Filas con geometrías nulas eliminadas. Quedan {len(gdf_ags)} filas.\")\n",
        "\n",
        "\n",
        "        # 3. Preparación del GeoDataFrame\n",
        "        # -------------------------------\n",
        "        variable_a_visualizar = 'POBTOT'\n",
        "\n",
        "        if variable_a_visualizar not in gdf_ags.columns:\n",
        "            print(f\"  ¡ERROR! La columna '{variable_a_visualizar}' no existe.\")\n",
        "            variable_a_visualizar = None\n",
        "        else:\n",
        "            gdf_ags[variable_a_visualizar] = pd.to_numeric(gdf_ags[variable_a_visualizar], errors='coerce')\n",
        "            gdf_ags.dropna(subset=[variable_a_visualizar], inplace=True) # Eliminar filas si la variable es NaN\n",
        "\n",
        "        if gdf_ags.empty or variable_a_visualizar is None:\n",
        "            print(\"  No hay datos válidos para visualizar después de la limpieza.\")\n",
        "        else:\n",
        "            # 4. Creación del Mapa Base con Folium\n",
        "            # -----------------------------------\n",
        "            bounds = gdf_ags.total_bounds\n",
        "            map_center_lat = (bounds[1] + bounds[3]) / 2\n",
        "            map_center_lon = (bounds[0] + bounds[2]) / 2\n",
        "\n",
        "            print(f\"  Centro del mapa: Lat={map_center_lat:.4f}, Lon={map_center_lon:.4f}\")\n",
        "\n",
        "            m = folium.Map(location=[map_center_lat, map_center_lon], zoom_start=12, tiles=\"CartoDB positron\")\n",
        "\n",
        "            # 5. Añadir Capa Coroplética\n",
        "            # --------------------------\n",
        "            if 'CVEGEO' in gdf_ags.columns and gdf_ags['CVEGEO'].is_unique:\n",
        "                 key_column = 'CVEGEO'\n",
        "            else:\n",
        "                 gdf_ags['folium_idx'] = range(len(gdf_ags))\n",
        "                 key_column = 'folium_idx'\n",
        "\n",
        "            try:\n",
        "                bins = list(gdf_ags[variable_a_visualizar].quantile([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
        "                bins = sorted(list(set(bins))) # Asegurar unicidad y orden\n",
        "                if len(bins) < 2: bins = 6 # Si no hay suficiente variación, usar un número fijo\n",
        "            except Exception: # Si el cálculo de cuantiles falla por alguna razón\n",
        "                bins = 6 # Default a un número fijo de bins\n",
        "\n",
        "            folium.Choropleth(\n",
        "                geo_data=gdf_ags.to_json(),\n",
        "                name=f'Coropleta de {variable_a_visualizar}',\n",
        "                data=gdf_ags,\n",
        "                columns=[key_column, variable_a_visualizar],\n",
        "                key_on=f'feature.properties.{key_column}',\n",
        "                fill_color='YlOrRd',\n",
        "                fill_opacity=0.7,\n",
        "                line_opacity=0.2, # Líneas de borde más sutiles\n",
        "                legend_name=f'{variable_a_visualizar} por Manzana en {NOMBRE_ESTADO}',\n",
        "                highlight=True,\n",
        "                bins=bins\n",
        "            ).add_to(m)\n",
        "\n",
        "            # Tooltips\n",
        "            tooltip_fields = ['CVEGEO', 'NOM_MUN', 'NOM_LOC', variable_a_visualizar, 'VIVTOT', 'VPH_INTER', 'VPH_PC', 'VPH_CEL', 'VPH_STVP', 'VPH_SPMVPI', 'VPH_CVJ', 'GRAPROES']\n",
        "            tooltip_aliases = [\n",
        "                'Clave:', 'Municipio:', 'Localidad:',\n",
        "                f'{variable_a_visualizar.replace(\"_\", \" \")}:',\n",
        "                'Viv. Totales:', 'Viv. Internet:', 'Viv. PC:', 'Viv. Celular:',\n",
        "                'Viv. TV Paga:', 'Viv. Streaming:', 'Viv. Consola:',\n",
        "                'Escolaridad Prom.:'\n",
        "            ]\n",
        "\n",
        "            tooltip_fields_existentes = [field for field in tooltip_fields if field in gdf_ags.columns]\n",
        "            # Crear aliases solo para los campos existentes para evitar errores de índice\n",
        "            tooltip_aliases_existentes = [tooltip_aliases[tooltip_fields.index(field)] for field in tooltip_fields_existentes]\n",
        "\n",
        "\n",
        "            if tooltip_fields_existentes:\n",
        "                 # Para Folium, es común que el tooltip se añada a una capa GeoJson separada\n",
        "                 # que puede ser transparente si solo se quiere el tooltip.\n",
        "                 folium.features.GeoJson(\n",
        "                    data=gdf_ags.to_json(), # GeoJSON de tus datos\n",
        "                    style_function=lambda x: {'fillColor': 'transparent', 'color': 'transparent', 'weight':0}, # Hace la capa invisible\n",
        "                    tooltip=folium.features.GeoJsonTooltip(\n",
        "                        fields=tooltip_fields_existentes,\n",
        "                        aliases=tooltip_aliases_existentes,\n",
        "                        sticky=False, # El tooltip sigue al cursor\n",
        "                        localize=True, # Formatea números y fechas según la configuración local\n",
        "                        style=(\"background-color: white; color: black; font-family: arial; font-size: 12px; padding: 10px;\")\n",
        "                    ),\n",
        "                    name=\"Información detallada (hover)\"\n",
        "                ).add_to(m)\n",
        "\n",
        "\n",
        "            folium.LayerControl().add_to(m)\n",
        "\n",
        "            # 6. Mostrar el Mapa Interactivo\n",
        "            # ------------------------------\n",
        "            print(\"\\nGenerando mapa interactivo de Folium...\")\n",
        "            display(m)\n",
        "\n",
        "except duckdb.Error as e_duck:\n",
        "    print(f\"  Error de DuckDB: {e_duck}\")\n",
        "except FileNotFoundError as e_file:\n",
        "    print(f\"  Error de Archivo: {e_file}\")\n",
        "except Exception as e_general:\n",
        "    print(f\"  Ocurrió un error general durante la visualización: {e_general}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    if con:\n",
        "        try:\n",
        "            con.close()\n",
        "            print(\"\\nConexión a DuckDB cerrada al finalizar la visualización.\")\n",
        "        except Exception as e_close:\n",
        "            print(f\"  Error al intentar cerrar la conexión a DuckDB: {e_close}\")\n",
        "\n",
        "print(\"\\n--- Fin del Script de Visualización ---\")"
      ],
      "metadata": {
        "id": "grjthtrIU4Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación Detallada de las Llamadas a `folium` en el Código:**\n",
        "\n",
        "`folium` es una librería de Python que facilita la visualización de datos geoespaciales de manera interactiva en un mapa Leaflet.js. Esta herramienta toma datos geográficos y los atributos que se desean mostrar, y genera un archivo HTML que contiene un mapa interactivo explorable con zoom, paneo, y a menudo, con información emergente (tooltips).\n",
        "\n",
        "En el script, `folium` se utiliza principalmente en dos celdas:\n",
        "\n",
        "1.  **Celda 15: Visualización de Manzanas Individuales (mapa `m`)**\n",
        "2.  **Celda 16: Visualización de Agregación Hexagonal (mapa `m_hex`)**\n",
        "\n",
        "Ambas celdas siguen una estructura similar para la creación del mapa:\n",
        "\n",
        "1.  **Creación del Mapa Base (`folium.Map`)**\n",
        "2.  **Adición de Capas de Datos (principalmente `folium.Choropleth`)**\n",
        "3.  **Adición de Información Emergente (Tooltips con `folium.features.GeoJson` y `folium.features.GeoJsonTooltip`)**\n",
        "4.  **Adición de Control de Capas (`folium.LayerControl`)**\n",
        "5.  **Visualización del Mapa (`display(m)`)**\n",
        "\n",
        "A continuación, se analizan los componentes clave:\n",
        "\n",
        "---\n",
        "\n",
        "**1. `folium.Map()`**\n",
        "\n",
        "*   **Qué esperar:** Esta es la primera llamada a `folium` y crea el lienzo base del mapa. Se visualizará un mapa del mundo (o una región específica si ya está centrado) con los controles básicos de zoom y paneo.\n",
        "*   **Funcionamiento de los parámetros (ejemplo de Celda 15):**\n",
        "    ```python\n",
        "    m = folium.Map(location=[map_center_lat, map_center_lon], zoom_start=12, tiles=\"CartoDB positron\")\n",
        "    ```\n",
        "    *   `location=[map_center_lat, map_center_lon]`:\n",
        "        *   **Qué es:** Una lista o tupla con dos números: `[latitud, longitud]`. Define el punto central donde se enfocará el mapa inicialmente.\n",
        "        *   **En el código:** `map_center_lat` y `map_center_lon` se calculan a partir de los límites (`total_bounds`) del GeoDataFrame (`gdf_ags` o `gdf_hex_vis`), asegurando que el mapa se centre en los datos de Aguascalientes.\n",
        "    *   `zoom_start=12`:\n",
        "        *   **Qué es:** Un número entero que define el nivel de zoom inicial del mapa. Números más altos significan un mayor acercamiento.\n",
        "        *   **En el código:** `12` es un nivel de zoom razonable para observar detalles a nivel de ciudad o región.\n",
        "    *   `tiles=\"CartoDB positron\"`:\n",
        "        *   **Qué es:** Define el estilo del mapa base (el fondo cartográfico).\n",
        "        *   **En el código:** `\"CartoDB positron\"` es un estilo de mapa claro y minimalista. Otros estilos populares incluyen `\"OpenStreetMap\"`, `\"Stamen Terrain\"`, `\"Stamen Toner\"`, etc.\n",
        "        *   **Qué esperar:** Un mapa con calles, cuerpos de agua, etc., con el estilo \"CartoDB positron\".\n",
        "\n",
        "---\n",
        "\n",
        "**2. `folium.Choropleth()`**\n",
        "\n",
        "*   **Qué esperar:** Esta es la función clave para crear mapas coropléticos. Dibuja las geometrías de los datos (manzanas en Celda 15, hexágonos en Celda 16) y las colorea según los valores de una variable específica (ej. `POBTOT`). También añade una leyenda para interpretar los colores.\n",
        "*   **Funcionamiento de los parámetros (ejemplo de Celda 15):**\n",
        "    ```python\n",
        "    folium.Choropleth(\n",
        "        geo_data=gdf_ags.to_json(),\n",
        "        name=f'Coropleta de {variable_a_visualizar}',\n",
        "        data=gdf_ags,\n",
        "        columns=[key_column, variable_a_visualizar],\n",
        "        key_on=f'feature.properties.{key_column}',\n",
        "        fill_color='YlOrRd',\n",
        "        fill_opacity=0.7,\n",
        "        line_opacity=0.2,\n",
        "        legend_name=f'{variable_a_visualizar} por Manzana en {NOMBRE_ESTADO}',\n",
        "        highlight=True,\n",
        "        bins=bins\n",
        "    ).add_to(m)\n",
        "    ```\n",
        "    *   `geo_data=gdf_ags.to_json()`:\n",
        "        *   **Qué es:** Los datos geoespaciales que contienen las geometrías a dibujar. `folium` espera esto en formato GeoJSON.\n",
        "        *   **En el código:** `gdf_ags` (o `gdf_hex_vis`) es el GeoDataFrame. El método `.to_json()` lo convierte al formato GeoJSON necesario.\n",
        "        *   **Qué esperar:** Las manzanas (o hexágonos) de Aguascalientes dibujadas en el mapa.\n",
        "    *   `name=f'Coropleta de {variable_a_visualizar}'` (y similar en Celda 16):\n",
        "        *   **Qué es:** Un nombre para esta capa. Es útil si existen múltiples capas, ya que aparecerá en el `LayerControl`.\n",
        "        *   **Qué esperar:** Este texto identificará la capa en el control de capas.\n",
        "    *   `data=gdf_ags`:\n",
        "        *   **Qué es:** El DataFrame (o GeoDataFrame) que contiene los datos (la variable) que se usarán para colorear las geometrías.\n",
        "        *   **En el código:** Es el mismo `gdf_ags` que también proporciona las geometrías, pero podría ser un DataFrame de Pandas diferente si las geometrías y los datos estuvieran separados.\n",
        "    *   `columns=[key_column, variable_a_visualizar]`:\n",
        "        *   **Qué es:** Una lista de dos cadenas.\n",
        "            *   La primera (`key_column`): El nombre de la columna en `data` (y en las propiedades de `geo_data`) que sirve como identificador único para unir las geometrías con los datos. En el código, es `CVEGEO` o un `folium_idx` si `CVEGEO` no es único o no existe.\n",
        "            *   La segunda (`variable_a_visualizar`): El nombre de la columna en `data` cuyos valores determinarán el color de cada geometría (ej. `POBTOT`).\n",
        "        *   **Qué esperar:** `folium` usará `key_column` para encontrar la geometría correcta y luego usará el valor de `variable_a_visualizar` para esa geometría para asignarle un color.\n",
        "    *   `key_on=f'feature.properties.{key_column}'`:\n",
        "        *   **Qué es:** Una cadena que le indica a `folium` dónde encontrar el identificador (la `key_column`) dentro de la estructura del `geo_data` (GeoJSON). La estructura típica es `feature.properties.NOMBRE_DE_LA_PROPIEDAD`.\n",
        "    *   `fill_color='YlOrRd'` (o `'BuPu'` en Celda 16):\n",
        "        *   **Qué es:** El esquema de color a utilizar. Estos son nombres de paletas de ColorBrewer.\n",
        "        *   **Qué esperar:** Las geometrías se colorearán usando una gradación de Amarillo-Naranja-Rojo (o Azul-Púrpura).\n",
        "    *   `fill_opacity=0.7` (o `0.75`):\n",
        "        *   **Qué es:** La opacidad del relleno de color (0=transparente, 1=opaco).\n",
        "    *   `line_opacity=0.2` (o `0.3`):\n",
        "        *   **Qué es:** La opacidad de las líneas de borde de las geometrías.\n",
        "    *   `legend_name=f'{variable_a_visualizar} por Manzana en {NOMBRE_ESTADO}'`:\n",
        "        *   **Qué es:** El título que aparecerá sobre la leyenda del mapa.\n",
        "        *   **Qué esperar:** Una leyenda en el mapa que ayuda a entender qué rango de valores representa cada color.\n",
        "    *   `highlight=True`:\n",
        "        *   **Qué es:** Si es `True`, las geometrías se resaltarán al pasar el cursor sobre ellas.\n",
        "    *   `bins=bins`:\n",
        "        *   **Qué es:** Define cómo se agrupan los datos para la asignación de colores. Puede ser un número entero (para N clases de igual tamaño) o una lista de valores de corte (para clases personalizadas).\n",
        "        *   **En el código:** `bins` se calcula usando cuantiles (`gdf_ags[variable_a_visualizar].quantile(...)`) para intentar una distribución de colores más equitativa.\n",
        "    *   `show=show_this_layer_by_default` (solo en Celda 16):\n",
        "        *   **Qué es:** Un booleano que indica si la capa debe ser visible por defecto cuando el mapa se carga. Útil cuando hay múltiples capas coropléticas.\n",
        "    *   `.add_to(m)`:\n",
        "        *   **Qué es:** Un método que añade esta capa coroplética al objeto mapa `m` creado anteriormente.\n",
        "\n",
        "---\n",
        "\n",
        "**3. `folium.features.GeoJson()` y `folium.features.GeoJsonTooltip()` (para Tooltips)**\n",
        "\n",
        "*   **Qué esperar:** Estas funciones trabajan juntas para mostrar información adicional cuando se pasa el cursor sobre una geometría (manzana o hexágono). Aparecerá una pequeña ventana emergente (tooltip) con los datos que se especifiquen.\n",
        "*   **Funcionamiento de los parámetros (ejemplo de Celda 15):**\n",
        "    ```python\n",
        "    folium.features.GeoJson(\n",
        "        data=gdf_ags.to_json(),\n",
        "        style_function=lambda x: {'fillColor': 'transparent', 'color': 'transparent', 'weight':0},\n",
        "        tooltip=folium.features.GeoJsonTooltip(\n",
        "            fields=tooltip_fields_existentes,\n",
        "            aliases=tooltip_aliases_existentes,\n",
        "            sticky=False,\n",
        "            localize=True,\n",
        "            style=(\"background-color: white; color: black; font-family: arial; font-size: 12px; padding: 10px;\")\n",
        "        ),\n",
        "        name=\"Información detallada (hover)\"\n",
        "    ).add_to(m)\n",
        "    ```\n",
        "    *   **`folium.features.GeoJson()`:**\n",
        "        *   `data=gdf_ags.to_json()`: Nuevamente, las geometrías en formato GeoJSON.\n",
        "        *   `style_function=lambda x: {'fillColor': 'transparent', 'color': 'transparent', 'weight':0}`:\n",
        "            *   **Qué es:** Una función que define el estilo de esta capa GeoJSON.\n",
        "            *   **En el código:** Se usa para hacer esta capa completamente invisible, ya que su único propósito es servir de \"ancla\" para los tooltips. Los colores y las formas ya están definidos por la capa `Choropleth`.\n",
        "        *   `tooltip=folium.features.GeoJsonTooltip(...)`:\n",
        "            *   **Qué es:** Aquí se anida el objeto que define el contenido y comportamiento del tooltip.\n",
        "        *   `name=\"Información detallada (hover)\"`: Nombre para esta capa en el control de capas.\n",
        "    *   **`folium.features.GeoJsonTooltip()`:**\n",
        "        *   `fields=tooltip_fields_existentes`:\n",
        "            *   **Qué es:** Una lista de los nombres de las columnas del `gdf_ags` (o `gdf_hex_vis`) que se quieren mostrar en el tooltip.\n",
        "            *   **En el código:** `tooltip_fields_existentes` se asegura de que solo se incluyan columnas que realmente existen en los datos.\n",
        "        *   `aliases=tooltip_aliases_existentes`:\n",
        "            *   **Qué es:** Una lista de etiquetas más amigables que se mostrarán en lugar de los nombres de columna crudos. Deben estar en el mismo orden que `fields`.\n",
        "        *   `sticky=False`:\n",
        "            *   **Qué es:** Si es `False`, el tooltip sigue el cursor del ratón mientras está sobre la geometría. Si es `True`, se fija a un punto de la geometría.\n",
        "        *   `localize=True`:\n",
        "            *   **Qué es:** Intenta formatear números y fechas según la configuración regional del navegador.\n",
        "        *   `style=`:\n",
        "            *   **Qué es:** Una cadena CSS para darle estilo al tooltip (color de fondo, fuente, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "**4. `folium.LayerControl()`**\n",
        "\n",
        "*   **Qué esperar:** Añade un control (generalmente en la esquina superior derecha del mapa) que permite activar o desactivar la visibilidad de las diferentes capas que se han añadido al mapa (las capas `Choropleth` y `GeoJson` que tienen un parámetro `name`).\n",
        "*   **Funcionamiento de los parámetros (ejemplo de Celda 16):**\n",
        "    ```python\n",
        "    folium.LayerControl(collapsed=False).add_to(m_hex)\n",
        "    ```\n",
        "    *   `collapsed=False`:\n",
        "        *   **Qué es:** Si es `False`, el control de capas se muestra expandido por defecto. Si es `True`, está colapsado y se necesita hacer clic para ver las capas.\n",
        "    *   `.add_to(m_hex)`: Añade el control al mapa `m_hex`.\n",
        "\n",
        "---\n",
        "\n",
        "**5. `display(m)`**\n",
        "\n",
        "*   **Qué esperar:** En entornos como Jupyter Notebook o Google Colab, esta función es la que efectivamente renderiza el objeto mapa `m` (o `m_hex`) como una salida interactiva en la celda.\n",
        "*   **Funcionamiento:** `display` es una función de IPython que puede mostrar diferentes tipos de objetos de forma enriquecida. Para los mapas de `folium`, los muestra como el mapa HTML interactivo.\n",
        "\n",
        "---\n",
        "\n",
        "**En Resumen del Proceso con `folium`:**\n",
        "\n",
        "1.  **Preparación de datos:** Se leen los datos geoespaciales y los atributos a visualizar en un GeoDataFrame de GeoPandas (ej. `gdf_ags`, `gdf_hex_vis`). Se asegura que el Sistema de Referencia de Coordenadas (CRS) sea `EPSG:4326`.\n",
        "2.  **Creación del mapa base:** `folium.Map()` proporciona el lienzo inicial.\n",
        "3.  **Adición de datos coloreados:** `folium.Choropleth()` dibuja las geometrías (manzanas/hexágonos) y las colorea según una variable, añadiendo una leyenda para la interpretación.\n",
        "4.  **Adición de interactividad:** `folium.features.GeoJson()` junto con `folium.features.GeoJsonTooltip()` permite que aparezca información útil cuando se pasa el cursor sobre las geometrías.\n",
        "5.  **Inclusión de control de capas:** `folium.LayerControl()` ofrece la opción de mostrar u ocultar capas si se han definido varias.\n",
        "6.  **Visualización del resultado:** `display(m)` renderiza el mapa interactivo final.\n",
        "\n",
        "El resultado final es un mapa HTML incrustado en el notebook, donde se puede hacer zoom, desplazarse, observar cómo se distribuye la variable de interés (población, viviendas con internet, etc.) a través de las diferentes áreas geográficas de Aguascalientes, y obtener detalles específicos al pasar el cursor por encima de los elementos del mapa."
      ],
      "metadata": {
        "id": "P5vaxavYTVj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geohexgrid --quiet"
      ],
      "metadata": {
        "id": "MBH4Eq0BVPdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 16: Visualización Exclusiva de Agregación Hexagonal (Nuevo Intento para AssertionError)\n",
        "# ---------------------------------------------------------------------------------------------\n",
        "\n",
        "import duckdb\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely import wkt, wkb\n",
        "from shapely.geometry import Point\n",
        "import folium\n",
        "import os\n",
        "from IPython.display import display\n",
        "import geohexgrid as ghg\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Iniciando Visualización Exclusiva de Agregación Hexagonal (Nuevo Intento AssertionError) ---\")\n",
        "\n",
        "# --- Variables de Configuración ---\n",
        "CODIGO_ESTADO_STR = \"01\"\n",
        "NOMBRE_ESTADO = \"Aguascalientes\"\n",
        "DIR_BASE_INEGI = \"./inegi_data_ags\"\n",
        "DB_FILENAME = f\"inegi_analisis_{CODIGO_ESTADO_STR}.duckdb\"\n",
        "DB_FILE_PATH = os.path.join(DIR_BASE_INEGI, DB_FILENAME)\n",
        "RADIO_HEXAGONO_METROS = 350\n",
        "CRS_PROYECTADO_MEXICO = \"EPSG:6372\"\n",
        "CRS_GEOGRAFICO = \"EPSG:4326\"\n",
        "\n",
        "con = None\n",
        "\n",
        "try:\n",
        "    # PARTE A: CREACIÓN/VERIFICACIÓN DE DATOS HEXAGONALES EN DUCKDB (Se mantiene igual)\n",
        "    # ================================================================================\n",
        "    print(f\"Conectando a DuckDB (RW) en: {DB_FILE_PATH} para preparar datos hexagonales...\")\n",
        "    if not os.path.exists(DB_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Base de datos no encontrada: {DB_FILE_PATH}.\")\n",
        "\n",
        "    con = duckdb.connect(database=DB_FILE_PATH, read_only=False)\n",
        "    print(\"  Conexión a DuckDB establecida.\")\n",
        "    con.execute(\"LOAD spatial;\")\n",
        "    print(\"  Extensión 'spatial' cargada.\")\n",
        "\n",
        "    table_check_censo_geo = con.execute(\"SELECT table_name FROM information_schema.tables WHERE table_name = 'censo_geo';\").fetch_df()\n",
        "    if table_check_censo_geo.empty:\n",
        "        raise ValueError(\"La tabla base 'censo_geo' no existe.\")\n",
        "\n",
        "    print(\"Preparando tabla de centroides de manzanas ('manzana_centroids_ags')...\")\n",
        "    con.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS manzana_centroids_ags AS\n",
        "    SELECT\n",
        "        CVEGEO, POBTOT, VIVTOT, TVIVHAB, VPH_INTER, VPH_PC,\n",
        "        VPH_CEL, VPH_STVP, VPH_SPMVPI, VPH_CVJ, GRAPROES,\n",
        "        ST_Centroid(geometry) as centroid_geom\n",
        "    FROM censo_geo\n",
        "    WHERE POBTOT IS NOT NULL AND POBTOT > 0 AND geometry IS NOT NULL AND ST_IsValid(geometry);\n",
        "    \"\"\")\n",
        "    num_centroids = con.execute(\"SELECT COUNT(*) FROM manzana_centroids_ags\").fetchone()[0]\n",
        "    if num_centroids == 0:\n",
        "        con.execute(\"DROP TABLE IF EXISTS manzana_centroids_ags;\")\n",
        "        con.execute(\"\"\"\n",
        "        CREATE TABLE manzana_centroids_ags AS SELECT\n",
        "            CVEGEO, POBTOT, VIVTOT, TVIVHAB, VPH_INTER, VPH_PC, VPH_CEL, VPH_STVP, VPH_SPMVPI, VPH_CVJ, GRAPROES,\n",
        "            ST_Centroid(geometry) as centroid_geom\n",
        "        FROM censo_geo WHERE POBTOT IS NOT NULL AND POBTOT > 0 AND geometry IS NOT NULL AND ST_IsValid(geometry);\"\"\")\n",
        "        num_centroids = con.execute(\"SELECT COUNT(*) FROM manzana_centroids_ags\").fetchone()[0]\n",
        "        if num_centroids == 0: raise ValueError(\"No se generaron centroides válidos desde 'censo_geo'.\")\n",
        "    print(f\"  Tabla 'manzana_centroids_ags' lista/creada con {num_centroids} centroides.\")\n",
        "\n",
        "    print(\"Preparando rejilla hexagonal ('hex_grid_ags')...\")\n",
        "    table_check_hex_grid = con.execute(\"SELECT table_name FROM information_schema.tables WHERE table_name = 'hex_grid_ags';\").fetch_df()\n",
        "    if table_check_hex_grid.empty:\n",
        "        print(\"  Tabla 'hex_grid_ags' no encontrada, generándola...\")\n",
        "        df_centroids_for_grid = con.execute(\"SELECT ST_AsText(centroid_geom) AS geom_wkt FROM manzana_centroids_ags WHERE centroid_geom IS NOT NULL;\").fetch_df()\n",
        "        if df_centroids_for_grid.empty:\n",
        "            raise ValueError(\"No se pudieron extraer centroides WKT para generar la rejilla.\")\n",
        "\n",
        "        def parse_wkt_for_grid(wkt_string):\n",
        "            if wkt_string is None or not isinstance(wkt_string, str) or wkt_string.strip() == \"\": return None\n",
        "            try: return wkt.loads(wkt_string)\n",
        "            except: return None\n",
        "\n",
        "        df_centroids_for_grid['geometry'] = df_centroids_for_grid['geom_wkt'].apply(parse_wkt_for_grid)\n",
        "        gdf_centroids_for_grid = gpd.GeoDataFrame(df_centroids_for_grid.drop(columns=['geom_wkt']), geometry='geometry', crs=CRS_GEOGRAFICO)\n",
        "        gdf_centroids_for_grid.dropna(subset=['geometry'], inplace=True)\n",
        "\n",
        "        if gdf_centroids_for_grid.empty:\n",
        "            raise ValueError(\"GeoDataFrame de centroides (desde WKT) para la rejilla está vacío.\")\n",
        "\n",
        "        grid_hex_proj = ghg.make_grid_from_gdf(gdf_centroids_for_grid.to_crs(CRS_PROYECTADO_MEXICO), R=RADIO_HEXAGONO_METROS)\n",
        "        grid_hex = grid_hex_proj.to_crs(CRS_GEOGRAFICO)\n",
        "        print(f\"  Rejilla hexagonal generada con {len(grid_hex)} celdas.\")\n",
        "\n",
        "        grid_hex['geom_wkt_hex'] = grid_hex['geometry'].apply(lambda g: g.wkt if g else None)\n",
        "        grid_hex_for_duckdb = grid_hex[['cell_id', 'geom_wkt_hex']].copy()\n",
        "        grid_hex_for_duckdb.dropna(subset=['geom_wkt_hex'], inplace=True)\n",
        "\n",
        "        con.execute(\"CREATE TABLE hex_grid_ags (cell_id VARCHAR, geometry GEOMETRY);\")\n",
        "        if not grid_hex_for_duckdb.empty:\n",
        "            for index, row in grid_hex_for_duckdb.iterrows():\n",
        "                con.execute(\"INSERT INTO hex_grid_ags VALUES (?, ST_GeomFromText(?))\", [row['cell_id'], row['geom_wkt_hex']])\n",
        "            print(\"  Rejilla hexagonal cargada a 'hex_grid_ags' usando WKT.\")\n",
        "        else:\n",
        "            raise ValueError(\"Rejilla hexagonal generada estaba vacía después de la conversión a WKT.\")\n",
        "    else:\n",
        "        print(\"  Tabla 'hex_grid_ags' ya existe.\")\n",
        "\n",
        "    print(\"Preparando tabla de agregación hexagonal ('hex_final_ags')...\")\n",
        "    variables_numericas_duck = ['POBTOT', 'VIVTOT', 'TVIVHAB', 'VPH_INTER', 'VPH_PC', 'VPH_CEL', 'VPH_STVP', 'VPH_SPMVPI', 'VPH_CVJ', 'GRAPROES']\n",
        "    sum_expressions = [f\"SUM(COALESCE(c.{var}, 0)) AS {var}_hex\" for var in variables_numericas_duck]\n",
        "\n",
        "    query_hex_final = f\"\"\"\n",
        "    CREATE OR REPLACE TABLE hex_final_ags AS\n",
        "    SELECT\n",
        "        h.cell_id,\n",
        "        h.geometry AS hex_geom,\n",
        "        COUNT(c.CVEGEO) AS num_manzanas_en_hex,\n",
        "        {', '.join(sum_expressions)}\n",
        "    FROM hex_grid_ags h\n",
        "    LEFT JOIN manzana_centroids_ags c\n",
        "        ON ST_Intersects(c.centroid_geom, h.geometry)\n",
        "    GROUP BY h.cell_id, h.geometry;\n",
        "    \"\"\"\n",
        "    con.execute(query_hex_final)\n",
        "    num_hex_final = con.execute(\"SELECT COUNT(*) FROM hex_final_ags\").fetchone()[0]\n",
        "    if num_hex_final == 0:\n",
        "        raise ValueError(\"La tabla 'hex_final_ags' se generó vacía.\")\n",
        "    print(f\"  Tabla 'hex_final_ags' lista/creada con {num_hex_final} hexágonos agregados.\")\n",
        "\n",
        "    # PARTE B: VISUALIZACIÓN CON FOLIUM\n",
        "    # =================================\n",
        "    print(\"\\nLeyendo datos de hexágonos agregados ('hex_final_ags') para visualización...\")\n",
        "\n",
        "    select_hex_vars_display = [f\"{var}_hex\" for var in variables_numericas_duck]\n",
        "    query_hex_vis_display = f\"\"\"\n",
        "    SELECT\n",
        "        cell_id,\n",
        "        num_manzanas_en_hex,\n",
        "        {', '.join(select_hex_vars_display)},\n",
        "        ST_AsText(hex_geom) AS geom_wkt\n",
        "    FROM hex_final_ags\n",
        "    WHERE num_manzanas_en_hex > 0;\n",
        "    \"\"\"\n",
        "\n",
        "    df_hex_vis_duck = con.execute(query_hex_vis_display).fetch_df()\n",
        "\n",
        "    if df_hex_vis_duck.empty:\n",
        "        raise ValueError(\"No se extrajeron datos de hexágonos para visualización.\")\n",
        "\n",
        "    def parse_wkt_for_viz(wkt_string):\n",
        "        if wkt_string is None or not isinstance(wkt_string, str) or wkt_string.strip() == \"\": return None\n",
        "        try: return wkt.loads(wkt_string)\n",
        "        except: return None\n",
        "\n",
        "    df_hex_vis_duck['geometry'] = df_hex_vis_duck['geom_wkt'].apply(parse_wkt_for_viz)\n",
        "    gdf_hex_vis = gpd.GeoDataFrame(df_hex_vis_duck.drop(columns=['geom_wkt']), geometry='geometry', crs=CRS_GEOGRAFICO)\n",
        "    gdf_hex_vis.dropna(subset=['geometry'], inplace=True)\n",
        "\n",
        "    for var_hex in select_hex_vars_display + ['num_manzanas_en_hex']:\n",
        "        if var_hex in gdf_hex_vis.columns:\n",
        "            gdf_hex_vis[var_hex] = pd.to_numeric(gdf_hex_vis[var_hex], errors='coerce')\n",
        "            gdf_hex_vis[var_hex] = gdf_hex_vis[var_hex].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if gdf_hex_vis.empty:\n",
        "        raise ValueError(\"GeoDataFrame de Hexágonos para visualización está vacío después de la limpieza.\")\n",
        "\n",
        "    print(f\"  GeoDataFrame de Hexágonos para visualización: {len(gdf_hex_vis)} filas. CRS: {gdf_hex_vis.crs}\")\n",
        "\n",
        "    bounds_map_hex = gdf_hex_vis.total_bounds\n",
        "    map_center_lat_hex = (bounds_map_hex[1] + bounds_map_hex[3]) / 2\n",
        "    map_center_lon_hex = (bounds_map_hex[0] + bounds_map_hex[2]) / 2\n",
        "    m_hex = folium.Map(location=[map_center_lat_hex, map_center_lon_hex], zoom_start=12, tiles=\"CartoDB positron\")\n",
        "    print(f\"  Mapa base para hexágonos creado, centrado en: Lat={map_center_lat_hex:.4f}, Lon={map_center_lon_hex:.4f}\")\n",
        "\n",
        "    variables_a_mapear_hex_dict = {\n",
        "        'POBTOT_hex': 'Población Total (Hex)', 'VPH_INTER_hex': 'Viv. Internet (Hex)',\n",
        "        'GRAPROES_hex': 'Escolaridad Prom. (Hex)', 'num_manzanas_en_hex': 'Num. Manzanas (Hex)'\n",
        "    }\n",
        "    default_hex_variable_to_show = 'POBTOT_hex'\n",
        "\n",
        "    # ***** INICIO DEL CAMBIO PRINCIPAL PARA EVITAR ASSERTIONERROR *****\n",
        "    for var_col_name, layer_display_name in variables_a_mapear_hex_dict.items():\n",
        "        if var_col_name not in gdf_hex_vis.columns or gdf_hex_vis[var_col_name].isnull().all():\n",
        "            print(f\"  Saltando capa para '{var_col_name}', no disponible o todos los valores son nulos.\")\n",
        "            continue\n",
        "\n",
        "        # Determinar si esta capa se muestra por defecto\n",
        "        show_this_layer_by_default = (var_col_name == default_hex_variable_to_show)\n",
        "\n",
        "        data_for_bins = gdf_hex_vis[var_col_name]\n",
        "        try:\n",
        "            if data_for_bins.nunique() > 1 and data_for_bins.max() > 0 :\n",
        "                bins_val = sorted(list(set(data_for_bins.quantile([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1]).tolist())))\n",
        "                if len(bins_val) < 2: bins_val = 5\n",
        "            else:\n",
        "                bins_val = [0, data_for_bins.max()] if data_for_bins.max() > 0 else [0,1]\n",
        "                if bins_val[0] == bins_val[1] : bins_val = [0, bins_val[1]*1.1 if bins_val[1] > 0 else 0.1]\n",
        "                if len(bins_val) < 2 or bins_val[0] == bins_val[1]: bins_val = np.linspace(0, max(0.1, bins_val[1]), num=5).tolist()\n",
        "            bins_val = sorted(list(set(el for el in bins_val if pd.notna(el) )))\n",
        "            if not bins_val or len(bins_val) < 2: bins_val = 5\n",
        "        except Exception as e_bin_calc:\n",
        "            print(f\"  Error calculando bins para {var_col_name}: {e_bin_calc}. Usando 5 bins por defecto.\")\n",
        "            bins_val = 5\n",
        "\n",
        "        # Crear el Choropleth y AÑADIRLO DIRECTAMENTE AL MAPA\n",
        "        choro_layer = folium.Choropleth(\n",
        "            geo_data=gdf_hex_vis.to_json(), data=gdf_hex_vis,\n",
        "            columns=['cell_id', var_col_name], key_on='feature.properties.cell_id',\n",
        "            fill_color='BuPu', fill_opacity=0.75, line_opacity=0.3,\n",
        "            legend_name=f'{layer_display_name} (R={RADIO_HEXAGONO_METROS}m)',\n",
        "            bins=bins_val, highlight=True,\n",
        "            name=layer_display_name, # Este nombre aparecerá en el LayerControl\n",
        "            show=show_this_layer_by_default # Controla la visibilidad inicial\n",
        "        )\n",
        "        choro_layer.add_to(m_hex) # Añadir Choropleth directamente al mapa\n",
        "\n",
        "        # Crear y añadir tooltips. Si se quiere que el tooltip esté asociado a esta capa\n",
        "        # específica en el control de capas, se puede añadir a la misma capa Choropleth\n",
        "        # o a un FeatureGroup que contenga solo esta capa Choropleth y sus tooltips.\n",
        "        # Por simplicidad, podemos añadir un GeoJson para tooltips que se active con esta capa.\n",
        "\n",
        "        tooltip_hex_fields_dynamic = ['cell_id', var_col_name, 'num_manzanas_en_hex', 'POBTOT_hex']\n",
        "        tooltip_hex_aliases_dynamic = ['ID Hex:', f'{layer_display_name.split(\"(\")[0].strip()}:', '# Manzanas:', 'Pob. Total Sum:']\n",
        "        current_hex_flds = [f for f in tooltip_hex_fields_dynamic if f in gdf_hex_vis.columns]\n",
        "        current_hex_als = [tooltip_hex_aliases_dynamic[tooltip_hex_fields_dynamic.index(f)] for f in current_hex_flds]\n",
        "\n",
        "        if current_hex_flds:\n",
        "            # El tooltip se puede añadir al objeto choro_layer si su clase base lo permite\n",
        "            # o como un GeoJson separado que se activa con la capa.\n",
        "            # Folium a veces es quisquilloso con esto.\n",
        "            # Añadirlo al mapa directamente y controlar con el mismo 'name' puede funcionar.\n",
        "             folium.features.GeoJson(\n",
        "                data=gdf_hex_vis.to_json(), # Usar el mismo geo_data\n",
        "                style_function=lambda x: {'fillColor': 'transparent', 'color': 'transparent', 'weight':0}, # Hacer invisible\n",
        "                tooltip=folium.features.GeoJsonTooltip(\n",
        "                    fields=current_hex_flds,\n",
        "                    aliases=current_hex_als,\n",
        "                    sticky=False,\n",
        "                    localize=True,\n",
        "                    style=\"background-color: white; color: black; font-size: 12px; padding: 5px;\"\n",
        "                ),\n",
        "                name=f\"Tooltips para {layer_display_name}\", # Nombre diferente para que no se superponga en control\n",
        "                show=show_this_layer_by_default # Mostrar si la capa principal se muestra\n",
        "            ).add_to(m_hex) # Añadir al mapa principal\n",
        "\n",
        "        print(f\"  Capa hexagonal para '{layer_display_name}' generada y añadida al mapa.\")\n",
        "    # ***** FIN DEL CAMBIO PRINCIPAL *****\n",
        "\n",
        "    folium.LayerControl(collapsed=False).add_to(m_hex)\n",
        "    print(\"\\nGenerando mapa interactivo de hexágonos...\")\n",
        "    display(m_hex)\n",
        "\n",
        "except FileNotFoundError as e_file:\n",
        "    print(f\"  Error de Archivo: {e_file}\")\n",
        "except ValueError as e_val:\n",
        "    print(f\"  Error de Valor: {e_val}\")\n",
        "    import traceback; traceback.print_exc()\n",
        "except ImportError as e_imp:\n",
        "    print(f\"  Error de Importación: {e_imp}. Asegúrate que 'geohexgrid' esté instalado.\")\n",
        "except duckdb.Error as e_duck:\n",
        "    print(f\"  Error de DuckDB: {e_duck}\")\n",
        "    import traceback; traceback.print_exc()\n",
        "except Exception as e_general:\n",
        "    print(f\"  Ocurrió un error general: {e_general}\")\n",
        "    import traceback; traceback.print_exc()\n",
        "finally:\n",
        "    if con:\n",
        "        try:\n",
        "            con.close()\n",
        "            print(\"\\nConexión a DuckDB cerrada al finalizar.\")\n",
        "        except Exception as e_close:\n",
        "            print(f\"  Error al cerrar la conexión: {e_close}\")\n",
        "\n",
        "print(\"\\n--- Fin del Script de Visualización Hexagonal (Nuevo Intento AssertionError) ---\")"
      ],
      "metadata": {
        "id": "eCXFqAe9ZFlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 17: Guardar Agregación Hexagonal como GeoPackage\n",
        "# ----------------------------------------------------\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd # Asegurar que pandas esté importado si no lo está ya\n",
        "import os\n",
        "\n",
        "print(\"--- Iniciando Guardado de Agregación Hexagonal a GeoPackage ---\")\n",
        "\n",
        "# --- Variables de Configuración (Requeridas si esta celda se ejecuta de forma aislada) ---\n",
        "# Asegúrate que estas coincidan con las celdas anteriores\n",
        "CODIGO_ESTADO_STR = \"01\"\n",
        "NOMBRE_ESTADO = \"Aguascalientes\" # Usado para el nombre de archivo\n",
        "DIR_BASE_INEGI = \"./inegi_data_ags\" # Directorio donde se guardará el GeoPackage\n",
        "# gdf_hex_vis debe existir de la Celda 16. Si no, necesitaríamos regenerarlo o leerlo.\n",
        "\n",
        "# Nombre y ruta para el archivo GeoPackage de salida\n",
        "GEOPACKAGE_OUTPUT_DIR = os.path.join(DIR_BASE_INEGI, \"geopackages_output\")\n",
        "os.makedirs(GEOPACKAGE_OUTPUT_DIR, exist_ok=True) # Crear directorio si no existe\n",
        "GEOPACKAGE_FILENAME = f\"hexagonos_agregados_{NOMBRE_ESTADO.lower().replace(' ', '_')}_{CODIGO_ESTADO_STR}.gpkg\"\n",
        "GEOPACKAGE_FILE_PATH = os.path.join(GEOPACKAGE_OUTPUT_DIR, GEOPACKAGE_FILENAME)\n",
        "LAYER_NAME_GPKG = f\"hexagonos_ags_agregados_{RADIO_HEXAGONO_METROS}m\" # Usar el radio en el nombre de la capa\n",
        "\n",
        "# Verificar si gdf_hex_vis existe y tiene datos\n",
        "if 'gdf_hex_vis' in locals() and isinstance(gdf_hex_vis, gpd.GeoDataFrame) and not gdf_hex_vis.empty:\n",
        "    print(f\"GeoDataFrame 'gdf_hex_vis' encontrado con {len(gdf_hex_vis)} hexágonos.\")\n",
        "\n",
        "    # Seleccionar las columnas que queremos guardar.\n",
        "    # Es buena práctica ser explícito, aunque podríamos guardar todo gdf_hex_vis.\n",
        "    # Columnas de interés: cell_id, geometry, y todas las que terminan en \"_hex\" o son \"num_manzanas_en_hex\"\n",
        "\n",
        "    cols_to_keep = ['cell_id', 'geometry', 'num_manzanas_en_hex']\n",
        "    variables_numericas_duck = ['POBTOT', 'VIVTOT', 'TVIVHAB', 'VPH_INTER', 'VPH_PC', 'VPH_CEL', 'VPH_STVP', 'VPH_SPMVPI', 'VPH_CVJ', 'GRAPROES']\n",
        "    for var_base in variables_numericas_duck:\n",
        "        col_hex = f\"{var_base}_hex\"\n",
        "        if col_hex in gdf_hex_vis.columns:\n",
        "            cols_to_keep.append(col_hex)\n",
        "\n",
        "    # Crear una copia con solo las columnas deseadas para evitar modificar el GDF original\n",
        "    gdf_to_save = gdf_hex_vis[cols_to_keep].copy()\n",
        "\n",
        "    # Asegurar que la columna de geometría se llame 'geometry' (GeoPandas usualmente lo hace)\n",
        "    if gdf_to_save.geometry.name != 'geometry':\n",
        "        gdf_to_save.rename_geometry('geometry', inplace=True)\n",
        "\n",
        "    print(f\"Columnas a guardar en el GeoPackage: {gdf_to_save.columns.tolist()}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nGuardando GeoDataFrame en: {GEOPACKAGE_FILE_PATH}\")\n",
        "        print(f\"Nombre de la capa: {LAYER_NAME_GPKG}\")\n",
        "\n",
        "        # Guardar a GeoPackage\n",
        "        # Si el archivo ya existe, geopandas lo sobrescribirá por defecto con to_file.\n",
        "        # Si quieres diferentes capas en el mismo archivo GPKG, necesitarías 'mode=\"a\"'\n",
        "        # pero para una sola capa principal, el modo por defecto \"w\" (o si no existe lo crea) está bien.\n",
        "        gdf_to_save.to_file(GEOPACKAGE_FILE_PATH, layer=LAYER_NAME_GPKG, driver=\"GPKG\")\n",
        "\n",
        "        print(\"\\n¡GeoPackage guardado exitosamente!\")\n",
        "        print(f\"  Ruta: {GEOPACKAGE_FILE_PATH}\")\n",
        "        print(f\"  Capa: {LAYER_NAME_GPKG}\")\n",
        "\n",
        "        # Opcional: Descargar el archivo si estás en Google Colab\n",
        "        # from google.colab import files\n",
        "        # files.download(GEOPACKAGE_FILE_PATH)\n",
        "\n",
        "    except Exception as e_save:\n",
        "        print(f\"  ¡ERROR al guardar el GeoDataFrame como GeoPackage!: {e_save}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"¡ERROR! El GeoDataFrame 'gdf_hex_vis' no fue encontrado o está vacío.\")\n",
        "    print(\"Asegúrate de que la Celda 16 (o la celda que genera 'gdf_hex_vis') se haya ejecutado correctamente.\")\n",
        "\n",
        "print(\"\\n--- Fin del Script de Guardado a GeoPackage ---\")"
      ],
      "metadata": {
        "id": "HitCQ5Ekb1eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "files.download(\"./inegi_data_ags/geopackages_output/hexagonos_agregados_aguascalientes_01.gpkg\")"
      ],
      "metadata": {
        "id": "UDcHZvVsezEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"./inegi_data_ags/inegi_analisis_01.duckdb\")"
      ],
      "metadata": {
        "id": "gAp5tKLGe4dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80DDn02egh7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}